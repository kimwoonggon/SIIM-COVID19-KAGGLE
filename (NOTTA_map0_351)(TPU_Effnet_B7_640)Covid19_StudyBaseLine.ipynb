{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(NOTTA_map0.351)(김웅곤)(TPU-Effnet-B7-512)Covid19-StudyBaseLine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP6EW9TgPjJNitBk7P2qN7G",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimwoonggon/SIIM-COVID19-KAGGLE/blob/main/(NOTTA_map0_351)(%EA%B9%80%EC%9B%85%EA%B3%A4)(TPU_Effnet_B7_512)Covid19_StudyBaseLine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhbJWFGLTJ9A",
        "outputId": "4ce12fbd-ac4b-4fe7-c4aa-14889cf210fe"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU_vL8ic3HcZ",
        "outputId": "94382998-160a-4253-a3d1-441a60af3f86"
      },
      "source": [
        "#!pip install tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0\n",
        "#!pip install -U tensorflow-addons==0.9.1\n",
        "!pip install -U tensorflow-addons\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import requests\n",
        "import os\n",
        "resp = requests.post(\"http://{}:8475/requestversion/{}\".format(os.environ[\"COLAB_TPU_ADDR\"].split(\":\")[0], tf.__version__))\n",
        "if resp.status_code != 200:\n",
        "  print(\"Failed to switch the TPU to TF {}\".format(version))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied, skipping upgrade: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xX204k2Ktd"
      },
      "source": [
        "!pip install -q efficientnet >> /dev/null"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFPVid4aN0du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87611988-cdff-4550-b6ca-994b99c90a6e"
      },
      "source": [
        "import random, re, math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf, tensorflow.keras.backend as K\n",
        "!pip install gcsfs #gcp 파일 로드\n",
        "#from kaggle_datasets import KaggleDatasets\n",
        "from tensorflow.data.experimental import AUTOTUNE\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "import operator\n",
        "import gc\n",
        "import pathlib\n",
        "from scipy import spatial\n",
        "import cv2\n",
        "import functools"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.7/dist-packages (2021.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gcsfs) (3.7.4.post0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.31.0)\n",
            "Requirement already satisfied: fsspec==2021.06.1 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2021.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (1.6.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (5.1.0)\n",
            "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.7.4.3)\n",
            "Requirement already satisfied: async-timeout<4.0,>=3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (21.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (57.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.7.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NERnp6GCrxgr"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37CFiVVS4Q82",
        "outputId": "953284bc-4488-4a76-9c28-9f9a26e431a2"
      },
      "source": [
        "DEVICE = \"TPU\"\n",
        "if DEVICE == \"TPU\":\n",
        "    print(\"connecting to TPU...\")\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        print(\"Could not connect to TPU\")\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        try:\n",
        "            print(\"initializing  TPU ...\")\n",
        "            tf.config.experimental_connect_to_cluster(tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "            print(\"TPU initialized\")\n",
        "        except:\n",
        "            print(\"failed to initialize TPU\")\n",
        "    else:\n",
        "        DEVICE = \"GPU\"\n",
        "\n",
        "if DEVICE != \"TPU\":\n",
        "    print(\"Using default strategy for CPU and single GPU\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "if DEVICE == \"GPU\":\n",
        "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "    \n",
        "\n",
        "AUTO     = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "connecting to TPU...\n",
            "Running on TPU  grpc://10.17.99.122:8470\n",
            "initializing  TPU ...\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU initialized\n",
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Ylvljm1eIu",
        "outputId": "4e3884fc-661d-47c0-b21c-18ce9f5c3403"
      },
      "source": [
        "MIXED_PRECISION = True\n",
        "XLA_ACCELERATE = True\n",
        " \n",
        "if MIXED_PRECISION:\n",
        "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "    if tpu: \n",
        "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
        "    else: \n",
        "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
        "    mixed_precision.set_policy(policy)\n",
        "    print('Mixed precision enabled')\n",
        " \n",
        "if XLA_ACCELERATE:\n",
        "    tf.config.optimizer.set_jit(True)\n",
        "    print('Accelerated Linear Algebra enabled')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mixed precision enabled\n",
            "Accelerated Linear Algebra enabled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quqZy4Kipt7v"
      },
      "source": [
        "class CFG:\n",
        "    StudyOrTwoClasses = \"study\"\n",
        "    WIDTH = 1024\n",
        "    HEIGHT = 1024\n",
        "    OBJ_WIDTH = 640\n",
        "    OBJ_HEIGHT = 640\n",
        "    MEAN = (0.485, 0.456, 0.406)\n",
        "    STD = (0.229, 0.224, 0.225)\n",
        "    CHANNELS = 3\n",
        "    \n",
        "    REPLICAS = 8\n",
        "    EPOCHS = 50\n",
        "    BATCH_SIZE = 8 * REPLICAS\n",
        "    AUG_BATCH = BATCH_SIZE\n",
        "    \n",
        "    LEARNING_RATE = 9e-5 * REPLICAS\n",
        "    \n",
        "    NUMBER_OF_CLASSES = 4\n",
        "    RANDAUG_NUM = 2\n",
        "    RANDAUG_MAGNITUDE = 15\n",
        "    N_FOLDS = 5\n",
        " \n",
        "    NET = 7\n",
        "    TTA_NUM = 4\n",
        "    SEED = 100\n",
        "    GCS_PATH = 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14'\n",
        "    ROOT_PATH = 'gdrive/My Drive/Colab Notebooks/KAGGLE_COVID19'\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qXd8pFJ1fmR",
        "outputId": "705be30a-1eb8-4a64-fa23-0b055b914a57"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import efficientnet.tfkeras as efn\n",
        "import tensorflow.keras.applications as apl\n",
        "# import EfficientNetB0\n",
        "# Configuration\n",
        "effnets = [efn.EfficientNetB0,efn.EfficientNetB1,efn.EfficientNetB2,efn.EfficientNetB3,efn.EfficientNetB4,efn.EfficientNetB5,efn.EfficientNetB6,efn.EfficientNetB7]\n",
        "#effnets = [apl.EfficientNetB0,apl.EfficientNetB1,apl.EfficientNetB2,apl.EfficientNetB3,apl.EfficientNetB4,apl.EfficientNetB5,apl.EfficientNetB6,apl.EfficientNetB7]\n",
        "TTA_NUM = CFG.TTA_NUM\n",
        "TOTALWIDTH = CFG.WIDTH\n",
        "TOTALHEIGHT = CFG.HEIGHT\n",
        "HEIGHT = CFG.OBJ_HEIGHT\n",
        "WIDTH = CFG.OBJ_WIDTH\n",
        "IMAGE_SIZE = [HEIGHT, WIDTH]\n",
        "NET = CFG.NET\n",
        "BATCH_SIZE = CFG.BATCH_SIZE\n",
        "AUG_BATCH = BATCH_SIZE\n",
        "CHANNELS = CFG.CHANNELS\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        " \n",
        "GCS_PATH = CFG.GCS_PATH\n",
        "ROOT_PATH = CFG.ROOT_PATH\n",
        "EPOCHS = CFG.EPOCHS\n",
        "SEED = CFG.SEED\n",
        "LEARNING_RATE = CFG.LEARNING_RATE\n",
        "NUMBER_OF_CLASSES = CFG.NUMBER_OF_CLASSES\n",
        " \n",
        "#class_weight = CFG.CLASS_WEIGHT\n",
        " \n",
        "IMAGE_MEAN = CFG.MEAN\n",
        "IMAGE_STD = CFG.STD \n",
        "FILENAMES = tf.io.gfile.glob(CFG.GCS_PATH+f\"/{CFG.StudyOrTwoClasses}_train*\")\n",
        "#TEST_FILENAMES = tf.io.gfile.glob(CFG.GCS_PATH+\"/test*\")\n",
        "print(FILENAMES)\n",
        "#print(TEST_FILENAMES)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14/study_train00-1267.tfrec', 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14/study_train01-1267.tfrec', 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14/study_train02-1267.tfrec', 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14/study_train03-1267.tfrec', 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14/study_train04-1266.tfrec']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SOJUTcaXH2a",
        "outputId": "eaf87016-e89f-48a9-802a-2172ad430d3c"
      },
      "source": [
        "test_image = tf.cast(tf.random.uniform(shape=(1024,1024,3),minval = 0,maxval = 255,dtype=tf.int32), dtype=tf.uint8)\n",
        " \n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from tensorflow_addons.image.utils import to_4D_image, from_4D_image \n",
        "import inspect\n",
        "import math\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#from tensorflow.contrib import image as contrib_image\n",
        "#from tensorflow.contrib import training as contrib_training\n",
        "def blend(image1, image2, factor):\n",
        "  \"\"\"Blend image1 and image2 using 'factor'.\n",
        "  Factor can be above 0.0.  A value of 0.0 means only image1 is used.\n",
        "  A value of 1.0 means only image2 is used.  A value between 0.0 and\n",
        "  1.0 means we linearly interpolate the pixel values between the two\n",
        "  images.  A value greater than 1.0 \"extrapolates\" the difference\n",
        "  between the two pixel values, and we clip the results to values\n",
        "  between 0 and 255.\n",
        "  Args:\n",
        "    image1: An image Tensor of type uint8.\n",
        "    image2: An image Tensor of type uint8.\n",
        "    factor: A floating point value above 0.0.\n",
        "  Returns:\n",
        "    A blended image Tensor of type uint8.\n",
        "  \"\"\"\n",
        "  if factor == 0.0:\n",
        "    return tf.convert_to_tensor(image1)\n",
        "  if factor == 1.0:\n",
        "    return tf.convert_to_tensor(image2)\n",
        " \n",
        "  image1 = tf.cast(image1, dtype=tf.float32)\n",
        "  image2 = tf.cast(image2, dtype=tf.float32)\n",
        " \n",
        "  difference = image2 - image1\n",
        "  scaled = factor * difference\n",
        " \n",
        "  # Do addition in float.\n",
        "  temp = tf.cast(image1, dtype=tf.float32) + scaled\n",
        " \n",
        "  # Interpolate\n",
        "  if factor > 0.0 and factor < 1.0:\n",
        "    # Interpolation means we always stay within 0 and 255.\n",
        "    return tf.cast(temp, tf.uint8)\n",
        " \n",
        "  # Extrapolate:\n",
        "  #\n",
        "  # We need to clip and then cast.\n",
        "  return tf.cast(tf.clip_by_value(temp, 0.0, 255.0), tf.uint8)\n",
        "def Identity(image, _):\n",
        "    return image\n",
        "#Identity(test_image, 3)\n",
        "def AutoContrast(image, _):\n",
        "  \"\"\"Implements Autocontrast function from PIL using TF ops.\n",
        "  Args:\n",
        "    image: A 3D uint8 tensor.\n",
        "  Returns:\n",
        "    The image after it has had autocontrast applied to it and will be of type\n",
        "    uint8.\n",
        "  \"\"\"\n",
        " \n",
        "  def scale_channel(image):\n",
        "    \"\"\"Scale the 2D image using the autocontrast rule.\"\"\"\n",
        "    # A possibly cheaper version can be done using cumsum/unique_with_counts\n",
        "    # over the histogram values, rather than iterating over the entire image.\n",
        "    # to compute mins and maxes.\n",
        "    lo = tf.cast(tf.reduce_min(image), dtype = tf.float32)\n",
        "    hi = tf.cast(tf.reduce_max(image), dtype = tf.float32)\n",
        " \n",
        "    # Scale the image, making the lowest value 0 and the highest value 255.\n",
        "    def scale_values(im):\n",
        "        scale = 255.0 / (hi - lo)\n",
        "        offset = -lo * scale\n",
        "        im = tf.cast(im, dtype=tf.float32) * scale + offset\n",
        "        im = tf.clip_by_value(im, 0.0, 255.0)\n",
        "        return tf.cast(im, tf.uint8)\n",
        " \n",
        "    result = tf.cond(hi > lo, lambda: scale_values(image), lambda: image)\n",
        "    return result\n",
        " \n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image[:, :, 0])\n",
        "  s2 = scale_channel(image[:, :, 1])\n",
        "  s3 = scale_channel(image[:, :, 2])\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        " \n",
        "AutoContrast(test_image, 3)\n",
        "def Equalize(image, _):\n",
        "  \"\"\"Implements Equalize function from PIL using TF ops.\"\"\"\n",
        "  def scale_channel(im, c):\n",
        "    \"\"\"Scale the data in the channel to implement equalize.\"\"\"\n",
        "    im = tf.cast(im[:, :, c], tf.int32)\n",
        "    # Compute the histogram of the image channel.\n",
        "    histo = tf.histogram_fixed_width(im, [0, 255], nbins=256)\n",
        " \n",
        "    # For the purposes of computing the step, filter out the nonzeros.\n",
        "    nonzero = tf.where(tf.not_equal(histo, 0))\n",
        "    nonzero_histo = tf.reshape(tf.gather(histo, nonzero), [-1])\n",
        "    step = (tf.reduce_sum(nonzero_histo) - nonzero_histo[-1]) // 255\n",
        " \n",
        "    def build_lut(histo, step):\n",
        "      # Compute the cumulative sum, shifting by step // 2\n",
        "      # and then normalization by step.\n",
        "      lut = (tf.cumsum(histo) + (step // 2)) // step\n",
        "      # Shift lut, prepending with 0.\n",
        "      lut = tf.concat([[0], lut[:-1]], 0)\n",
        "      # Clip the counts to be in range.  This is done\n",
        "      # in the C code for image.point.\n",
        "      return tf.clip_by_value(lut, 0, 255)\n",
        " \n",
        "    # If step is zero, return the original image.  Otherwise, build\n",
        "    # lut from the full histogram and step and then index from it.\n",
        "    result = tf.cond(tf.equal(step, 0),\n",
        "                     lambda: im,\n",
        "                     lambda: tf.gather(build_lut(histo, step), im))\n",
        " \n",
        "    return tf.cast(result, tf.uint8)\n",
        " \n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image, 0)\n",
        "  s2 = scale_channel(image, 1)\n",
        "  s3 = scale_channel(image, 2)\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        "Equalize(test_image, 1)\n",
        "def Rotate(image, degrees):\n",
        "  \"\"\"Rotates the image by degrees either clockwise or counterclockwise.\n",
        "  Args:\n",
        "    image: An image Tensor of type uint8.\n",
        "    degrees: Float, a scalar angle in degrees to rotate all images by. If\n",
        "      degrees is positive the image will be rotated clockwise otherwise it will\n",
        "      be rotated counterclockwise.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels caused by\n",
        "      the rotate operation.\n",
        "  Returns:\n",
        "    The rotated version of image.\n",
        "  \"\"\"\n",
        "  # Convert from degrees to radians.\n",
        "  degrees = int(degrees)\n",
        "  degrees_to_radians = math.pi / 180.0\n",
        "  radians = degrees * degrees_to_radians\n",
        " \n",
        "  # In practice, we should randomize the rotation degrees by flipping\n",
        "  # it negatively half the time, but that's done on 'degrees' outside\n",
        "  # of the function.\n",
        "  #image = contrib_image.rotate(wrap(image), radians)\n",
        "  image = tfa.image.rotate(image, radians)\n",
        "  #return unwrap(image, replace)\n",
        "  return image\n",
        "Rotate(test_image, 30.1)\n",
        "def Solarize(image, threshold=128):\n",
        "  # For each pixel in the image, select the pixel\n",
        "  # if the value is less than the threshold.\n",
        "  # Otherwise, subtract 255 from the pixel.\n",
        "  #image = tf.convert_to_tensor(image, dtype=tf.int32)\n",
        "  #print(image)\n",
        "  \n",
        "  threshold = tf.cast(threshold, dtype=tf.uint8)\n",
        "  #print(threshold)\n",
        "  minus_value = tf.constant(255, dtype=tf.uint8)\n",
        "  #print(minus_value)\n",
        "  return tf.where(image < threshold, image, minus_value - image)\n",
        "Solarize(test_image, 10.0)\n",
        "def Color(image, factor):\n",
        "  \"\"\"Equivalent of PIL Color.\"\"\"\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))\n",
        "  #factor = tf.cast(factor, dtype=tf.float32)\n",
        "  return blend(degenerate, image, factor)\n",
        "Color(test_image, 10.1)\n",
        " \n",
        " \n",
        " \n",
        "def Posterize(image, bits):\n",
        " \n",
        "  bits=int(bits)\n",
        "  #print(bits)\n",
        "  \"\"\"Equivalent of PIL Posterize.\"\"\"\n",
        "  shift = 8 - bits\n",
        "  #print(shift)\n",
        "  #print(image)\n",
        "  return tf.bitwise.left_shift(tf.bitwise.right_shift(image, shift), shift)\n",
        "Posterize(test_image, 1.1)\n",
        "def Contrast(image, factor):\n",
        "  \"\"\"Equivalent of PIL Contrast.\"\"\"\n",
        "  degenerate = tf.image.rgb_to_grayscale(image)\n",
        "  # Cast before calling tf.histogram.\n",
        "  degenerate = tf.cast(degenerate, tf.int32)\n",
        " \n",
        "  # Compute the grayscale histogram, then compute the mean pixel value,\n",
        "  # and create a constant image size of that value.  Use that as the\n",
        "  # blending degenerate target of the original image.\n",
        "  hist = tf.histogram_fixed_width(degenerate, [0, 255], nbins=256)\n",
        "  mean = tf.reduce_sum(tf.cast(hist, tf.float32)) / 256.0\n",
        "  degenerate = tf.ones_like(degenerate, dtype=tf.float32) * mean\n",
        "  degenerate = tf.clip_by_value(degenerate, 0.0, 255.0)\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.cast(degenerate, tf.uint8))\n",
        "  return blend(degenerate, image, factor)\n",
        "Contrast(test_image, 10.1)\n",
        "def Brightness(image, factor):\n",
        "  \"\"\"Equivalent of PIL Brightness.\"\"\"\n",
        "  degenerate = tf.zeros_like(image)\n",
        "  return blend(degenerate, image, factor)\n",
        "Brightness(test_image, 10.1)\n",
        "def _sharpness_image(image, factor):\n",
        "    orig_image = image\n",
        "    image_dtype = image.dtype\n",
        "    image_channels = image.shape[-1]\n",
        "    image = tf.cast(image, tf.float32)\n",
        " \n",
        "    # SMOOTH PIL Kernel.\n",
        "    kernel = (\n",
        "        tf.constant(\n",
        "            [[1, 1, 1], [1, 5, 1], [1, 1, 1]], dtype=tf.float32, shape=[3, 3, 1, 1]\n",
        "        )\n",
        "        / 13.0\n",
        "    )\n",
        "    kernel = tf.tile(kernel, [1, 1, image_channels, 1])\n",
        " \n",
        "    # Apply kernel channel-wise.\n",
        "    degenerate = tf.nn.depthwise_conv2d(\n",
        "        image, kernel, strides=[1, 1, 1, 1], padding=\"VALID\", dilations=[1, 1]\n",
        "    )\n",
        "    degenerate = tf.cast(degenerate, image_dtype)\n",
        " \n",
        "    # For the borders of the resulting image, fill in the values of the original image.\n",
        "    mask = tf.ones_like(degenerate)\n",
        "    padded_mask = tf.pad(mask, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "    padded_degenerate = tf.pad(degenerate, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "    result = tf.where(tf.equal(padded_mask, 1), padded_degenerate, orig_image)\n",
        " \n",
        "    # Blend the final result.\n",
        "    blended = blend(result, orig_image, factor)\n",
        "    return tf.cast(blended, image_dtype)\n",
        " \n",
        " \n",
        "def Sharpness(image, factor):\n",
        "    \n",
        "        image_dims = tf.rank(image)\n",
        "        image = to_4D_image(image)\n",
        "        image = _sharpness_image(image, factor=factor)\n",
        "        return from_4D_image(image, image_dims)\n",
        "    #return tfa.image.sharpness(image, factor)\n",
        "Sharpness(test_image, 10.1)\n",
        " \n",
        "def ShearX(image, level):\n",
        "  \"\"\"Equivalent of PIL Shearing in X dimension.\"\"\"\n",
        "  # Shear parallel to x axis is a projective transform\n",
        "  # with a matrix form of:\n",
        "  # [1  level\n",
        "  #  0  1].\n",
        "  #image = contrib_image.transform(\n",
        "  #    wrap(image), [1., level, 0., 0., 1., 0., 0., 0.])\n",
        "  #return unwrap(image, replace)\n",
        "  \n",
        "  return tfa.image.shear_x(image, level, 0)\n",
        "ShearX(test_image,10)\n",
        "def ShearY(image, level):\n",
        "  \"\"\"Equivalent of PIL Shearing in Y dimension.\"\"\"\n",
        "  # Shear parallel to y axis is a projective transform\n",
        "  # with a matrix form of:\n",
        "  # [1  0\n",
        "  #  level  1].\n",
        "  #image = contrib_image.transform(\n",
        "  #    wrap(image), [1., 0., 0., level, 1., 0., 0., 0.])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.shear_y(image, level, 0)\n",
        "ShearX(test_image,20)\n",
        "def wrap(image):\n",
        "  \"\"\"Returns 'image' with an extra channel set to all 1s.\"\"\"\n",
        "  shape = tf.shape(image)\n",
        "  extended_channel = tf.ones([shape[0], shape[1], 1], image.dtype)\n",
        "  extended = tf.concat([image, extended_channel], 2)\n",
        "  return extended\n",
        " \n",
        "def unwrap(image, replace):\n",
        "  \"\"\"Unwraps an image produced by wrap.\n",
        "  Where there is a 0 in the last channel for every spatial position,\n",
        "  the rest of the three channels in that spatial dimension are grayed\n",
        "  (set to 128).  Operations like translate and shear on a wrapped\n",
        "  Tensor will leave 0s in empty locations.  Some transformations look\n",
        "  at the intensity of values to do preprocessing, and we want these\n",
        "  empty pixels to assume the 'average' value, rather than pure black.\n",
        "  Args:\n",
        "    image: A 3D Image Tensor with 4 channels.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels.\n",
        "  Returns:\n",
        "    image: A 3D image Tensor with 3 channels.\n",
        "  \"\"\"\n",
        "  image_shape = tf.shape(image)\n",
        "  # Flatten the spatial dimensions.\n",
        "  flattened_image = tf.reshape(image, [-1, image_shape[2]])\n",
        " \n",
        "  # Find all pixels where the last channel is zero.\n",
        "  alpha_channel = flattened_image[:, 3]\n",
        " \n",
        "  replace = tf.concat([replace, tf.ones([1], image.dtype)], 0)\n",
        " \n",
        "  # Where they are zero, fill them in with 'replace'.\n",
        "  flattened_image = tf.where(\n",
        "      tf.equal(alpha_channel, 0),\n",
        "      tf.ones_like(flattened_image, dtype=image.dtype) * replace,\n",
        "      flattened_image)\n",
        " \n",
        "  image = tf.reshape(flattened_image, image_shape)\n",
        "  image = tf.slice(image, [0, 0, 0], [image_shape[0], image_shape[1], 3])\n",
        "  return image\n",
        " \n",
        "def TranslateX(image, pixels):\n",
        "  \"\"\"Equivalent of PIL Translate in X dimension.\"\"\"\n",
        "  #image = contrib_image.translate(wrap(image), [-pixels, 0])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.translate_xy(image, [pixels, 0], replace=0)\n",
        "TranslateX(test_image, 10)\n",
        "def TranslateY(image, pixels):\n",
        "  \"\"\"Equivalent of PIL Translate in Y dimension.\"\"\"\n",
        "  #image = contrib_image.translate(wrap(image), [0, -pixels])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.translate_xy(image, [0, pixels], replace=0)\n",
        "TranslateY(test_image, 10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1024, 1024, 3), dtype=uint8, numpy=\n",
              "array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[104, 108, 141],\n",
              "        [110, 196, 179],\n",
              "        [180, 240, 122],\n",
              "        ...,\n",
              "        [105,  14, 253],\n",
              "        [126, 203,  42],\n",
              "        [213, 140,  34]],\n",
              "\n",
              "       [[251,  97, 103],\n",
              "        [112, 228,   9],\n",
              "        [239,  80,  83],\n",
              "        ...,\n",
              "        [157,  22, 215],\n",
              "        [150,  99, 177],\n",
              "        [168,  55, 238]],\n",
              "\n",
              "       [[ 30, 170,  49],\n",
              "        [223, 112, 135],\n",
              "        [145, 183, 177],\n",
              "        ...,\n",
              "        [141, 177,   5],\n",
              "        [214,  21, 180],\n",
              "        [192, 254, 172]]], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws5Tg2JZpE7g"
      },
      "source": [
        "class RandomResizedCrop:\n",
        "    \"\"\"Torchvision's variant of crop a random part of the input and rescale it to some size.\n",
        "    Args:\n",
        "        height (int): height after crop and resize.\n",
        "        width (int): width after crop and resize.\n",
        "        scale ((float, float)): range of size of the origin size cropped\n",
        "        ratio ((float, float)): range of aspect ratio of the origin aspect ratio cropped\n",
        "        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:\n",
        "            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.\n",
        "            Default: cv2.INTER_LINEAR.\n",
        "        p (float): probability of applying the transform. Default: 1.\n",
        "    Targets:\n",
        "        image, mask, bboxes, keypoints\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        height,\n",
        "        width,\n",
        "        org_height,\n",
        "        org_width,\n",
        "        scale=(0.08, 1.0),\n",
        "        ratio=(0.75, 1.3333333333333333),\n",
        "    ):\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.scale = scale\n",
        "        self.ratio = ratio\n",
        "        self.beforeheight = org_height\n",
        "        self.beforewidth = org_width\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_random_crop_coords(height, width, crop_height, crop_width, h_start, w_start):\n",
        "        x1 = int((height - crop_height) * h_start)\n",
        "        x2 = x1 + crop_height\n",
        "        y1 = int((width - crop_width) * w_start)\n",
        "        y2 = y1 + crop_width\n",
        "        return x1, y1, x2, y2\n",
        "    \n",
        "    def __call__(self, img):\n",
        "\n",
        "        \n",
        "        area = img.shape[0] * img.shape[1]\n",
        "        #print(img.shape[0], img.shape[1])\n",
        "        for _attempt in range(10):\n",
        "            target_area = random.uniform(*self.scale) * area\n",
        "            log_ratio = (math.log(self.ratio[0]), math.log(self.ratio[1]))\n",
        "            aspect_ratio = math.exp(random.uniform(*log_ratio))\n",
        "\n",
        "            w = int(round(math.sqrt(target_area * aspect_ratio)))  # skipcq: PTC-W0028\n",
        "            h = int(round(math.sqrt(target_area / aspect_ratio)))  # skipcq: PTC-W0028\n",
        "            #print(w, h)\n",
        "            if 0 < w <= img.shape[1] and 0 < h <= img.shape[0]:\n",
        "                i = random.randint(0, img.shape[0] - h)\n",
        "                j = random.randint(0, img.shape[1] - w)\n",
        "                h_start = i * 1.0 / (img.shape[0] - h + 1e-10)\n",
        "                w_start = j * 1.0 / (img.shape[1] - w + 1e-10)\n",
        "                #print(h, w)\n",
        "                x1, y1, x2, y2 = self.get_random_crop_coords(self.beforeheight, self.beforewidth, h, w, h_start, w_start)\n",
        "                #print(h, w)\n",
        "                #print(x1, y1, x2, y2)\n",
        "                #print(x1, y1, x2, y2)\n",
        "                img = img[x1:x2, y1:y2, :]\n",
        "                img = tf.image.resize(img, (self.height, self.width))\n",
        "                return tf.cast(img, dtype=tf.uint8)\n",
        "\n",
        "        # Fallback to central crop\n",
        "        #print('central gogo')\n",
        "        in_ratio = img.shape[1] / img.shape[0]\n",
        "        if in_ratio < min(self.ratio):\n",
        "            w = img.shape[1]\n",
        "            h = int(round(w / min(self.ratio)))\n",
        "        elif in_ratio > max(self.ratio):\n",
        "            h = img.shape[0]\n",
        "            w = int(round(h * max(self.ratio)))\n",
        "        else:  # whole image\n",
        "            w = img.shape[1]\n",
        "            h = img.shape[0]\n",
        "        i = (img.shape[0] - h) // 2\n",
        "        j = (img.shape[1] - w) // 2\n",
        "        x1, y1, x2, y2 = self.get_random_crop_coords(self.beforeheight, self.beforewidth, h, w, i, j)\n",
        "        img = img[x1:x2, y1:y2, :]\n",
        "        img = tf.image.resize(img, (self.height, self.width))\n",
        "        return tf.cast(img, dtype=tf.uint8)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDDsiU6PE6Zm"
      },
      "source": [
        "class Normalize:\n",
        "    \"\"\"Divide pixel values by 255 = 2**8 - 1, subtract mean per channel and divide by std per channel.\n",
        "    Args:\n",
        "        mean (float, list of float): mean values\n",
        "        std  (float, list of float): std values\n",
        "        max_pixel_value (float): maximum possible pixel value\n",
        "    Targets:\n",
        "        image\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, mean=CFG.MEAN, std=CFG.STD, max_pixel_value=255.0, always_apply=False, p=1.0\n",
        "    ):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.max_pixel_value = max_pixel_value\n",
        "\n",
        "\n",
        "    \n",
        "    def normalize_image(self, img, mean, std, max_pixel_value=255.0):\n",
        "        mean = tf.convert_to_tensor(mean, dtype=tf.float32)\n",
        "        mean = mean * max_pixel_value\n",
        "\n",
        "        std = tf.convert_to_tensor(std, dtype=tf.float32)\n",
        "        std = std * max_pixel_value\n",
        "\n",
        "        denominator = tf.math.reciprocal(std)\n",
        "\n",
        "        #print('before cast', img)\n",
        "        img = tf.cast(img, dtype = tf.float32)\n",
        "        #print('after cast', img)\n",
        "        #img = img - mean\n",
        "        #img = img * denominator\n",
        "        img = img / 255.\n",
        "        return img\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.normalize_image(img, self.mean, self.std)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ivUmviTzRd6"
      },
      "source": [
        "class CoarseDropout:\n",
        "  def __init__(self, max_holes, size=0.06):\n",
        "    self.size = size\n",
        "    self.max_holes = max_holes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __call__(self, image):\n",
        "      #holes = []\n",
        "      P = random.uniform(0,1)\n",
        "      height = image.shape[0]\n",
        "      width = image.shape[1]\n",
        "      for _n in range(self.max_holes):\n",
        "          hole_height = height * self.size * P\n",
        "          hole_width = width * self.size * P\n",
        "          hole_height = int(hole_height)\n",
        "          hole_width = int(hole_width)\n",
        "          y1 = random.randint(0, height - hole_height)\n",
        "          x1 = random.randint(0, width- hole_width)\n",
        "          y2 = y1 + hole_height\n",
        "          x2 = x1 + hole_width\n",
        "          #holes.append((y1, x1, y2, x2))\n",
        "        \n",
        "          one = image[y1:y2,0:x1,:]\n",
        "          two = tf.zeros([y2-y1,x2-x1,3], dtype=tf.uint8) \n",
        "          three = image[y1:y2,x2:width,:]\n",
        "          middle = tf.concat([one,two,three],axis=1)\n",
        "          image = tf.concat([image[0:y1,:,:],middle,image[y2:height,:,:]],axis=0)\n",
        "      \n",
        "          \n",
        "      image = tf.cast(image, dtype=tf.uint8)\n",
        "      return image"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qtmKcRRnLJS"
      },
      "source": [
        "def augment_list():\n",
        " \n",
        "  l = [  #(Identity, 0, 1),\n",
        "        #(AutoContrast, 0, 1),\n",
        "        #(Equalize, 0, 1),\n",
        "        (Rotate, -20, 20),\n",
        "        #(Posterize, 0, 4),\n",
        "        #(Solarize, 0, 256),\n",
        "        #(Color, 0.1, 1.9),\n",
        "        (Contrast, 0.1, 1.9),\n",
        "        (Brightness, 0.1, 1.9),\n",
        "        #(Sharpness, 0.1, 1.9),\n",
        "        (ShearX, -0.1, 0.1),\n",
        "        (ShearY, -0.1, 0.1),\n",
        "        (TranslateX, -CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "        (TranslateY, -CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "    ]\n",
        "  return l"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tzakJMqhjAY"
      },
      "source": [
        "def augment_list_tta():\n",
        " \n",
        "  l = [  #(Identity, 0, 1),\n",
        "        #(AutoContrast, 0, 1),\n",
        "        #(Equalize, 0, 1),\n",
        "        #(Rotate, -15, 15),\n",
        "        #(Posterize, 0, 4),\n",
        "        #(Solarize, 0, 256),\n",
        "        #(Color, 0.1, 1.9),\n",
        "        #(Contrast, 0.1, 1.9),\n",
        "        (Brightness, 0.1, 1.9),\n",
        "        #(Sharpness, 0.1, 1.9),\n",
        "        #(ShearX, -0.1, 0.1),\n",
        "        #(ShearY, -0.1, 0.1),\n",
        "        #(TranslateX, -CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "        #(TranslateY, -CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "    ]\n",
        "  return l"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYyHDbDpnfBk"
      },
      "source": [
        "import random\n",
        "class RandAugment:\n",
        "    def __init__(self, n, m):\n",
        "        self.n = n\n",
        "        self.m = m      # [0, 30]\n",
        "        self.augment_list = augment_list()\n",
        " \n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_list, k=self.n)\n",
        "        for op, minval, maxval in ops:\n",
        "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
        "            img = op(img, val)\n",
        " \n",
        " \n",
        "        return img"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykrpFND_rQ-p"
      },
      "source": [
        "import random\n",
        "class RandAugmentTTA:\n",
        "    def __init__(self, n, m):\n",
        "        self.n = n\n",
        "        self.m = m      # [0, 30]\n",
        "        self.augment_list = augment_list_tta()\n",
        " \n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_list, k=self.n)\n",
        "        for op, minval, maxval in ops:\n",
        "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
        "            img = op(img, val)\n",
        " \n",
        " \n",
        "        return img"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oqGkm0mLoW0"
      },
      "source": [
        "def cutmix(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with cutmix applied\n",
        "    #print(image.shape, label.shape)\n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.BATCH_SIZE\n",
        "    cutmix_start = 0.0\n",
        "    imgs = []; labs = []\n",
        "    \n",
        "    image = tf.image.resize(image, size=(DIM1, DIM2))\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],cutmix_start,1)<=PROBABILITY, tf.int32)\n",
        "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        # CHOOSE RANDOM LOCATION\n",
        "        x = tf.cast( tf.random.uniform([],0,DIM2),tf.int32)\n",
        "        y = tf.cast( tf.random.uniform([],0,DIM1),tf.int32)\n",
        "        a = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32)\n",
        "        b = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32) # this is beta dist with alpha=1.0\n",
        "        WIDTH = tf.cast( DIM2 * tf.math.sqrt(1-a),tf.int32) * P\n",
        "        HEIGHT = tf.cast( DIM1 * tf.math.sqrt(1-b), tf.int32) * P\n",
        "        ya = tf.math.maximum(0,y-HEIGHT//2)\n",
        "        yb = tf.math.minimum(DIM1,y+HEIGHT//2)\n",
        "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
        "        xb = tf.math.minimum(DIM2,x+WIDTH//2)\n",
        "        # MAKE CUTMIX IMAGE\n",
        "        one = image[j,ya:yb,0:xa,:]\n",
        "        two = image[k,ya:yb,xa:xb,:]\n",
        "        three = image[j,ya:yb,xb:DIM2,:]\n",
        "        middle = tf.concat([one,two,three],axis=1)\n",
        "        cutmix_img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM1,:,:]],axis=0)\n",
        "        p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        if p_flip > 0.5:\n",
        "            cutmix_img = tf.image.flip_left_right(cutmix_img)\n",
        "        if p_v_flip > 0.5:\n",
        "            cutmix_img = tf.image.flip_up_down(cutmix_img)\n",
        "        if p_transpose > 0.5:\n",
        "            cutmix_img = tf.image.transpose(cutmix_img)\n",
        "        #cutmix_img = Normalize(CFG.MEAN, CFG.STD)(cutmix_img)\n",
        "        #cutmix_img = tf.image.resize(cutmix_img, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        #mixup_image = (1-a)*img1 + a*img2\n",
        "        cutmix_img = Normalize(CFG.MEAN, CFG.STD)(cutmix_img)\n",
        "        #mixup_image = tf.image.resize(mixup_image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        #imgs.append(mixup_image)\n",
        "        imgs.append(cutmix_img)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        a = tf.cast(WIDTH*HEIGHT/DIM1/DIM2,tf.float32)\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2\n",
        " \n",
        " \n",
        " \n",
        "def mixup(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with mixup applied\n",
        "    AUG_BATCH = CFG.BATCH_SIZE\n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    \n",
        "    imgs = []; labs = []\n",
        "    image = tf.image.resize(image, size=(DIM1, DIM2))\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n",
        "        # CHOOSE RANDOM\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        a = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32)*P # this is beta dist with alpha=1.0\n",
        "        # MAKE MIXUP IMAGE\n",
        "        img1 = image[j,]\n",
        "        img2 = image[k,]\n",
        "        #mixup_image = (1-0.5)*img1 + 0.5*img2\n",
        "        mixup_image = (1-a)*img1 + a*img2\n",
        "        p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        #p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        #p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        if p_flip > 0.5:\n",
        "            mixup_image = tf.image.flip_left_right(mixup_image)\n",
        "        #if p_v_flip > 0.5:\n",
        "        #    mixup_image = tf.image.flip_up_down(mixup_image)\n",
        "        #if p_transpose > 0.5:\n",
        "        #    mixup_image = tf.image.transpose(mixup_image)\n",
        "        mixup_image = Normalize(CFG.MEAN, CFG.STD)(mixup_image)\n",
        "        #mixup_image = tf.image.resize(mixup_image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        imgs.append(mixup_image)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEAxFwBse-yv"
      },
      "source": [
        "def real_data_augment(image, label):\n",
        "    k = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    if k < 0.5:\n",
        "        image2, label2 = mixup(image, label)\n",
        "    #elif (k >= -2) and (k < 0):\n",
        "    #    image2, label2 = cutmix(image, label)\n",
        "    else:\n",
        "        image2, label2 = data_augment(image, label)\n",
        " \n",
        "    return image2, label2 \n",
        " \n",
        "def prep_for_val(image, label):\n",
        "    \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    #randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    #coarse = CoarseDropout(30)\n",
        "    #randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.85, 1.0))\n",
        " \n",
        "    #P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            img = tf.image.resize(img, [DIM1, DIM2])\n",
        "            img = normalize(img)\n",
        "            imgs.append(img)\n",
        " \n",
        "       \n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2\n",
        " \n",
        " \n",
        "def data_augment(image, label):\n",
        " \n",
        " \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    coarse = CoarseDropout(1)\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.9, 1.1))\n",
        " \n",
        "    P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        " \n",
        "            img = randomcrop(img)\n",
        " \n",
        "            if p_flip >= 0.5:\n",
        "                img = tf.image.flip_left_right(img)\n",
        "            if p_v_flip >= 0.5:\n",
        "                img = tf.image.flip_up_down(img)\n",
        "            #if p_transpose >= 0.5:\n",
        "            #    if CFG.OBJ_HEIGHT == CFG.OBJ_WIDTH:\n",
        "            #        img = tf.image.transpose(img)\n",
        " \n",
        "            img = coarse(img)\n",
        "            img = randaug(img)\n",
        "            #img = img/255.\n",
        "            img = tf.cast(img, tf.float32) / 255.\n",
        "            imgs.append(img)\n",
        " \n",
        "       \n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECrHNVz2S4Dk",
        "outputId": "c5ebdce1-eb75-4a2c-a3b7-84a2afa73272"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI8RTuBuSEpg"
      },
      "source": [
        "def decode_tr_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    \n",
        "    return image\n",
        " \n",
        "def decode_val_image(image_data, label):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    #image = normalize(image)\n",
        "    image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    label = tf.reshape(label, [CFG.NUMBER_OF_CLASSES])\n",
        "    return image, label\n",
        "\n",
        "def decode_test_image(image_data, label):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image, label\n",
        "\n",
        "def decode_just_test_image(image_data):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image\n",
        " \n",
        "def decode_val_image_for_tta(image_data):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.99,1.0))\n",
        "    randaug = RandAugmentTTA(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    #p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    #image = randomcrop(image)\n",
        "    if p_flip > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "    if p_v_flip > 0.5:\n",
        "        image = tf.image.flip_up_down(image)\n",
        "    #if CFG.OBJ_HEIGHT == CFG.OBJ_WIDTH:\n",
        "    #    if p_transpose > 0.5:\n",
        "    #        image = tf.image.transpose(image)\n",
        "    image = randaugtta(image)\n",
        "    #image = normalize(image)\n",
        "    image = tf.cast(image, tf.float32) / 255.\n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image\n",
        " \n",
        "def read_tfrecord(example, labeled=True):\n",
        "    \"\"\"\n",
        "        1. Parse data based on the 'TFREC_FORMAT' map.\n",
        "        2. Decode image.\n",
        "        3. If 'labeled' returns (image, label) if not (image, name).\n",
        "    \"\"\"\n",
        "    if labeled:\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'target': tf.io.FixedLenFeature([], tf.int64), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image'], tf.one_hot(example['target'], depth=CFG.NUMBER_OF_CLASSES)\n",
        "    else:\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image'], example['image_id']\n",
        "\n",
        "def read_test_tfrecord(example):\n",
        "\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image'], example['image_id']\n",
        "\n",
        "def read_test_image_tfrecord(example):\n",
        "\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image']\n",
        " \n",
        "def load_dataset(filenames, validation, labeled=True, ordered=False, ):\n",
        "    \"\"\"\n",
        "        Create a Tensorflow dataset from TFRecords.\n",
        "    \"\"\"\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False\n",
        " \n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "    dataset = dataset.with_options(ignore_order)\n",
        "    if validation == False:\n",
        " \n",
        "        dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled, validation = False), num_parallel_calls=AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled, validation = True), num_parallel_calls=AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False, validation=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(1024*8)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        dataset = dataset.with_options(opt)\n",
        "    \n",
        "    if (labeled == True):\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=True), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=False), num_parallel_calls = AUTO)\n",
        "    \n",
        "    if (validation == True) and (labeled == False):\n",
        "        pass\n",
        "    elif (validation == False) and (labeled == True):\n",
        "        dataset = dataset.map(lambda image, label : (decode_tr_image(image), label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda image, label : decode_val_image(image, label), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if augment:\n",
        "            dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "    #else:\n",
        "    #        dataset = dataset.map(prep_for_val, num_parallel_calls=AUTO)\n",
        "    \n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_test_dataset(FILENAMES, return_image_name=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()   \n",
        "    \n",
        "    \n",
        "    if return_image_name:\n",
        "        dataset = dataset.map(lambda example : read_test_tfrecord(example), num_parallel_calls = AUTO)\n",
        "        dataset = dataset.map(lambda image, label : decode_test_image(image, label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_test_image_tfrecord(example), num_parallel_calls = AUTO)\n",
        "        dataset = dataset.map(lambda image : decode_just_test_image(image), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_dataset_for_tta(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False, validation=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(1024*8)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        dataset = dataset.with_options(opt)\n",
        "    \n",
        "    if (labeled == True):\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=True), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=False), num_parallel_calls = AUTO)\n",
        "    \n",
        "    if validation == False:\n",
        "        dataset = dataset.map(lambda image, label : (decode_tr_image(image), label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda image, label : (decode_val_image_for_tta(image), label), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if augment:\n",
        "            dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "    \n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEVAoSVZoB-1"
      },
      "source": [
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    print(n)\n",
        "    return np.sum(n)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDqawNTsn1vX"
      },
      "source": [
        "from tensorflow_addons.utils.types import FloatTensorLike\n",
        " \n",
        "from typing import Union, Callable, Dict\n",
        "from typeguard import typechecked\n",
        " \n",
        " \n",
        "class CosineDecayRAdam(tfa.optimizers.RectifiedAdam):\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        var_dtype = var.dtype.base_dtype\n",
        "        lr_t = self._decayed_lr(var_dtype)\n",
        "        wd_t = self._decayed_wd(var_dtype)\n",
        "        m = self.get_slot(var, \"m\")\n",
        "        v = self.get_slot(var, \"v\")\n",
        "        beta_1_t = self._get_hyper(\"beta_1\", var_dtype)\n",
        "        beta_2_t = self._get_hyper(\"beta_2\", var_dtype)\n",
        "        epsilon_t = tf.convert_to_tensor(self.epsilon, var_dtype)\n",
        "        local_step = tf.cast(self.iterations + 1, var_dtype)\n",
        "        beta_1_power = tf.pow(beta_1_t, local_step)\n",
        "        beta_2_power = tf.pow(beta_2_t, local_step)\n",
        " \n",
        "        if self._initial_total_steps > 0:\n",
        "            total_steps = self._get_hyper(\"total_steps\", var_dtype)\n",
        "            warmup_steps = total_steps * self._get_hyper(\"warmup_proportion\", var_dtype)\n",
        "            min_lr = self._get_hyper(\"min_lr\", var_dtype)\n",
        "            decay_steps = tf.maximum(total_steps - warmup_steps, 1)\n",
        "            decay_rate = (min_lr - lr_t) / decay_steps\n",
        "            pi = tf.constant(3.141592)\n",
        "            cos = tf.math.cos(pi * ((local_step - warmup_steps) / (total_steps - warmup_steps))) + tf.constant(1.)\n",
        "            lr_t = tf.where(\n",
        "                local_step <= warmup_steps,\n",
        "                lr_t * (local_step / warmup_steps),\n",
        "                #lr_t + decay_rate * tf.minimum(local_step - warmup_steps, decay_steps),\n",
        "                min_lr + (lr_t - min_lr) / 2. * cos\n",
        "            )\n",
        " \n",
        "        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n",
        "        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n",
        " \n",
        "        m_t = m.assign(\n",
        "            beta_1_t * m + (1.0 - beta_1_t) * grad, use_locking=self._use_locking\n",
        "        )\n",
        "        m_corr_t = m_t / (1.0 - beta_1_power)\n",
        " \n",
        "        v_t = v.assign(\n",
        "            beta_2_t * v + (1.0 - beta_2_t) * tf.square(grad),\n",
        "            use_locking=self._use_locking,\n",
        "        )\n",
        "        if self.amsgrad:\n",
        "            vhat = self.get_slot(var, \"vhat\")\n",
        "            vhat_t = vhat.assign(tf.maximum(vhat, v_t), use_locking=self._use_locking)\n",
        "            v_corr_t = tf.sqrt(vhat_t / (1.0 - beta_2_power))\n",
        "        else:\n",
        "            vhat_t = None\n",
        "            v_corr_t = tf.sqrt(v_t / (1.0 - beta_2_power))\n",
        " \n",
        "        r_t = tf.sqrt(\n",
        "            (sma_t - 4.0)\n",
        "            / (sma_inf - 4.0)\n",
        "            * (sma_t - 2.0)\n",
        "            / (sma_inf - 2.0)\n",
        "            * sma_inf\n",
        "            / sma_t\n",
        "        )\n",
        " \n",
        "        sma_threshold = self._get_hyper(\"sma_threshold\", var_dtype)\n",
        "        var_t = tf.where(\n",
        "            sma_t >= sma_threshold, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t\n",
        "        )\n",
        " \n",
        "        if self._has_weight_decay:\n",
        "            var_t += wd_t * var\n",
        " \n",
        "        var_update = var.assign_sub(lr_t * var_t, use_locking=self._use_locking)\n",
        " \n",
        "        updates = [var_update, m_t, v_t]\n",
        "        if self.amsgrad:\n",
        "            updates.append(vhat_t)\n",
        "        return tf.group(*updates)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtZCnkM3BCN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "599d4592-af76-44cc-8951-979d63d0f2aa"
      },
      "source": [
        "# RandomCropedSized FIX\n",
        "# Cosine Decay Radam\n",
        " \n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = []; history_list = []; normal_oof_pred = []; pred_max = []\n",
        "import gc\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = CFG.N_FOLDS, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "seed_everything(SEED)\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    TRAINING_IMAGES = TRAINING_FILENAMES\n",
        " \n",
        "    train_dataset = get_dataset(TRAINING_FILENAMES, labeled=True, ordered=False, repeated=True, augment=True, validation=False)\n",
        "    val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        " \n",
        "    def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'imagenet', include_top = False, pooling='avg')\n",
        "        #for i, layer in enumerate(effnet.layers):\n",
        "            #if i < 236: overfit\n",
        "        #    if i < 200:\n",
        "                # 179 overfit\n",
        "\n",
        "        #        layer.trainable = False\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x0 = tf.keras.layers.Dropout(0.5)(x0)\n",
        "        x0 = tf.keras.layers.Dense(64, activation='relu')(x0)\n",
        "        x = tf.keras.layers.Dense(CFG.NUMBER_OF_CLASSES, activation='softmax', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        \n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        #opt =tf.keras.optimizers.Adam(learning_rate=CFG.LEARNING_RATE)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'categorical_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tf.keras.backend.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(ROOT_PATH, f\"COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"), \n",
        "                                                    monitor = 'val_auc', \n",
        "                                                    save_best_only = True,\n",
        "                                                    mode = 'max')\n",
        "    history = model.fit(train_dataset,  \n",
        "                        steps_per_epoch = STEPS_PER_EPOCH,\n",
        "                        epochs = CFG.EPOCHS,\n",
        "                        callbacks = [checkpoint],\n",
        "                        validation_data = val_dataset,\n",
        "                        verbose = 1,\n",
        "                        ).history\n",
        "    print(f\"#### FOLD {fold+1} without TTA VAL_AUC = {np.max(history['val_auc']):.3f}\")\n",
        "    del model\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model7 has been loaded \n",
            "Epoch 1/50\n",
            "79/79 [==============================] - 877s 1s/step - loss: 1.3953 - auc: 0.5149 - val_loss: 1.3275 - val_auc: 0.5846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 1.2566 - auc: 0.5526 - val_loss: 1.1493 - val_auc: 0.6613\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 1.0993 - auc: 0.6244 - val_loss: 1.0895 - val_auc: 0.7162\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 1.0440 - auc: 0.6513 - val_loss: 0.9679 - val_auc: 0.7611\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 1.0202 - auc: 0.6628 - val_loss: 0.9243 - val_auc: 0.7845\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.9902 - auc: 0.6846 - val_loss: 0.9559 - val_auc: 0.7869\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.9391 - auc: 0.7150 - val_loss: 0.9714 - val_auc: 0.7828\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 66s 837ms/step - loss: 0.9720 - auc: 0.6971 - val_loss: 0.9306 - val_auc: 0.7971\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.9327 - auc: 0.7161 - val_loss: 0.8987 - val_auc: 0.8062\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.9090 - auc: 0.7269 - val_loss: 0.9744 - val_auc: 0.7891\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 66s 837ms/step - loss: 0.9169 - auc: 0.7222 - val_loss: 0.9418 - val_auc: 0.7877\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 66s 839ms/step - loss: 0.8552 - auc: 0.7575 - val_loss: 0.9833 - val_auc: 0.7818\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 66s 836ms/step - loss: 0.8236 - auc: 0.7605 - val_loss: 1.0111 - val_auc: 0.7934\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.8330 - auc: 0.7688 - val_loss: 0.9844 - val_auc: 0.7852\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 66s 837ms/step - loss: 0.8086 - auc: 0.7667 - val_loss: 1.0465 - val_auc: 0.7918\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 66s 834ms/step - loss: 0.7761 - auc: 0.7763 - val_loss: 1.1420 - val_auc: 0.7738\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 66s 838ms/step - loss: 0.7526 - auc: 0.7869 - val_loss: 1.0590 - val_auc: 0.7776\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 66s 836ms/step - loss: 0.7284 - auc: 0.7909 - val_loss: 1.0635 - val_auc: 0.7925\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 66s 836ms/step - loss: 0.7108 - auc: 0.7926 - val_loss: 1.1516 - val_auc: 0.7800\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 66s 838ms/step - loss: 0.6923 - auc: 0.7975 - val_loss: 1.1314 - val_auc: 0.7715\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.6309 - auc: 0.8207 - val_loss: 1.2925 - val_auc: 0.7551\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 66s 837ms/step - loss: 0.6188 - auc: 0.8189 - val_loss: 1.1992 - val_auc: 0.7686\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.6120 - auc: 0.8338 - val_loss: 1.5225 - val_auc: 0.7445\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.5586 - auc: 0.8382 - val_loss: 1.2946 - val_auc: 0.7582\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.5192 - auc: 0.8516 - val_loss: 1.3073 - val_auc: 0.7580\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 66s 838ms/step - loss: 0.4988 - auc: 0.8444 - val_loss: 1.3670 - val_auc: 0.7530\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 66s 836ms/step - loss: 0.4829 - auc: 0.8425 - val_loss: 1.3893 - val_auc: 0.7563\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.4680 - auc: 0.8324 - val_loss: 1.4752 - val_auc: 0.7507\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 66s 839ms/step - loss: 0.4270 - auc: 0.8640 - val_loss: 1.4938 - val_auc: 0.7517\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 66s 839ms/step - loss: 0.4330 - auc: 0.8360 - val_loss: 1.4325 - val_auc: 0.7490\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 66s 838ms/step - loss: 0.3834 - auc: 0.8709 - val_loss: 1.4851 - val_auc: 0.7487\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 66s 838ms/step - loss: 0.3828 - auc: 0.8480 - val_loss: 1.4348 - val_auc: 0.7603\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 66s 838ms/step - loss: 0.3450 - auc: 0.8590 - val_loss: 1.5593 - val_auc: 0.7567\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.3324 - auc: 0.8677 - val_loss: 1.5841 - val_auc: 0.7542\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.3343 - auc: 0.8751 - val_loss: 1.5039 - val_auc: 0.7586\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 66s 836ms/step - loss: 0.3285 - auc: 0.8708 - val_loss: 1.5236 - val_auc: 0.7585\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 66s 843ms/step - loss: 0.3058 - auc: 0.8764 - val_loss: 1.4995 - val_auc: 0.7616\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.2942 - auc: 0.8709 - val_loss: 1.5268 - val_auc: 0.7573\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.2807 - auc: 0.8834 - val_loss: 1.5381 - val_auc: 0.7575\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 66s 839ms/step - loss: 0.2851 - auc: 0.8796 - val_loss: 1.5375 - val_auc: 0.7558\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.2776 - auc: 0.8753 - val_loss: 1.5671 - val_auc: 0.7576\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 66s 839ms/step - loss: 0.2846 - auc: 0.8610 - val_loss: 1.5298 - val_auc: 0.7546\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 66s 836ms/step - loss: 0.2682 - auc: 0.8732 - val_loss: 1.5431 - val_auc: 0.7544\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 66s 837ms/step - loss: 0.2941 - auc: 0.8629 - val_loss: 1.5282 - val_auc: 0.7541\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.2926 - auc: 0.8558 - val_loss: 1.5270 - val_auc: 0.7520\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 66s 838ms/step - loss: 0.2756 - auc: 0.8689 - val_loss: 1.5337 - val_auc: 0.7536\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 66s 839ms/step - loss: 0.2601 - auc: 0.8687 - val_loss: 1.5186 - val_auc: 0.7569\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 66s 836ms/step - loss: 0.2739 - auc: 0.8727 - val_loss: 1.5270 - val_auc: 0.7557\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 66s 837ms/step - loss: 0.2765 - auc: 0.8530 - val_loss: 1.5307 - val_auc: 0.7555\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 66s 839ms/step - loss: 0.2759 - auc: 0.8678 - val_loss: 1.5261 - val_auc: 0.7557\n",
            "#### FOLD 1 without TTA VAL_AUC = 0.806\n",
            "[1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model7 has been loaded \n",
            "Epoch 1/50\n",
            "79/79 [==============================] - 844s 1s/step - loss: 1.3722 - auc: 0.5138 - val_loss: 1.4101 - val_auc: 0.5051\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 1.2838 - auc: 0.5543 - val_loss: 1.2528 - val_auc: 0.6223\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 1.1004 - auc: 0.6217 - val_loss: 1.0653 - val_auc: 0.7012\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 1.0198 - auc: 0.6639 - val_loss: 0.9947 - val_auc: 0.7359\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 1.0212 - auc: 0.6696 - val_loss: 0.9264 - val_auc: 0.7637\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 67s 852ms/step - loss: 0.9936 - auc: 0.6833 - val_loss: 0.9885 - val_auc: 0.7608\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.9624 - auc: 0.7012 - val_loss: 0.9270 - val_auc: 0.7784\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 67s 848ms/step - loss: 0.9621 - auc: 0.7050 - val_loss: 0.8863 - val_auc: 0.7901\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 67s 850ms/step - loss: 0.9256 - auc: 0.7140 - val_loss: 0.9434 - val_auc: 0.7832\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.9392 - auc: 0.7114 - val_loss: 1.0653 - val_auc: 0.7662\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.9163 - auc: 0.7243 - val_loss: 1.0361 - val_auc: 0.7660\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.8790 - auc: 0.7413 - val_loss: 0.9248 - val_auc: 0.7973\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.8677 - auc: 0.7448 - val_loss: 0.9563 - val_auc: 0.7851\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.8518 - auc: 0.7683 - val_loss: 0.9631 - val_auc: 0.7882\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 66s 839ms/step - loss: 0.8357 - auc: 0.7555 - val_loss: 1.0675 - val_auc: 0.7720\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.8181 - auc: 0.7604 - val_loss: 1.0172 - val_auc: 0.7835\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 66s 843ms/step - loss: 0.7690 - auc: 0.7890 - val_loss: 1.0708 - val_auc: 0.7603\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.7606 - auc: 0.7846 - val_loss: 1.0252 - val_auc: 0.7764\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.7434 - auc: 0.7842 - val_loss: 1.0335 - val_auc: 0.7788\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.7083 - auc: 0.7969 - val_loss: 1.0943 - val_auc: 0.7754\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.6651 - auc: 0.8104 - val_loss: 1.0829 - val_auc: 0.7732\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.6222 - auc: 0.8317 - val_loss: 1.1206 - val_auc: 0.7753\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.6123 - auc: 0.8333 - val_loss: 1.1415 - val_auc: 0.7674\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.5932 - auc: 0.8384 - val_loss: 1.3131 - val_auc: 0.7560\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 66s 843ms/step - loss: 0.5645 - auc: 0.8443 - val_loss: 1.2563 - val_auc: 0.7636\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 66s 843ms/step - loss: 0.5525 - auc: 0.8350 - val_loss: 1.2290 - val_auc: 0.7632\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.5172 - auc: 0.8364 - val_loss: 1.3157 - val_auc: 0.7564\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.5108 - auc: 0.8325 - val_loss: 1.2569 - val_auc: 0.7736\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 66s 839ms/step - loss: 0.4513 - auc: 0.8641 - val_loss: 1.3510 - val_auc: 0.7492\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 66s 843ms/step - loss: 0.4492 - auc: 0.8417 - val_loss: 1.2930 - val_auc: 0.7557\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.4098 - auc: 0.8720 - val_loss: 1.4344 - val_auc: 0.7502\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.4131 - auc: 0.8552 - val_loss: 1.3992 - val_auc: 0.7472\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.3942 - auc: 0.8555 - val_loss: 1.3742 - val_auc: 0.7508\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.3589 - auc: 0.8732 - val_loss: 1.3870 - val_auc: 0.7544\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.3361 - auc: 0.8758 - val_loss: 1.4756 - val_auc: 0.7433\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.3368 - auc: 0.8697 - val_loss: 1.3977 - val_auc: 0.7478\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.3351 - auc: 0.8747 - val_loss: 1.4238 - val_auc: 0.7503\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.3216 - auc: 0.8766 - val_loss: 1.4279 - val_auc: 0.7473\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.3079 - auc: 0.8816 - val_loss: 1.4518 - val_auc: 0.7501\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.2925 - auc: 0.8823 - val_loss: 1.4490 - val_auc: 0.7479\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.3044 - auc: 0.8731 - val_loss: 1.4636 - val_auc: 0.7418\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.3109 - auc: 0.8613 - val_loss: 1.4695 - val_auc: 0.7437\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.2975 - auc: 0.8720 - val_loss: 1.4915 - val_auc: 0.7369\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.3226 - auc: 0.8653 - val_loss: 1.4750 - val_auc: 0.7385\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.3242 - auc: 0.8541 - val_loss: 1.4640 - val_auc: 0.7404\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 66s 838ms/step - loss: 0.2947 - auc: 0.8743 - val_loss: 1.4637 - val_auc: 0.7409\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.2962 - auc: 0.8687 - val_loss: 1.4589 - val_auc: 0.7397\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.2871 - auc: 0.8800 - val_loss: 1.4660 - val_auc: 0.7401\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.3024 - auc: 0.8651 - val_loss: 1.4661 - val_auc: 0.7410\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.2959 - auc: 0.8710 - val_loss: 1.4657 - val_auc: 0.7399\n",
            "#### FOLD 2 without TTA VAL_AUC = 0.797\n",
            "[1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model7 has been loaded \n",
            "Epoch 1/50\n",
            "79/79 [==============================] - 850s 1s/step - loss: 1.3784 - auc: 0.5100 - val_loss: 1.3593 - val_auc: 0.5166\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 67s 848ms/step - loss: 1.2788 - auc: 0.5534 - val_loss: 1.1879 - val_auc: 0.6443\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 67s 850ms/step - loss: 1.0873 - auc: 0.6266 - val_loss: 1.1241 - val_auc: 0.6921\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 67s 849ms/step - loss: 1.0353 - auc: 0.6567 - val_loss: 1.0603 - val_auc: 0.7358\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.9829 - auc: 0.6811 - val_loss: 0.9407 - val_auc: 0.7679\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 67s 850ms/step - loss: 1.0000 - auc: 0.6960 - val_loss: 0.9036 - val_auc: 0.7787\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 67s 850ms/step - loss: 0.9584 - auc: 0.7203 - val_loss: 0.9564 - val_auc: 0.7760\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.9701 - auc: 0.7009 - val_loss: 0.9118 - val_auc: 0.7821\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.9262 - auc: 0.7178 - val_loss: 0.9312 - val_auc: 0.7802\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.9049 - auc: 0.7238 - val_loss: 0.9409 - val_auc: 0.7815\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.9130 - auc: 0.7274 - val_loss: 1.0531 - val_auc: 0.7480\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.8813 - auc: 0.7461 - val_loss: 0.9377 - val_auc: 0.7886\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 67s 850ms/step - loss: 0.8590 - auc: 0.7478 - val_loss: 0.9687 - val_auc: 0.7934\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 67s 848ms/step - loss: 0.8410 - auc: 0.7699 - val_loss: 0.9726 - val_auc: 0.7873\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.7932 - auc: 0.7659 - val_loss: 1.0271 - val_auc: 0.7837\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.7777 - auc: 0.7723 - val_loss: 1.1549 - val_auc: 0.7680\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.7637 - auc: 0.7894 - val_loss: 1.0978 - val_auc: 0.7645\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.7405 - auc: 0.7889 - val_loss: 1.0498 - val_auc: 0.7794\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.7060 - auc: 0.7923 - val_loss: 1.1372 - val_auc: 0.7643\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 67s 848ms/step - loss: 0.6715 - auc: 0.8115 - val_loss: 1.2623 - val_auc: 0.7533\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.6765 - auc: 0.8111 - val_loss: 1.1389 - val_auc: 0.7565\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.6236 - auc: 0.8246 - val_loss: 1.2005 - val_auc: 0.7597\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.5834 - auc: 0.8350 - val_loss: 1.2980 - val_auc: 0.7431\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.5751 - auc: 0.8368 - val_loss: 1.2177 - val_auc: 0.7623\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.5246 - auc: 0.8556 - val_loss: 1.3475 - val_auc: 0.7706\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.5306 - auc: 0.8408 - val_loss: 1.2889 - val_auc: 0.7566\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.4935 - auc: 0.8440 - val_loss: 1.4132 - val_auc: 0.7432\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 67s 848ms/step - loss: 0.4806 - auc: 0.8349 - val_loss: 1.3695 - val_auc: 0.7487\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.4219 - auc: 0.8740 - val_loss: 1.4888 - val_auc: 0.7440\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.4268 - auc: 0.8474 - val_loss: 1.3905 - val_auc: 0.7538\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.4011 - auc: 0.8687 - val_loss: 1.4137 - val_auc: 0.7547\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 66s 843ms/step - loss: 0.4008 - auc: 0.8466 - val_loss: 1.3973 - val_auc: 0.7363\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.3684 - auc: 0.8628 - val_loss: 1.4550 - val_auc: 0.7456\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.3401 - auc: 0.8759 - val_loss: 1.4389 - val_auc: 0.7518\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 67s 848ms/step - loss: 0.3211 - auc: 0.8820 - val_loss: 1.4894 - val_auc: 0.7491\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.3153 - auc: 0.8692 - val_loss: 1.4458 - val_auc: 0.7468\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.2998 - auc: 0.8791 - val_loss: 1.5049 - val_auc: 0.7496\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.3030 - auc: 0.8770 - val_loss: 1.5694 - val_auc: 0.7436\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 67s 851ms/step - loss: 0.2765 - auc: 0.8858 - val_loss: 1.5477 - val_auc: 0.7462\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.2791 - auc: 0.8810 - val_loss: 1.5496 - val_auc: 0.7454\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.2829 - auc: 0.8773 - val_loss: 1.5199 - val_auc: 0.7444\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.2887 - auc: 0.8682 - val_loss: 1.5290 - val_auc: 0.7441\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.2854 - auc: 0.8776 - val_loss: 1.5191 - val_auc: 0.7455\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.2923 - auc: 0.8643 - val_loss: 1.4973 - val_auc: 0.7433\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.2895 - auc: 0.8566 - val_loss: 1.4944 - val_auc: 0.7481\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 67s 842ms/step - loss: 0.2812 - auc: 0.8710 - val_loss: 1.4993 - val_auc: 0.7464\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.2747 - auc: 0.8702 - val_loss: 1.5047 - val_auc: 0.7472\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.2596 - auc: 0.8817 - val_loss: 1.5061 - val_auc: 0.7467\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.2886 - auc: 0.8638 - val_loss: 1.5043 - val_auc: 0.7450\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.2795 - auc: 0.8699 - val_loss: 1.5038 - val_auc: 0.7473\n",
            "#### FOLD 3 without TTA VAL_AUC = 0.793\n",
            "[1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model7 has been loaded \n",
            "Epoch 1/50\n",
            "79/79 [==============================] - 872s 1s/step - loss: 1.4017 - auc: 0.4978 - val_loss: 1.4207 - val_auc: 0.5751\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 71s 902ms/step - loss: 1.2955 - auc: 0.5564 - val_loss: 1.2364 - val_auc: 0.6346\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 1.1029 - auc: 0.6207 - val_loss: 1.0260 - val_auc: 0.7080\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 1.0084 - auc: 0.6659 - val_loss: 1.0014 - val_auc: 0.7504\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.9974 - auc: 0.6685 - val_loss: 0.9163 - val_auc: 0.7729\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 67s 850ms/step - loss: 0.9980 - auc: 0.6785 - val_loss: 0.9136 - val_auc: 0.7817\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 67s 849ms/step - loss: 0.9586 - auc: 0.7082 - val_loss: 0.9109 - val_auc: 0.7925\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.9502 - auc: 0.7071 - val_loss: 0.8972 - val_auc: 0.8029\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.9519 - auc: 0.7082 - val_loss: 0.9684 - val_auc: 0.8002\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.9095 - auc: 0.7238 - val_loss: 0.8574 - val_auc: 0.8033\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 67s 848ms/step - loss: 0.8816 - auc: 0.7274 - val_loss: 0.9766 - val_auc: 0.8015\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.8917 - auc: 0.7401 - val_loss: 0.9083 - val_auc: 0.7910\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.8607 - auc: 0.7449 - val_loss: 0.9412 - val_auc: 0.8006\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.8277 - auc: 0.7643 - val_loss: 0.9512 - val_auc: 0.7892\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.8238 - auc: 0.7617 - val_loss: 1.0622 - val_auc: 0.7950\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.8151 - auc: 0.7606 - val_loss: 1.0763 - val_auc: 0.7944\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.7900 - auc: 0.7762 - val_loss: 0.9774 - val_auc: 0.7957\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.7443 - auc: 0.7855 - val_loss: 1.0619 - val_auc: 0.7831\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.7360 - auc: 0.7841 - val_loss: 1.0739 - val_auc: 0.7956\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.6852 - auc: 0.7973 - val_loss: 1.0613 - val_auc: 0.7806\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.6696 - auc: 0.8125 - val_loss: 1.0952 - val_auc: 0.7817\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.6283 - auc: 0.8205 - val_loss: 1.1835 - val_auc: 0.7619\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.6114 - auc: 0.8355 - val_loss: 1.2132 - val_auc: 0.7651\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.5614 - auc: 0.8321 - val_loss: 1.1896 - val_auc: 0.7642\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 67s 842ms/step - loss: 0.5256 - auc: 0.8436 - val_loss: 1.3186 - val_auc: 0.7567\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.5294 - auc: 0.8391 - val_loss: 1.3272 - val_auc: 0.7574\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 66s 838ms/step - loss: 0.5137 - auc: 0.8408 - val_loss: 1.2591 - val_auc: 0.7764\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.4876 - auc: 0.8373 - val_loss: 1.3221 - val_auc: 0.7746\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.4229 - auc: 0.8636 - val_loss: 1.2863 - val_auc: 0.7663\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.4481 - auc: 0.8382 - val_loss: 1.3250 - val_auc: 0.7619\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.3898 - auc: 0.8689 - val_loss: 1.4735 - val_auc: 0.7505\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.3988 - auc: 0.8479 - val_loss: 1.3980 - val_auc: 0.7617\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 67s 842ms/step - loss: 0.3432 - auc: 0.8611 - val_loss: 1.4033 - val_auc: 0.7584\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.3455 - auc: 0.8713 - val_loss: 1.4263 - val_auc: 0.7623\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.3138 - auc: 0.8746 - val_loss: 1.4595 - val_auc: 0.7540\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.3294 - auc: 0.8618 - val_loss: 1.4503 - val_auc: 0.7567\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.3083 - auc: 0.8727 - val_loss: 1.4500 - val_auc: 0.7588\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.2968 - auc: 0.8665 - val_loss: 1.4697 - val_auc: 0.7591\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.2685 - auc: 0.8806 - val_loss: 1.4875 - val_auc: 0.7561\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.2713 - auc: 0.8848 - val_loss: 1.4922 - val_auc: 0.7535\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.2760 - auc: 0.8779 - val_loss: 1.5154 - val_auc: 0.7551\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.2815 - auc: 0.8674 - val_loss: 1.5109 - val_auc: 0.7577\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.2642 - auc: 0.8733 - val_loss: 1.5121 - val_auc: 0.7564\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.2838 - auc: 0.8621 - val_loss: 1.5104 - val_auc: 0.7570\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.2955 - auc: 0.8506 - val_loss: 1.4973 - val_auc: 0.7577\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.2608 - auc: 0.8684 - val_loss: 1.4954 - val_auc: 0.7583\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.2645 - auc: 0.8664 - val_loss: 1.5026 - val_auc: 0.7557\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.2554 - auc: 0.8683 - val_loss: 1.5061 - val_auc: 0.7564\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.2661 - auc: 0.8655 - val_loss: 1.5099 - val_auc: 0.7556\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.2618 - auc: 0.8613 - val_loss: 1.5072 - val_auc: 0.7578\n",
            "#### FOLD 4 without TTA VAL_AUC = 0.803\n",
            "[1267, 1267, 1267, 1267]\n",
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model7 has been loaded \n",
            "Epoch 1/50\n",
            "79/79 [==============================] - 853s 1s/step - loss: 1.4291 - auc: 0.5133 - val_loss: 1.4276 - val_auc: 0.5779\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 67s 851ms/step - loss: 1.3001 - auc: 0.5421 - val_loss: 1.2051 - val_auc: 0.6330\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 1.1066 - auc: 0.6281 - val_loss: 1.0384 - val_auc: 0.7044\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 1.0465 - auc: 0.6533 - val_loss: 1.0593 - val_auc: 0.7243\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 1.0216 - auc: 0.6703 - val_loss: 0.9434 - val_auc: 0.7610\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 71s 902ms/step - loss: 0.9806 - auc: 0.6815 - val_loss: 0.9629 - val_auc: 0.7635\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 67s 849ms/step - loss: 0.9600 - auc: 0.7152 - val_loss: 0.9036 - val_auc: 0.7876\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.9531 - auc: 0.7014 - val_loss: 0.9002 - val_auc: 0.7915\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.9347 - auc: 0.7134 - val_loss: 0.9975 - val_auc: 0.7701\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.9297 - auc: 0.7205 - val_loss: 0.9313 - val_auc: 0.7950\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 67s 850ms/step - loss: 0.8945 - auc: 0.7272 - val_loss: 0.9331 - val_auc: 0.7881\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.9032 - auc: 0.7523 - val_loss: 0.9735 - val_auc: 0.7725\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.8602 - auc: 0.7450 - val_loss: 0.9255 - val_auc: 0.7912\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.8408 - auc: 0.7704 - val_loss: 0.9518 - val_auc: 0.7876\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.8377 - auc: 0.7560 - val_loss: 1.0400 - val_auc: 0.7725\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.8143 - auc: 0.7643 - val_loss: 0.9578 - val_auc: 0.7882\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.7882 - auc: 0.7828 - val_loss: 1.0379 - val_auc: 0.7717\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.7737 - auc: 0.7804 - val_loss: 1.0378 - val_auc: 0.7773\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.7562 - auc: 0.7822 - val_loss: 1.0653 - val_auc: 0.7859\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.7333 - auc: 0.7934 - val_loss: 1.0217 - val_auc: 0.7740\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.6806 - auc: 0.8148 - val_loss: 1.0556 - val_auc: 0.7873\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.6620 - auc: 0.8208 - val_loss: 1.1102 - val_auc: 0.7712\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 67s 848ms/step - loss: 0.6290 - auc: 0.8312 - val_loss: 1.1473 - val_auc: 0.7757\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.6074 - auc: 0.8241 - val_loss: 1.1930 - val_auc: 0.7654\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 67s 848ms/step - loss: 0.5630 - auc: 0.8498 - val_loss: 1.1709 - val_auc: 0.7730\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.5750 - auc: 0.8301 - val_loss: 1.1770 - val_auc: 0.7668\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.5467 - auc: 0.8377 - val_loss: 1.2035 - val_auc: 0.7675\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.5117 - auc: 0.8372 - val_loss: 1.2285 - val_auc: 0.7650\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.4734 - auc: 0.8643 - val_loss: 1.2095 - val_auc: 0.7791\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.4789 - auc: 0.8402 - val_loss: 1.2246 - val_auc: 0.7630\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.4123 - auc: 0.8676 - val_loss: 1.3263 - val_auc: 0.7628\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.4302 - auc: 0.8461 - val_loss: 1.3193 - val_auc: 0.7563\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 67s 842ms/step - loss: 0.4031 - auc: 0.8613 - val_loss: 1.3826 - val_auc: 0.7554\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.4015 - auc: 0.8691 - val_loss: 1.3004 - val_auc: 0.7663\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.3655 - auc: 0.8755 - val_loss: 1.3405 - val_auc: 0.7726\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.3452 - auc: 0.8697 - val_loss: 1.3976 - val_auc: 0.7573\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.3361 - auc: 0.8801 - val_loss: 1.3940 - val_auc: 0.7577\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 67s 849ms/step - loss: 0.3435 - auc: 0.8775 - val_loss: 1.3778 - val_auc: 0.7566\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 67s 850ms/step - loss: 0.3113 - auc: 0.8783 - val_loss: 1.4067 - val_auc: 0.7554\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 67s 847ms/step - loss: 0.3068 - auc: 0.8825 - val_loss: 1.3831 - val_auc: 0.7598\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.3239 - auc: 0.8771 - val_loss: 1.3709 - val_auc: 0.7591\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.3184 - auc: 0.8691 - val_loss: 1.3759 - val_auc: 0.7618\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 66s 840ms/step - loss: 0.3157 - auc: 0.8773 - val_loss: 1.3791 - val_auc: 0.7562\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 66s 842ms/step - loss: 0.3359 - auc: 0.8623 - val_loss: 1.3739 - val_auc: 0.7562\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.3433 - auc: 0.8543 - val_loss: 1.3688 - val_auc: 0.7537\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 66s 841ms/step - loss: 0.3015 - auc: 0.8747 - val_loss: 1.3858 - val_auc: 0.7560\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 67s 845ms/step - loss: 0.3171 - auc: 0.8692 - val_loss: 1.3812 - val_auc: 0.7570\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 67s 844ms/step - loss: 0.3032 - auc: 0.8763 - val_loss: 1.3882 - val_auc: 0.7545\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 67s 846ms/step - loss: 0.3188 - auc: 0.8636 - val_loss: 1.3821 - val_auc: 0.7543\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 67s 843ms/step - loss: 0.3070 - auc: 0.8702 - val_loss: 1.3809 - val_auc: 0.7543\n",
            "#### FOLD 5 without TTA VAL_AUC = 0.795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSXjYZ-Rewt-"
      },
      "source": [
        "#Inference B4512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eZByBYeuDMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "495698f5-7fc9-4250-ce80-243998f83fb3"
      },
      "source": [
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "test_gogo = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-07b08a23789b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_FILENAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_image_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_gogo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TEST_FILENAMES' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hCPkcNNNrPi",
        "outputId": "dc5859a9-e2a1-4aa7-cfee-a3d36289a60f"
      },
      "source": [
        "len(test_gogo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaX722tJhYXh",
        "outputId": "e822843b-c154-4cd5-ef92-308c2095089c"
      },
      "source": [
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "sub_names = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])\n",
        "sub_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['002a34c58c5b758217ed1f584ccbcfe9',\n",
              "       '004f33259ee4aef671c2b95d54e4be68',\n",
              "       '008bdde2af2462e86fd373a445d0f4cd', ...,\n",
              "       'ffaa288c8abca300974f043b57d81521',\n",
              "       'ffc441e0c8b7153844047483a577e7c3',\n",
              "       'ffccf1709d0081d122a1d1f9edbefdf1'], dtype='<U32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuMFk-cMhmly"
      },
      "source": [
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "6LOiSoo6hnfA",
        "outputId": "cb4d6f24-3fb7-4227-85da-d02609af2cce"
      },
      "source": [
        "df_total_sub_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002a34c58c5b758217ed1f584ccbcfe9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>004f33259ee4aef671c2b95d54e4be68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008bdde2af2462e86fd373a445d0f4cd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>009bc039326338823ca3aa84381f17f1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00a2145de1886cb9eb88869c85d74080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>ff91fb82429a27521bbec8569b041f02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>ff9fcc4087ed5e941209aa3fa948e364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>ffaa288c8abca300974f043b57d81521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>ffc441e0c8b7153844047483a577e7c3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>ffccf1709d0081d122a1d1f9edbefdf1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image_name\n",
              "0     002a34c58c5b758217ed1f584ccbcfe9\n",
              "1     004f33259ee4aef671c2b95d54e4be68\n",
              "2     008bdde2af2462e86fd373a445d0f4cd\n",
              "3     009bc039326338823ca3aa84381f17f1\n",
              "4     00a2145de1886cb9eb88869c85d74080\n",
              "...                                ...\n",
              "2995  ff91fb82429a27521bbec8569b041f02\n",
              "2996  ff9fcc4087ed5e941209aa3fa948e364\n",
              "2997  ffaa288c8abca300974f043b57d81521\n",
              "2998  ffc441e0c8b7153844047483a577e7c3\n",
              "2999  ffccf1709d0081d122a1d1f9edbefdf1\n",
              "\n",
              "[3000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "DvkmEybnhuxB",
        "outputId": "a9aa89a9-9785-4caf-d25f-9f91c82c5ed8"
      },
      "source": [
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub\n",
        "#df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_SUB.csv'),index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002a34c58c5b758217ed1f584ccbcfe9</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.002111</td>\n",
              "      <td>0.001013</td>\n",
              "      <td>0.000697</td>\n",
              "      <td>0.001526</td>\n",
              "      <td>0.002502</td>\n",
              "      <td>0.001551</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.001017</td>\n",
              "      <td>0.005805</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.001309</td>\n",
              "      <td>0.195280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>004f33259ee4aef671c2b95d54e4be68</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.002430</td>\n",
              "      <td>0.000818</td>\n",
              "      <td>0.000933</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>0.000899</td>\n",
              "      <td>0.001299</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.001937</td>\n",
              "      <td>0.001803</td>\n",
              "      <td>0.003263</td>\n",
              "      <td>0.000503</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>0.197328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008bdde2af2462e86fd373a445d0f4cd</td>\n",
              "      <td>0.174792</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>0.007077</td>\n",
              "      <td>0.122213</td>\n",
              "      <td>0.002034</td>\n",
              "      <td>0.004011</td>\n",
              "      <td>0.006038</td>\n",
              "      <td>0.022974</td>\n",
              "      <td>0.007495</td>\n",
              "      <td>0.016485</td>\n",
              "      <td>0.003327</td>\n",
              "      <td>0.023178</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>0.018443</td>\n",
              "      <td>0.033101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>009bc039326338823ca3aa84381f17f1</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>0.000667</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.000990</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.000758</td>\n",
              "      <td>0.000430</td>\n",
              "      <td>0.000802</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.199561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00a2145de1886cb9eb88869c85d74080</td>\n",
              "      <td>0.086371</td>\n",
              "      <td>0.000703</td>\n",
              "      <td>0.002839</td>\n",
              "      <td>0.140198</td>\n",
              "      <td>0.002009</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>0.002813</td>\n",
              "      <td>0.008863</td>\n",
              "      <td>0.003644</td>\n",
              "      <td>0.006245</td>\n",
              "      <td>0.003057</td>\n",
              "      <td>0.019245</td>\n",
              "      <td>0.001014</td>\n",
              "      <td>0.005706</td>\n",
              "      <td>0.062666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>ff91fb82429a27521bbec8569b041f02</td>\n",
              "      <td>0.169418</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.034280</td>\n",
              "      <td>0.107503</td>\n",
              "      <td>0.099559</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.036410</td>\n",
              "      <td>0.178246</td>\n",
              "      <td>0.184320</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>0.007016</td>\n",
              "      <td>0.037167</td>\n",
              "      <td>0.001567</td>\n",
              "      <td>0.069370</td>\n",
              "      <td>0.002304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>ff9fcc4087ed5e941209aa3fa948e364</td>\n",
              "      <td>0.195568</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.008906</td>\n",
              "      <td>0.118982</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.002094</td>\n",
              "      <td>0.002883</td>\n",
              "      <td>0.007362</td>\n",
              "      <td>0.006666</td>\n",
              "      <td>0.011426</td>\n",
              "      <td>0.005162</td>\n",
              "      <td>0.045798</td>\n",
              "      <td>0.000817</td>\n",
              "      <td>0.026318</td>\n",
              "      <td>0.010865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>ffaa288c8abca300974f043b57d81521</td>\n",
              "      <td>0.001954</td>\n",
              "      <td>0.002920</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>0.001406</td>\n",
              "      <td>0.004295</td>\n",
              "      <td>0.005929</td>\n",
              "      <td>0.011130</td>\n",
              "      <td>0.022830</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.125751</td>\n",
              "      <td>0.071830</td>\n",
              "      <td>0.002736</td>\n",
              "      <td>0.005590</td>\n",
              "      <td>0.162730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>ffc441e0c8b7153844047483a577e7c3</td>\n",
              "      <td>0.018895</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.021862</td>\n",
              "      <td>0.001242</td>\n",
              "      <td>0.000793</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>0.004114</td>\n",
              "      <td>0.002283</td>\n",
              "      <td>0.002916</td>\n",
              "      <td>0.001685</td>\n",
              "      <td>0.003270</td>\n",
              "      <td>0.000978</td>\n",
              "      <td>0.003354</td>\n",
              "      <td>0.163176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>ffccf1709d0081d122a1d1f9edbefdf1</td>\n",
              "      <td>0.145861</td>\n",
              "      <td>0.095181</td>\n",
              "      <td>0.034802</td>\n",
              "      <td>0.004557</td>\n",
              "      <td>0.008672</td>\n",
              "      <td>0.045669</td>\n",
              "      <td>0.050831</td>\n",
              "      <td>0.070977</td>\n",
              "      <td>0.008625</td>\n",
              "      <td>0.026598</td>\n",
              "      <td>0.189738</td>\n",
              "      <td>0.199768</td>\n",
              "      <td>0.004524</td>\n",
              "      <td>0.194726</td>\n",
              "      <td>0.000403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image_name    class0  ...   class13   class14\n",
              "0     002a34c58c5b758217ed1f584ccbcfe9  0.000875  ...  0.001309  0.195280\n",
              "1     004f33259ee4aef671c2b95d54e4be68  0.001957  ...  0.000784  0.197328\n",
              "2     008bdde2af2462e86fd373a445d0f4cd  0.174792  ...  0.018443  0.033101\n",
              "3     009bc039326338823ca3aa84381f17f1  0.000378  ...  0.000440  0.199561\n",
              "4     00a2145de1886cb9eb88869c85d74080  0.086371  ...  0.005706  0.062666\n",
              "...                                ...       ...  ...       ...       ...\n",
              "2995  ff91fb82429a27521bbec8569b041f02  0.169418  ...  0.069370  0.002304\n",
              "2996  ff9fcc4087ed5e941209aa3fa948e364  0.195568  ...  0.026318  0.010865\n",
              "2997  ffaa288c8abca300974f043b57d81521  0.001954  ...  0.005590  0.162730\n",
              "2998  ffc441e0c8b7153844047483a577e7c3  0.018895  ...  0.003354  0.163176\n",
              "2999  ffccf1709d0081d122a1d1f9edbefdf1  0.145861  ...  0.194726  0.000403\n",
              "\n",
              "[3000 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HAnbQUN5qXv"
      },
      "source": [
        "TTA = True"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "id": "jPmlTjd8exx8",
        "outputId": "0c1ba29a-04f2-4e83-825b-6f3d56bf4429"
      },
      "source": [
        "#model prediction\n",
        "from sklearn.metrics import average_precision_score\n",
        "TEST_FILENAMES = FILENAMES\n",
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "sub_names = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])\n",
        "\n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [];\n",
        "history_list = []; normal_oof_pred = []; pred_max = []; pred_probs = []; pred_sub_probs = [];\n",
        "sub_pred = [];\n",
        "pred_sub_prob = np.zeros(shape=(count_data_items(TEST_FILENAMES), CFG.NUMBER_OF_CLASSES))\n",
        "def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'imagenet', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x0 = tf.keras.layers.Dropout(0.5)(x0)\n",
        "        x0 = tf.keras.layers.Dense(64, activation='relu')(x0)\n",
        "        x = tf.keras.layers.Dense(CFG.NUMBER_OF_CLASSES, activation='softmax', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=500, warmup_proportion=0.1, min_lr=2e-6)\n",
        "        \n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        #opt =tf.keras.optimizers.Adam(learning_rate=CFG.LEARNING_RATE)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'categorical_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = CFG.N_FOLDS, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        "    #val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    seed_everything(SEED)\n",
        "    model.load_weights(os.path.join(ROOT_PATH, f\"COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"))\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False                   \n",
        "    \n",
        "    ct_valid = count_data_items(VALIDATION_FILENAMES)\n",
        "    \n",
        "    if TTA:\n",
        "########## TTA\n",
        "    ## GET NORMAL OOF\n",
        "        for i in range(CFG.TTA_NUM+1):\n",
        "            if i == 0:\n",
        "                ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "                pred_prob = model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 1)\n",
        "            else:\n",
        "                ds_valid = get_dataset_for_tta(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "                pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 1)\n",
        "\n",
        "########## NO TTA\n",
        "    else:\n",
        "        ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "        pred_prob = model.predict(ds_valid, verbose=1)\n",
        "    \n",
        "    pred_probs.append(pred_prob)\n",
        "\n",
        "\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
        "    oof_folds.append(np.ones_like(oof_tar[-1], dtype='int8')*fold)\n",
        "    ds = get_dataset(VALIDATION_FILENAMES, labeled=False, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds.unbatch())]))\n",
        "    \n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=False)\n",
        "    pred_sub_prob += model.predict(ds_test, verbose=1) / CFG.N_FOLDS\n",
        "    #pred_sub_probs.append(pred_sub_prob)\n",
        "\n",
        "    #ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "    #sub_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())]))\n",
        "\n",
        "\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "#total_sub_names = np.concatenate(sub_names)\n",
        "#total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(CFG.NUMBER_OF_CLASSES)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'(sub)COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.csv'),index=False)\n",
        "print(df_sub)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(CFG.NUMBER_OF_CLASSES)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(CFG.NUMBER_OF_CLASSES)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'(oof)COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.csv.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "ind_class_ap = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "    ind_class_ap.append(average_precision_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"total map:\",np.array(ind_class_ap).mean()*2/3)\n",
        "#print(f\"class {CFG.NUMBER_OF_CLASSES} auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "WARNING:tensorflow:TPU system grpc://10.17.99.122:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.17.99.122:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "Efficient Model7 has been loaded \n",
            "[1267]\n",
            "20/20 [==============================] - 28s 190ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-1e97ae47dd9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mpred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTTA_NUM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mds_valid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_dataset_for_tta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVALIDATION_FILENAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabeled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeated\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mpred_prob\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTTA_NUM\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-22b8021e6d21>\u001b[0m in \u001b[0;36mget_dataset_for_tta\u001b[0;34m(FILENAMES, labeled, ordered, repeated, augment, validation)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecode_tr_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdecode_val_image_for_tta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAUTO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1930\u001b[0m           \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m           \u001b[0mdeterministic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m           preserve_cardinality=True)\n\u001b[0m\u001b[1;32m   1933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4524\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4525\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4526\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4527\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4528\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deterministic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3710\u001b[0m     \u001b[0mresource_tracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceTracker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3711\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3712\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3713\u001b[0m       \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3714\u001b[0m       \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3133\u001b[0m     \"\"\"\n\u001b[1;32m   3134\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3135\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3136\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3098\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3099\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3100\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3101\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3102\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3685\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3686\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3687\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3688\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3615\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3616\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3617\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3618\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3619\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: in user code:\n\n    <ipython-input-53-22b8021e6d21>:220 None  *\n        lambda image, label : (decode_val_image_for_tta(image), label), num_parallel_calls = AUTO)\n    <ipython-input-53-22b8021e6d21>:79 decode_val_image_for_tta  *\n        image = randaugtta(image)\n\n    NameError: name 'randaugtta' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "gabhdDkw7fqP",
        "outputId": "258f646b-7960-4f92-d0bc-93885be3f2e2"
      },
      "source": [
        "df_oof[['target0','target1','target2','target3']]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c3a3f293f</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044777</td>\n",
              "      <td>0.229694</td>\n",
              "      <td>0.041547</td>\n",
              "      <td>0.683982</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00b0891276a3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.070826</td>\n",
              "      <td>0.166704</td>\n",
              "      <td>0.025137</td>\n",
              "      <td>0.737333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00e37a390f0f</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.075357</td>\n",
              "      <td>0.003436</td>\n",
              "      <td>0.913689</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00e3a7e91a34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0d4d6acc9ed3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6329</th>\n",
              "      <td>fece1740823c</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.296112</td>\n",
              "      <td>0.276682</td>\n",
              "      <td>0.046547</td>\n",
              "      <td>0.380660</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6330</th>\n",
              "      <td>ff23167d20b4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.045188</td>\n",
              "      <td>0.237923</td>\n",
              "      <td>0.060011</td>\n",
              "      <td>0.656877</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6331</th>\n",
              "      <td>ff322f8e36c4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.877586</td>\n",
              "      <td>0.057183</td>\n",
              "      <td>0.005390</td>\n",
              "      <td>0.059840</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6332</th>\n",
              "      <td>ff9f10a24c27</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.949183</td>\n",
              "      <td>0.023384</td>\n",
              "      <td>0.004172</td>\n",
              "      <td>0.023261</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6333</th>\n",
              "      <td>ffbeafe30b77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.293803</td>\n",
              "      <td>0.321225</td>\n",
              "      <td>0.096799</td>\n",
              "      <td>0.288172</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6334 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        image_name  target0  target1  ...    class2    class3  fold\n",
              "0     000c3a3f293f      1.0      0.0  ...  0.041547  0.683982     0\n",
              "1     00b0891276a3      0.0      0.0  ...  0.025137  0.737333     0\n",
              "2     00e37a390f0f      0.0      0.0  ...  0.003436  0.913689     0\n",
              "3     00e3a7e91a34      1.0      0.0  ...  0.049463  0.544704     0\n",
              "4     0d4d6acc9ed3      1.0      0.0  ...  0.049463  0.544704     0\n",
              "...            ...      ...      ...  ...       ...       ...   ...\n",
              "6329  fece1740823c      0.0      0.0  ...  0.046547  0.380660     4\n",
              "6330  ff23167d20b4      0.0      0.0  ...  0.060011  0.656877     4\n",
              "6331  ff322f8e36c4      0.0      0.0  ...  0.005390  0.059840     4\n",
              "6332  ff9f10a24c27      1.0      0.0  ...  0.004172  0.023261     4\n",
              "6333  ffbeafe30b77      0.0      0.0  ...  0.096799  0.288172     4\n",
              "\n",
              "[6334 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "TFQiTe-u6CCx",
        "outputId": "393f346e-4ed8-4575-f56c-2eb5579d1d71"
      },
      "source": [
        "ind_class_roc = []\n",
        "ind_class_ap = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "    ind_class_ap.append(average_precision_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"total map:\",np.array(ind_class_ap).mean()*2/3)\n",
        "#print(f\"class {CFG.NUMBER_OF_CLASSES} auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total auc: 0.7926285606178927\n",
            "total map: 0.3519535713592532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c3a3f293f</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044777</td>\n",
              "      <td>0.229694</td>\n",
              "      <td>0.041547</td>\n",
              "      <td>0.683982</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00b0891276a3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.070826</td>\n",
              "      <td>0.166704</td>\n",
              "      <td>0.025137</td>\n",
              "      <td>0.737333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00e37a390f0f</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.075357</td>\n",
              "      <td>0.003436</td>\n",
              "      <td>0.913689</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00e3a7e91a34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0d4d6acc9ed3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_name  target0  target1  target2  ...    class1    class2    class3  fold\n",
              "0  000c3a3f293f      1.0      0.0      0.0  ...  0.229694  0.041547  0.683982     0\n",
              "1  00b0891276a3      0.0      0.0      0.0  ...  0.166704  0.025137  0.737333     0\n",
              "2  00e37a390f0f      0.0      0.0      0.0  ...  0.075357  0.003436  0.913689     0\n",
              "3  00e3a7e91a34      1.0      0.0      0.0  ...  0.262778  0.049463  0.544704     0\n",
              "4  0d4d6acc9ed3      1.0      0.0      0.0  ...  0.262778  0.049463  0.544704     0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}
