{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(NOTTA_map0.351)(김웅곤)(TPU-Effnet-B7-512)Covid19-StudyBaseLine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPItazkaRXZN2ihJl0NuDi7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimwoonggon/SIIM-COVID19-KAGGLE/blob/main/(NOTTA_map0_351)(%EA%B9%80%EC%9B%85%EA%B3%A4)(TPU_Effnet_B7_512)Covid19_StudyBaseLine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhbJWFGLTJ9A",
        "outputId": "d741e25f-4b11-4b9f-f97b-805db66ab5e6"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU_vL8ic3HcZ",
        "outputId": "24c22fe8-cc3e-4912-aa90-c31f14f1a3c8"
      },
      "source": [
        "#!pip install tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0\n",
        "#!pip install -U tensorflow-addons==0.9.1\n",
        "!pip install -U tensorflow-addons\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import requests\n",
        "import os\n",
        "resp = requests.post(\"http://{}:8475/requestversion/{}\".format(os.environ[\"COLAB_TPU_ADDR\"].split(\":\")[0], tf.__version__))\n",
        "if resp.status_code != 200:\n",
        "  print(\"Failed to switch the TPU to TF {}\".format(version))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 5.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xX204k2Ktd"
      },
      "source": [
        "!pip install -q efficientnet >> /dev/null"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFPVid4aN0du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669d6708-49db-4b7c-f3fc-8f24ae5ee74d"
      },
      "source": [
        "import random, re, math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf, tensorflow.keras.backend as K\n",
        "!pip install gcsfs #gcp 파일 로드\n",
        "#from kaggle_datasets import KaggleDatasets\n",
        "from tensorflow.data.experimental import AUTOTUNE\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "import operator\n",
        "import gc\n",
        "import pathlib\n",
        "from scipy import spatial\n",
        "import cv2\n",
        "import functools"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/11/30/306bcaadd0145f55934202c77215e26e73b4c3d81fbdac587d26af38a2ad/gcsfs-2021.6.1-py2.py3-none-any.whl\n",
            "Collecting fsspec==2021.06.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/3a/666e63625a19883ae8e1674099e631f9737bd5478c4790e5ad49c5ac5261/fsspec-2021.6.1-py3-none-any.whl (115kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.23.0)\n",
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 9.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.31.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 20.5MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 25.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.7.4.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (57.0.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.1)\n",
            "Installing collected packages: fsspec, multidict, yarl, async-timeout, aiohttp, gcsfs\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.6.1 gcsfs-2021.6.1 multidict-5.1.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NERnp6GCrxgr"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37CFiVVS4Q82",
        "outputId": "6b336ab4-22d5-4a9b-e15c-3e708e807509"
      },
      "source": [
        "DEVICE = \"TPU\"\n",
        "if DEVICE == \"TPU\":\n",
        "    print(\"connecting to TPU...\")\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        print(\"Could not connect to TPU\")\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        try:\n",
        "            print(\"initializing  TPU ...\")\n",
        "            tf.config.experimental_connect_to_cluster(tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "            print(\"TPU initialized\")\n",
        "        except:\n",
        "            print(\"failed to initialize TPU\")\n",
        "    else:\n",
        "        DEVICE = \"GPU\"\n",
        "\n",
        "if DEVICE != \"TPU\":\n",
        "    print(\"Using default strategy for CPU and single GPU\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "if DEVICE == \"GPU\":\n",
        "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "    \n",
        "\n",
        "AUTO     = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "connecting to TPU...\n",
            "Running on TPU  grpc://10.103.110.98:8470\n",
            "initializing  TPU ...\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU initialized\n",
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Ylvljm1eIu",
        "outputId": "f4c8bd4b-28de-48f9-c95f-a4f64cbc7a52"
      },
      "source": [
        "MIXED_PRECISION = True\n",
        "XLA_ACCELERATE = True\n",
        " \n",
        "if MIXED_PRECISION:\n",
        "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "    if tpu: \n",
        "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
        "    else: \n",
        "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
        "    mixed_precision.set_policy(policy)\n",
        "    print('Mixed precision enabled')\n",
        " \n",
        "if XLA_ACCELERATE:\n",
        "    tf.config.optimizer.set_jit(True)\n",
        "    print('Accelerated Linear Algebra enabled')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mixed precision enabled\n",
            "Accelerated Linear Algebra enabled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quqZy4Kipt7v"
      },
      "source": [
        "class CFG:\n",
        "    StudyOrTwoClasses = \"study\"\n",
        "    WIDTH = 1024\n",
        "    HEIGHT = 1024\n",
        "    OBJ_WIDTH = 512\n",
        "    OBJ_HEIGHT = 512\n",
        "    MEAN = (0.485, 0.456, 0.406)\n",
        "    STD = (0.229, 0.224, 0.225)\n",
        "    CHANNELS = 3\n",
        "    \n",
        "    REPLICAS = 8\n",
        "    EPOCHS = 20\n",
        "    BATCH_SIZE = 8 * REPLICAS\n",
        "    AUG_BATCH = BATCH_SIZE\n",
        "    \n",
        "    LEARNING_RATE = 9e-5 * REPLICAS\n",
        "    \n",
        "    NUMBER_OF_CLASSES = 4\n",
        "    RANDAUG_NUM = 2\n",
        "    RANDAUG_MAGNITUDE = 15\n",
        "    N_FOLDS = 5\n",
        " \n",
        "    NET = 7\n",
        "    TTA_NUM = 4\n",
        "    SEED = 100\n",
        "    GCS_PATH = 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14'\n",
        "    ROOT_PATH = 'gdrive/My Drive/Colab Notebooks/KAGGLE_COVID19'\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qXd8pFJ1fmR",
        "outputId": "2cba9a7b-9e4f-49b0-fd29-99d22bce6492"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import efficientnet.tfkeras as efn\n",
        "import tensorflow.keras.applications as apl\n",
        "# import EfficientNetB0\n",
        "# Configuration\n",
        "effnets = [efn.EfficientNetB0,efn.EfficientNetB1,efn.EfficientNetB2,efn.EfficientNetB3,efn.EfficientNetB4,efn.EfficientNetB5,efn.EfficientNetB6,efn.EfficientNetB7]\n",
        "#effnets = [apl.EfficientNetB0,apl.EfficientNetB1,apl.EfficientNetB2,apl.EfficientNetB3,apl.EfficientNetB4,apl.EfficientNetB5,apl.EfficientNetB6,apl.EfficientNetB7]\n",
        "TTA_NUM = CFG.TTA_NUM\n",
        "TOTALWIDTH = CFG.WIDTH\n",
        "TOTALHEIGHT = CFG.HEIGHT\n",
        "HEIGHT = CFG.OBJ_HEIGHT\n",
        "WIDTH = CFG.OBJ_WIDTH\n",
        "IMAGE_SIZE = [HEIGHT, WIDTH]\n",
        "NET = CFG.NET\n",
        "BATCH_SIZE = CFG.BATCH_SIZE\n",
        "AUG_BATCH = BATCH_SIZE\n",
        "CHANNELS = CFG.CHANNELS\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        " \n",
        "GCS_PATH = CFG.GCS_PATH\n",
        "ROOT_PATH = CFG.ROOT_PATH\n",
        "EPOCHS = CFG.EPOCHS\n",
        "SEED = CFG.SEED\n",
        "LEARNING_RATE = CFG.LEARNING_RATE\n",
        "NUMBER_OF_CLASSES = CFG.NUMBER_OF_CLASSES\n",
        " \n",
        "#class_weight = CFG.CLASS_WEIGHT\n",
        " \n",
        "IMAGE_MEAN = CFG.MEAN\n",
        "IMAGE_STD = CFG.STD \n",
        "FILENAMES = tf.io.gfile.glob(CFG.GCS_PATH+f\"/{CFG.StudyOrTwoClasses}_train*\")\n",
        "#TEST_FILENAMES = tf.io.gfile.glob(CFG.GCS_PATH+\"/test*\")\n",
        "print(FILENAMES)\n",
        "#print(TEST_FILENAMES)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14/study_train00-1267.tfrec', 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14/study_train01-1267.tfrec', 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14/study_train02-1267.tfrec', 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14/study_train03-1267.tfrec', 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14/study_train04-1266.tfrec']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SOJUTcaXH2a",
        "outputId": "3cd96973-6274-4383-f738-a55a228f2c52"
      },
      "source": [
        "test_image = tf.cast(tf.random.uniform(shape=(1024,1024,3),minval = 0,maxval = 255,dtype=tf.int32), dtype=tf.uint8)\n",
        " \n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from tensorflow_addons.image.utils import to_4D_image, from_4D_image \n",
        "import inspect\n",
        "import math\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#from tensorflow.contrib import image as contrib_image\n",
        "#from tensorflow.contrib import training as contrib_training\n",
        "def blend(image1, image2, factor):\n",
        "  \"\"\"Blend image1 and image2 using 'factor'.\n",
        "  Factor can be above 0.0.  A value of 0.0 means only image1 is used.\n",
        "  A value of 1.0 means only image2 is used.  A value between 0.0 and\n",
        "  1.0 means we linearly interpolate the pixel values between the two\n",
        "  images.  A value greater than 1.0 \"extrapolates\" the difference\n",
        "  between the two pixel values, and we clip the results to values\n",
        "  between 0 and 255.\n",
        "  Args:\n",
        "    image1: An image Tensor of type uint8.\n",
        "    image2: An image Tensor of type uint8.\n",
        "    factor: A floating point value above 0.0.\n",
        "  Returns:\n",
        "    A blended image Tensor of type uint8.\n",
        "  \"\"\"\n",
        "  if factor == 0.0:\n",
        "    return tf.convert_to_tensor(image1)\n",
        "  if factor == 1.0:\n",
        "    return tf.convert_to_tensor(image2)\n",
        " \n",
        "  image1 = tf.cast(image1, dtype=tf.float32)\n",
        "  image2 = tf.cast(image2, dtype=tf.float32)\n",
        " \n",
        "  difference = image2 - image1\n",
        "  scaled = factor * difference\n",
        " \n",
        "  # Do addition in float.\n",
        "  temp = tf.cast(image1, dtype=tf.float32) + scaled\n",
        " \n",
        "  # Interpolate\n",
        "  if factor > 0.0 and factor < 1.0:\n",
        "    # Interpolation means we always stay within 0 and 255.\n",
        "    return tf.cast(temp, tf.uint8)\n",
        " \n",
        "  # Extrapolate:\n",
        "  #\n",
        "  # We need to clip and then cast.\n",
        "  return tf.cast(tf.clip_by_value(temp, 0.0, 255.0), tf.uint8)\n",
        "def Identity(image, _):\n",
        "    return image\n",
        "#Identity(test_image, 3)\n",
        "def AutoContrast(image, _):\n",
        "  \"\"\"Implements Autocontrast function from PIL using TF ops.\n",
        "  Args:\n",
        "    image: A 3D uint8 tensor.\n",
        "  Returns:\n",
        "    The image after it has had autocontrast applied to it and will be of type\n",
        "    uint8.\n",
        "  \"\"\"\n",
        " \n",
        "  def scale_channel(image):\n",
        "    \"\"\"Scale the 2D image using the autocontrast rule.\"\"\"\n",
        "    # A possibly cheaper version can be done using cumsum/unique_with_counts\n",
        "    # over the histogram values, rather than iterating over the entire image.\n",
        "    # to compute mins and maxes.\n",
        "    lo = tf.cast(tf.reduce_min(image), dtype = tf.float32)\n",
        "    hi = tf.cast(tf.reduce_max(image), dtype = tf.float32)\n",
        " \n",
        "    # Scale the image, making the lowest value 0 and the highest value 255.\n",
        "    def scale_values(im):\n",
        "        scale = 255.0 / (hi - lo)\n",
        "        offset = -lo * scale\n",
        "        im = tf.cast(im, dtype=tf.float32) * scale + offset\n",
        "        im = tf.clip_by_value(im, 0.0, 255.0)\n",
        "        return tf.cast(im, tf.uint8)\n",
        " \n",
        "    result = tf.cond(hi > lo, lambda: scale_values(image), lambda: image)\n",
        "    return result\n",
        " \n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image[:, :, 0])\n",
        "  s2 = scale_channel(image[:, :, 1])\n",
        "  s3 = scale_channel(image[:, :, 2])\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        " \n",
        "AutoContrast(test_image, 3)\n",
        "def Equalize(image, _):\n",
        "  \"\"\"Implements Equalize function from PIL using TF ops.\"\"\"\n",
        "  def scale_channel(im, c):\n",
        "    \"\"\"Scale the data in the channel to implement equalize.\"\"\"\n",
        "    im = tf.cast(im[:, :, c], tf.int32)\n",
        "    # Compute the histogram of the image channel.\n",
        "    histo = tf.histogram_fixed_width(im, [0, 255], nbins=256)\n",
        " \n",
        "    # For the purposes of computing the step, filter out the nonzeros.\n",
        "    nonzero = tf.where(tf.not_equal(histo, 0))\n",
        "    nonzero_histo = tf.reshape(tf.gather(histo, nonzero), [-1])\n",
        "    step = (tf.reduce_sum(nonzero_histo) - nonzero_histo[-1]) // 255\n",
        " \n",
        "    def build_lut(histo, step):\n",
        "      # Compute the cumulative sum, shifting by step // 2\n",
        "      # and then normalization by step.\n",
        "      lut = (tf.cumsum(histo) + (step // 2)) // step\n",
        "      # Shift lut, prepending with 0.\n",
        "      lut = tf.concat([[0], lut[:-1]], 0)\n",
        "      # Clip the counts to be in range.  This is done\n",
        "      # in the C code for image.point.\n",
        "      return tf.clip_by_value(lut, 0, 255)\n",
        " \n",
        "    # If step is zero, return the original image.  Otherwise, build\n",
        "    # lut from the full histogram and step and then index from it.\n",
        "    result = tf.cond(tf.equal(step, 0),\n",
        "                     lambda: im,\n",
        "                     lambda: tf.gather(build_lut(histo, step), im))\n",
        " \n",
        "    return tf.cast(result, tf.uint8)\n",
        " \n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image, 0)\n",
        "  s2 = scale_channel(image, 1)\n",
        "  s3 = scale_channel(image, 2)\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        "Equalize(test_image, 1)\n",
        "def Rotate(image, degrees):\n",
        "  \"\"\"Rotates the image by degrees either clockwise or counterclockwise.\n",
        "  Args:\n",
        "    image: An image Tensor of type uint8.\n",
        "    degrees: Float, a scalar angle in degrees to rotate all images by. If\n",
        "      degrees is positive the image will be rotated clockwise otherwise it will\n",
        "      be rotated counterclockwise.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels caused by\n",
        "      the rotate operation.\n",
        "  Returns:\n",
        "    The rotated version of image.\n",
        "  \"\"\"\n",
        "  # Convert from degrees to radians.\n",
        "  degrees = int(degrees)\n",
        "  degrees_to_radians = math.pi / 180.0\n",
        "  radians = degrees * degrees_to_radians\n",
        " \n",
        "  # In practice, we should randomize the rotation degrees by flipping\n",
        "  # it negatively half the time, but that's done on 'degrees' outside\n",
        "  # of the function.\n",
        "  #image = contrib_image.rotate(wrap(image), radians)\n",
        "  image = tfa.image.rotate(image, radians)\n",
        "  #return unwrap(image, replace)\n",
        "  return image\n",
        "Rotate(test_image, 30.1)\n",
        "def Solarize(image, threshold=128):\n",
        "  # For each pixel in the image, select the pixel\n",
        "  # if the value is less than the threshold.\n",
        "  # Otherwise, subtract 255 from the pixel.\n",
        "  #image = tf.convert_to_tensor(image, dtype=tf.int32)\n",
        "  #print(image)\n",
        "  \n",
        "  threshold = tf.cast(threshold, dtype=tf.uint8)\n",
        "  #print(threshold)\n",
        "  minus_value = tf.constant(255, dtype=tf.uint8)\n",
        "  #print(minus_value)\n",
        "  return tf.where(image < threshold, image, minus_value - image)\n",
        "Solarize(test_image, 10.0)\n",
        "def Color(image, factor):\n",
        "  \"\"\"Equivalent of PIL Color.\"\"\"\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))\n",
        "  #factor = tf.cast(factor, dtype=tf.float32)\n",
        "  return blend(degenerate, image, factor)\n",
        "Color(test_image, 10.1)\n",
        " \n",
        " \n",
        " \n",
        "def Posterize(image, bits):\n",
        " \n",
        "  bits=int(bits)\n",
        "  #print(bits)\n",
        "  \"\"\"Equivalent of PIL Posterize.\"\"\"\n",
        "  shift = 8 - bits\n",
        "  #print(shift)\n",
        "  #print(image)\n",
        "  return tf.bitwise.left_shift(tf.bitwise.right_shift(image, shift), shift)\n",
        "Posterize(test_image, 1.1)\n",
        "def Contrast(image, factor):\n",
        "  \"\"\"Equivalent of PIL Contrast.\"\"\"\n",
        "  degenerate = tf.image.rgb_to_grayscale(image)\n",
        "  # Cast before calling tf.histogram.\n",
        "  degenerate = tf.cast(degenerate, tf.int32)\n",
        " \n",
        "  # Compute the grayscale histogram, then compute the mean pixel value,\n",
        "  # and create a constant image size of that value.  Use that as the\n",
        "  # blending degenerate target of the original image.\n",
        "  hist = tf.histogram_fixed_width(degenerate, [0, 255], nbins=256)\n",
        "  mean = tf.reduce_sum(tf.cast(hist, tf.float32)) / 256.0\n",
        "  degenerate = tf.ones_like(degenerate, dtype=tf.float32) * mean\n",
        "  degenerate = tf.clip_by_value(degenerate, 0.0, 255.0)\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.cast(degenerate, tf.uint8))\n",
        "  return blend(degenerate, image, factor)\n",
        "Contrast(test_image, 10.1)\n",
        "def Brightness(image, factor):\n",
        "  \"\"\"Equivalent of PIL Brightness.\"\"\"\n",
        "  degenerate = tf.zeros_like(image)\n",
        "  return blend(degenerate, image, factor)\n",
        "Brightness(test_image, 10.1)\n",
        "def _sharpness_image(image, factor):\n",
        "    orig_image = image\n",
        "    image_dtype = image.dtype\n",
        "    image_channels = image.shape[-1]\n",
        "    image = tf.cast(image, tf.float32)\n",
        " \n",
        "    # SMOOTH PIL Kernel.\n",
        "    kernel = (\n",
        "        tf.constant(\n",
        "            [[1, 1, 1], [1, 5, 1], [1, 1, 1]], dtype=tf.float32, shape=[3, 3, 1, 1]\n",
        "        )\n",
        "        / 13.0\n",
        "    )\n",
        "    kernel = tf.tile(kernel, [1, 1, image_channels, 1])\n",
        " \n",
        "    # Apply kernel channel-wise.\n",
        "    degenerate = tf.nn.depthwise_conv2d(\n",
        "        image, kernel, strides=[1, 1, 1, 1], padding=\"VALID\", dilations=[1, 1]\n",
        "    )\n",
        "    degenerate = tf.cast(degenerate, image_dtype)\n",
        " \n",
        "    # For the borders of the resulting image, fill in the values of the original image.\n",
        "    mask = tf.ones_like(degenerate)\n",
        "    padded_mask = tf.pad(mask, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "    padded_degenerate = tf.pad(degenerate, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "    result = tf.where(tf.equal(padded_mask, 1), padded_degenerate, orig_image)\n",
        " \n",
        "    # Blend the final result.\n",
        "    blended = blend(result, orig_image, factor)\n",
        "    return tf.cast(blended, image_dtype)\n",
        " \n",
        " \n",
        "def Sharpness(image, factor):\n",
        "    \n",
        "        image_dims = tf.rank(image)\n",
        "        image = to_4D_image(image)\n",
        "        image = _sharpness_image(image, factor=factor)\n",
        "        return from_4D_image(image, image_dims)\n",
        "    #return tfa.image.sharpness(image, factor)\n",
        "Sharpness(test_image, 10.1)\n",
        " \n",
        "def ShearX(image, level):\n",
        "  \"\"\"Equivalent of PIL Shearing in X dimension.\"\"\"\n",
        "  # Shear parallel to x axis is a projective transform\n",
        "  # with a matrix form of:\n",
        "  # [1  level\n",
        "  #  0  1].\n",
        "  #image = contrib_image.transform(\n",
        "  #    wrap(image), [1., level, 0., 0., 1., 0., 0., 0.])\n",
        "  #return unwrap(image, replace)\n",
        "  \n",
        "  return tfa.image.shear_x(image, level, 0)\n",
        "ShearX(test_image,10)\n",
        "def ShearY(image, level):\n",
        "  \"\"\"Equivalent of PIL Shearing in Y dimension.\"\"\"\n",
        "  # Shear parallel to y axis is a projective transform\n",
        "  # with a matrix form of:\n",
        "  # [1  0\n",
        "  #  level  1].\n",
        "  #image = contrib_image.transform(\n",
        "  #    wrap(image), [1., 0., 0., level, 1., 0., 0., 0.])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.shear_y(image, level, 0)\n",
        "ShearX(test_image,20)\n",
        "def wrap(image):\n",
        "  \"\"\"Returns 'image' with an extra channel set to all 1s.\"\"\"\n",
        "  shape = tf.shape(image)\n",
        "  extended_channel = tf.ones([shape[0], shape[1], 1], image.dtype)\n",
        "  extended = tf.concat([image, extended_channel], 2)\n",
        "  return extended\n",
        " \n",
        "def unwrap(image, replace):\n",
        "  \"\"\"Unwraps an image produced by wrap.\n",
        "  Where there is a 0 in the last channel for every spatial position,\n",
        "  the rest of the three channels in that spatial dimension are grayed\n",
        "  (set to 128).  Operations like translate and shear on a wrapped\n",
        "  Tensor will leave 0s in empty locations.  Some transformations look\n",
        "  at the intensity of values to do preprocessing, and we want these\n",
        "  empty pixels to assume the 'average' value, rather than pure black.\n",
        "  Args:\n",
        "    image: A 3D Image Tensor with 4 channels.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels.\n",
        "  Returns:\n",
        "    image: A 3D image Tensor with 3 channels.\n",
        "  \"\"\"\n",
        "  image_shape = tf.shape(image)\n",
        "  # Flatten the spatial dimensions.\n",
        "  flattened_image = tf.reshape(image, [-1, image_shape[2]])\n",
        " \n",
        "  # Find all pixels where the last channel is zero.\n",
        "  alpha_channel = flattened_image[:, 3]\n",
        " \n",
        "  replace = tf.concat([replace, tf.ones([1], image.dtype)], 0)\n",
        " \n",
        "  # Where they are zero, fill them in with 'replace'.\n",
        "  flattened_image = tf.where(\n",
        "      tf.equal(alpha_channel, 0),\n",
        "      tf.ones_like(flattened_image, dtype=image.dtype) * replace,\n",
        "      flattened_image)\n",
        " \n",
        "  image = tf.reshape(flattened_image, image_shape)\n",
        "  image = tf.slice(image, [0, 0, 0], [image_shape[0], image_shape[1], 3])\n",
        "  return image\n",
        " \n",
        "def TranslateX(image, pixels):\n",
        "  \"\"\"Equivalent of PIL Translate in X dimension.\"\"\"\n",
        "  #image = contrib_image.translate(wrap(image), [-pixels, 0])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.translate_xy(image, [pixels, 0], replace=0)\n",
        "TranslateX(test_image, 10)\n",
        "def TranslateY(image, pixels):\n",
        "  \"\"\"Equivalent of PIL Translate in Y dimension.\"\"\"\n",
        "  #image = contrib_image.translate(wrap(image), [0, -pixels])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.translate_xy(image, [0, pixels], replace=0)\n",
        "TranslateY(test_image, 10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1024, 1024, 3), dtype=uint8, numpy=\n",
              "array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 86,  75, 216],\n",
              "        [131, 234, 232],\n",
              "        [ 14, 245,  65],\n",
              "        ...,\n",
              "        [154, 177,  33],\n",
              "        [243,   1, 116],\n",
              "        [ 73, 133, 245]],\n",
              "\n",
              "       [[ 84,  93,  27],\n",
              "        [137, 180, 172],\n",
              "        [104, 129,  89],\n",
              "        ...,\n",
              "        [ 48, 217,   9],\n",
              "        [ 72, 248,  76],\n",
              "        [  4, 221,  37]],\n",
              "\n",
              "       [[ 95, 182,  57],\n",
              "        [248, 112,  72],\n",
              "        [153,  78, 139],\n",
              "        ...,\n",
              "        [ 28, 118,  96],\n",
              "        [  3, 127, 175],\n",
              "        [247, 193,  33]]], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws5Tg2JZpE7g"
      },
      "source": [
        "class RandomResizedCrop:\n",
        "    \"\"\"Torchvision's variant of crop a random part of the input and rescale it to some size.\n",
        "    Args:\n",
        "        height (int): height after crop and resize.\n",
        "        width (int): width after crop and resize.\n",
        "        scale ((float, float)): range of size of the origin size cropped\n",
        "        ratio ((float, float)): range of aspect ratio of the origin aspect ratio cropped\n",
        "        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:\n",
        "            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.\n",
        "            Default: cv2.INTER_LINEAR.\n",
        "        p (float): probability of applying the transform. Default: 1.\n",
        "    Targets:\n",
        "        image, mask, bboxes, keypoints\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        height,\n",
        "        width,\n",
        "        org_height,\n",
        "        org_width,\n",
        "        scale=(0.08, 1.0),\n",
        "        ratio=(0.75, 1.3333333333333333),\n",
        "    ):\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.scale = scale\n",
        "        self.ratio = ratio\n",
        "        self.beforeheight = org_height\n",
        "        self.beforewidth = org_width\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_random_crop_coords(height, width, crop_height, crop_width, h_start, w_start):\n",
        "        x1 = int((height - crop_height) * h_start)\n",
        "        x2 = x1 + crop_height\n",
        "        y1 = int((width - crop_width) * w_start)\n",
        "        y2 = y1 + crop_width\n",
        "        return x1, y1, x2, y2\n",
        "    \n",
        "    def __call__(self, img):\n",
        "\n",
        "        \n",
        "        area = img.shape[0] * img.shape[1]\n",
        "        #print(img.shape[0], img.shape[1])\n",
        "        for _attempt in range(10):\n",
        "            target_area = random.uniform(*self.scale) * area\n",
        "            log_ratio = (math.log(self.ratio[0]), math.log(self.ratio[1]))\n",
        "            aspect_ratio = math.exp(random.uniform(*log_ratio))\n",
        "\n",
        "            w = int(round(math.sqrt(target_area * aspect_ratio)))  # skipcq: PTC-W0028\n",
        "            h = int(round(math.sqrt(target_area / aspect_ratio)))  # skipcq: PTC-W0028\n",
        "            #print(w, h)\n",
        "            if 0 < w <= img.shape[1] and 0 < h <= img.shape[0]:\n",
        "                i = random.randint(0, img.shape[0] - h)\n",
        "                j = random.randint(0, img.shape[1] - w)\n",
        "                h_start = i * 1.0 / (img.shape[0] - h + 1e-10)\n",
        "                w_start = j * 1.0 / (img.shape[1] - w + 1e-10)\n",
        "                #print(h, w)\n",
        "                x1, y1, x2, y2 = self.get_random_crop_coords(self.beforeheight, self.beforewidth, h, w, h_start, w_start)\n",
        "                #print(h, w)\n",
        "                #print(x1, y1, x2, y2)\n",
        "                #print(x1, y1, x2, y2)\n",
        "                img = img[x1:x2, y1:y2, :]\n",
        "                img = tf.image.resize(img, (self.height, self.width))\n",
        "                return tf.cast(img, dtype=tf.uint8)\n",
        "\n",
        "        # Fallback to central crop\n",
        "        #print('central gogo')\n",
        "        in_ratio = img.shape[1] / img.shape[0]\n",
        "        if in_ratio < min(self.ratio):\n",
        "            w = img.shape[1]\n",
        "            h = int(round(w / min(self.ratio)))\n",
        "        elif in_ratio > max(self.ratio):\n",
        "            h = img.shape[0]\n",
        "            w = int(round(h * max(self.ratio)))\n",
        "        else:  # whole image\n",
        "            w = img.shape[1]\n",
        "            h = img.shape[0]\n",
        "        i = (img.shape[0] - h) // 2\n",
        "        j = (img.shape[1] - w) // 2\n",
        "        x1, y1, x2, y2 = self.get_random_crop_coords(self.beforeheight, self.beforewidth, h, w, i, j)\n",
        "        img = img[x1:x2, y1:y2, :]\n",
        "        img = tf.image.resize(img, (self.height, self.width))\n",
        "        return tf.cast(img, dtype=tf.uint8)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDDsiU6PE6Zm"
      },
      "source": [
        "class Normalize:\n",
        "    \"\"\"Divide pixel values by 255 = 2**8 - 1, subtract mean per channel and divide by std per channel.\n",
        "    Args:\n",
        "        mean (float, list of float): mean values\n",
        "        std  (float, list of float): std values\n",
        "        max_pixel_value (float): maximum possible pixel value\n",
        "    Targets:\n",
        "        image\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, mean=CFG.MEAN, std=CFG.STD, max_pixel_value=255.0, always_apply=False, p=1.0\n",
        "    ):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.max_pixel_value = max_pixel_value\n",
        "\n",
        "\n",
        "    \n",
        "    def normalize_image(self, img, mean, std, max_pixel_value=255.0):\n",
        "        mean = tf.convert_to_tensor(mean, dtype=tf.float32)\n",
        "        mean = mean * max_pixel_value\n",
        "\n",
        "        std = tf.convert_to_tensor(std, dtype=tf.float32)\n",
        "        std = std * max_pixel_value\n",
        "\n",
        "        denominator = tf.math.reciprocal(std)\n",
        "\n",
        "        #print('before cast', img)\n",
        "        img = tf.cast(img, dtype = tf.float32)\n",
        "        #print('after cast', img)\n",
        "        #img = img - mean\n",
        "        #img = img * denominator\n",
        "        img = img / 255.\n",
        "        return img\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.normalize_image(img, self.mean, self.std)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ivUmviTzRd6"
      },
      "source": [
        "class CoarseDropout:\n",
        "  def __init__(self, max_holes, size=0.06):\n",
        "    self.size = size\n",
        "    self.max_holes = max_holes\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def __call__(self, image):\n",
        "      #holes = []\n",
        "      P = random.uniform(0,1)\n",
        "      height = image.shape[0]\n",
        "      width = image.shape[1]\n",
        "      for _n in range(self.max_holes):\n",
        "          hole_height = height * self.size * P\n",
        "          hole_width = width * self.size * P\n",
        "          hole_height = int(hole_height)\n",
        "          hole_width = int(hole_width)\n",
        "          y1 = random.randint(0, height - hole_height)\n",
        "          x1 = random.randint(0, width- hole_width)\n",
        "          y2 = y1 + hole_height\n",
        "          x2 = x1 + hole_width\n",
        "          #holes.append((y1, x1, y2, x2))\n",
        "        \n",
        "          one = image[y1:y2,0:x1,:]\n",
        "          two = tf.zeros([y2-y1,x2-x1,3], dtype=tf.uint8) \n",
        "          three = image[y1:y2,x2:width,:]\n",
        "          middle = tf.concat([one,two,three],axis=1)\n",
        "          image = tf.concat([image[0:y1,:,:],middle,image[y2:height,:,:]],axis=0)\n",
        "      \n",
        "          \n",
        "      image = tf.cast(image, dtype=tf.uint8)\n",
        "      return image"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qtmKcRRnLJS"
      },
      "source": [
        "def augment_list():\n",
        " \n",
        "  l = [  #(Identity, 0, 1),\n",
        "        #(AutoContrast, 0, 1),\n",
        "        #(Equalize, 0, 1),\n",
        "        (Rotate, -20, 20),\n",
        "        #(Posterize, 0, 4),\n",
        "        #(Solarize, 0, 256),\n",
        "        #(Color, 0.1, 1.9),\n",
        "        (Contrast, 0.1, 1.9),\n",
        "        (Brightness, 0.1, 1.9),\n",
        "        #(Sharpness, 0.1, 1.9),\n",
        "        (ShearX, -0.1, 0.1),\n",
        "        (ShearY, -0.1, 0.1),\n",
        "        (TranslateX, -CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "        (TranslateY, -CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "    ]\n",
        "  return l"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tzakJMqhjAY"
      },
      "source": [
        "def augment_list_tta():\n",
        " \n",
        "  l = [  #(Identity, 0, 1),\n",
        "        #(AutoContrast, 0, 1),\n",
        "        #(Equalize, 0, 1),\n",
        "        #(Rotate, -15, 15),\n",
        "        #(Posterize, 0, 4),\n",
        "        #(Solarize, 0, 256),\n",
        "        #(Color, 0.1, 1.9),\n",
        "        #(Contrast, 0.1, 1.9),\n",
        "        (Brightness, 0.1, 1.9),\n",
        "        #(Sharpness, 0.1, 1.9),\n",
        "        #(ShearX, -0.1, 0.1),\n",
        "        #(ShearY, -0.1, 0.1),\n",
        "        #(TranslateX, -CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "        #(TranslateY, -CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "    ]\n",
        "  return l"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYyHDbDpnfBk"
      },
      "source": [
        "import random\n",
        "class RandAugment:\n",
        "    def __init__(self, n, m):\n",
        "        self.n = n\n",
        "        self.m = m      # [0, 30]\n",
        "        self.augment_list = augment_list()\n",
        " \n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_list, k=self.n)\n",
        "        for op, minval, maxval in ops:\n",
        "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
        "            img = op(img, val)\n",
        " \n",
        " \n",
        "        return img"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykrpFND_rQ-p"
      },
      "source": [
        "import random\n",
        "class RandAugmentTTA:\n",
        "    def __init__(self, n, m):\n",
        "        self.n = n\n",
        "        self.m = m      # [0, 30]\n",
        "        self.augment_list = augment_list_tta()\n",
        " \n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_list, k=self.n)\n",
        "        for op, minval, maxval in ops:\n",
        "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
        "            img = op(img, val)\n",
        " \n",
        " \n",
        "        return img"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB4CyRdNAKS4"
      },
      "source": [
        "randomaugtta = RandAugmentTTA(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "randaugtta = RandAugmentTTA(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oqGkm0mLoW0"
      },
      "source": [
        "def cutmix(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with cutmix applied\n",
        "    #print(image.shape, label.shape)\n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.BATCH_SIZE\n",
        "    cutmix_start = 0.0\n",
        "    imgs = []; labs = []\n",
        "    \n",
        "    image = tf.image.resize(image, size=(DIM1, DIM2))\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],cutmix_start,1)<=PROBABILITY, tf.int32)\n",
        "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        # CHOOSE RANDOM LOCATION\n",
        "        x = tf.cast( tf.random.uniform([],0,DIM2),tf.int32)\n",
        "        y = tf.cast( tf.random.uniform([],0,DIM1),tf.int32)\n",
        "        a = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32)\n",
        "        b = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32) # this is beta dist with alpha=1.0\n",
        "        WIDTH = tf.cast( DIM2 * tf.math.sqrt(1-a),tf.int32) * P\n",
        "        HEIGHT = tf.cast( DIM1 * tf.math.sqrt(1-b), tf.int32) * P\n",
        "        ya = tf.math.maximum(0,y-HEIGHT//2)\n",
        "        yb = tf.math.minimum(DIM1,y+HEIGHT//2)\n",
        "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
        "        xb = tf.math.minimum(DIM2,x+WIDTH//2)\n",
        "        # MAKE CUTMIX IMAGE\n",
        "        one = image[j,ya:yb,0:xa,:]\n",
        "        two = image[k,ya:yb,xa:xb,:]\n",
        "        three = image[j,ya:yb,xb:DIM2,:]\n",
        "        middle = tf.concat([one,two,three],axis=1)\n",
        "        cutmix_img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM1,:,:]],axis=0)\n",
        "        p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        if p_flip > 0.5:\n",
        "            cutmix_img = tf.image.flip_left_right(cutmix_img)\n",
        "        if p_v_flip > 0.5:\n",
        "            cutmix_img = tf.image.flip_up_down(cutmix_img)\n",
        "        if p_transpose > 0.5:\n",
        "            cutmix_img = tf.image.transpose(cutmix_img)\n",
        "        #cutmix_img = Normalize(CFG.MEAN, CFG.STD)(cutmix_img)\n",
        "        #cutmix_img = tf.image.resize(cutmix_img, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        #mixup_image = (1-a)*img1 + a*img2\n",
        "        cutmix_img = Normalize(CFG.MEAN, CFG.STD)(cutmix_img)\n",
        "        #mixup_image = tf.image.resize(mixup_image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        #imgs.append(mixup_image)\n",
        "        imgs.append(cutmix_img)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        a = tf.cast(WIDTH*HEIGHT/DIM1/DIM2,tf.float32)\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2\n",
        " \n",
        " \n",
        " \n",
        "def mixup(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with mixup applied\n",
        "    AUG_BATCH = CFG.BATCH_SIZE\n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    \n",
        "    imgs = []; labs = []\n",
        "    image = tf.image.resize(image, size=(DIM1, DIM2))\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n",
        "        # CHOOSE RANDOM\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        a = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32)*P # this is beta dist with alpha=1.0\n",
        "        # MAKE MIXUP IMAGE\n",
        "        img1 = image[j,]\n",
        "        img2 = image[k,]\n",
        "        #mixup_image = (1-0.5)*img1 + 0.5*img2\n",
        "        mixup_image = (1-a)*img1 + a*img2\n",
        "        p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        #p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        #p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        if p_flip > 0.5:\n",
        "            mixup_image = tf.image.flip_left_right(mixup_image)\n",
        "        #if p_v_flip > 0.5:\n",
        "        #    mixup_image = tf.image.flip_up_down(mixup_image)\n",
        "        #if p_transpose > 0.5:\n",
        "        #    mixup_image = tf.image.transpose(mixup_image)\n",
        "        mixup_image = Normalize(CFG.MEAN, CFG.STD)(mixup_image)\n",
        "        #mixup_image = tf.image.resize(mixup_image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        imgs.append(mixup_image)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEAxFwBse-yv"
      },
      "source": [
        "def real_data_augment(image, label):\n",
        "    k = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    if k < 0.5:\n",
        "        image2, label2 = mixup(image, label)\n",
        "    #elif (k >= -2) and (k < 0):\n",
        "    #    image2, label2 = cutmix(image, label)\n",
        "    else:\n",
        "        image2, label2 = data_augment(image, label)\n",
        " \n",
        "    return image2, label2 \n",
        " \n",
        "def prep_for_val(image, label):\n",
        "    \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    #randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    #coarse = CoarseDropout(30)\n",
        "    #randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.85, 1.0))\n",
        " \n",
        "    #P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            img = tf.image.resize(img, [DIM1, DIM2])\n",
        "            img = normalize(img)\n",
        "            imgs.append(img)\n",
        " \n",
        "       \n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2\n",
        " \n",
        " \n",
        "def data_augment(image, label):\n",
        " \n",
        " \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    coarse = CoarseDropout(1)\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.9, 1.1))\n",
        " \n",
        "    P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        " \n",
        "            img = randomcrop(img)\n",
        " \n",
        "            if p_flip >= 0.5:\n",
        "                img = tf.image.flip_left_right(img)\n",
        "            if p_v_flip >= 0.5:\n",
        "                img = tf.image.flip_up_down(img)\n",
        "            #if p_transpose >= 0.5:\n",
        "            #    if CFG.OBJ_HEIGHT == CFG.OBJ_WIDTH:\n",
        "            #        img = tf.image.transpose(img)\n",
        " \n",
        "            img = coarse(img)\n",
        "            img = randaug(img)\n",
        "            #img = img/255.\n",
        "            img = tf.cast(img, tf.float32) / 255.\n",
        "            imgs.append(img)\n",
        " \n",
        "       \n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECrHNVz2S4Dk",
        "outputId": "56203d65-4040-45c6-bd12-7b27d86fba85"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI8RTuBuSEpg"
      },
      "source": [
        "def decode_tr_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    \n",
        "    return image\n",
        " \n",
        "def decode_val_image(image_data, label):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    #image = normalize(image)\n",
        "    image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    label = tf.reshape(label, [CFG.NUMBER_OF_CLASSES])\n",
        "    return image, label\n",
        "\n",
        "def decode_test_image(image_data, label):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image, label\n",
        "\n",
        "def decode_just_test_image(image_data):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image\n",
        " \n",
        "def decode_val_image_for_tta(image_data):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.99,1.0))\n",
        "    randaug = RandAugmentTTA(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    #p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    #image = randomcrop(image)\n",
        "    if p_flip > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "    if p_v_flip > 0.5:\n",
        "        image = tf.image.flip_up_down(image)\n",
        "    #if CFG.OBJ_HEIGHT == CFG.OBJ_WIDTH:\n",
        "    #    if p_transpose > 0.5:\n",
        "    #        image = tf.image.transpose(image)\n",
        "    image = randaugtta(image)\n",
        "    #image = normalize(image)\n",
        "    image = tf.cast(image, tf.float32) / 255.\n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image\n",
        " \n",
        "def read_tfrecord(example, labeled=True):\n",
        "    \"\"\"\n",
        "        1. Parse data based on the 'TFREC_FORMAT' map.\n",
        "        2. Decode image.\n",
        "        3. If 'labeled' returns (image, label) if not (image, name).\n",
        "    \"\"\"\n",
        "    if labeled:\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'target': tf.io.FixedLenFeature([], tf.int64), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image'], tf.one_hot(example['target'], depth=CFG.NUMBER_OF_CLASSES)\n",
        "    else:\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image'], example['image_id']\n",
        "\n",
        "def read_test_tfrecord(example):\n",
        "\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image'], example['image_id']\n",
        "\n",
        "def read_test_image_tfrecord(example):\n",
        "\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image']\n",
        " \n",
        "def load_dataset(filenames, validation, labeled=True, ordered=False, ):\n",
        "    \"\"\"\n",
        "        Create a Tensorflow dataset from TFRecords.\n",
        "    \"\"\"\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False\n",
        " \n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "    dataset = dataset.with_options(ignore_order)\n",
        "    if validation == False:\n",
        " \n",
        "        dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled, validation = False), num_parallel_calls=AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled, validation = True), num_parallel_calls=AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False, validation=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(1024*8)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        dataset = dataset.with_options(opt)\n",
        "    \n",
        "    if (labeled == True):\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=True), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=False), num_parallel_calls = AUTO)\n",
        "    \n",
        "    if (validation == True) and (labeled == False):\n",
        "        pass\n",
        "    elif (validation == False) and (labeled == True):\n",
        "        dataset = dataset.map(lambda image, label : (decode_tr_image(image), label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda image, label : decode_val_image(image, label), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if augment:\n",
        "            dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "    #else:\n",
        "    #        dataset = dataset.map(prep_for_val, num_parallel_calls=AUTO)\n",
        "    \n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_test_dataset(FILENAMES, return_image_name=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()   \n",
        "    \n",
        "    \n",
        "    if return_image_name:\n",
        "        dataset = dataset.map(lambda example : read_test_tfrecord(example), num_parallel_calls = AUTO)\n",
        "        dataset = dataset.map(lambda image, label : decode_test_image(image, label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_test_image_tfrecord(example), num_parallel_calls = AUTO)\n",
        "        dataset = dataset.map(lambda image : decode_just_test_image(image), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_dataset_for_tta(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False, validation=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(1024*8)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        dataset = dataset.with_options(opt)\n",
        "    \n",
        "    if (labeled == True):\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=True), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=False), num_parallel_calls = AUTO)\n",
        "    \n",
        "    if validation == False:\n",
        "        dataset = dataset.map(lambda image, label : (decode_tr_image(image), label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda image, label : (decode_val_image_for_tta(image), label), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if augment:\n",
        "            dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "    \n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEVAoSVZoB-1"
      },
      "source": [
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    print(n)\n",
        "    return np.sum(n)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDqawNTsn1vX"
      },
      "source": [
        "from tensorflow_addons.utils.types import FloatTensorLike\n",
        " \n",
        "from typing import Union, Callable, Dict\n",
        "from typeguard import typechecked\n",
        " \n",
        " \n",
        "class CosineDecayRAdam(tfa.optimizers.RectifiedAdam):\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        var_dtype = var.dtype.base_dtype\n",
        "        lr_t = self._decayed_lr(var_dtype)\n",
        "        wd_t = self._decayed_wd(var_dtype)\n",
        "        m = self.get_slot(var, \"m\")\n",
        "        v = self.get_slot(var, \"v\")\n",
        "        beta_1_t = self._get_hyper(\"beta_1\", var_dtype)\n",
        "        beta_2_t = self._get_hyper(\"beta_2\", var_dtype)\n",
        "        epsilon_t = tf.convert_to_tensor(self.epsilon, var_dtype)\n",
        "        local_step = tf.cast(self.iterations + 1, var_dtype)\n",
        "        beta_1_power = tf.pow(beta_1_t, local_step)\n",
        "        beta_2_power = tf.pow(beta_2_t, local_step)\n",
        " \n",
        "        if self._initial_total_steps > 0:\n",
        "            total_steps = self._get_hyper(\"total_steps\", var_dtype)\n",
        "            warmup_steps = total_steps * self._get_hyper(\"warmup_proportion\", var_dtype)\n",
        "            min_lr = self._get_hyper(\"min_lr\", var_dtype)\n",
        "            decay_steps = tf.maximum(total_steps - warmup_steps, 1)\n",
        "            decay_rate = (min_lr - lr_t) / decay_steps\n",
        "            pi = tf.constant(3.141592)\n",
        "            cos = tf.math.cos(pi * ((local_step - warmup_steps) / (total_steps - warmup_steps))) + tf.constant(1.)\n",
        "            lr_t = tf.where(\n",
        "                local_step <= warmup_steps,\n",
        "                lr_t * (local_step / warmup_steps),\n",
        "                #lr_t + decay_rate * tf.minimum(local_step - warmup_steps, decay_steps),\n",
        "                min_lr + (lr_t - min_lr) / 2. * cos\n",
        "            )\n",
        " \n",
        "        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n",
        "        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n",
        " \n",
        "        m_t = m.assign(\n",
        "            beta_1_t * m + (1.0 - beta_1_t) * grad, use_locking=self._use_locking\n",
        "        )\n",
        "        m_corr_t = m_t / (1.0 - beta_1_power)\n",
        " \n",
        "        v_t = v.assign(\n",
        "            beta_2_t * v + (1.0 - beta_2_t) * tf.square(grad),\n",
        "            use_locking=self._use_locking,\n",
        "        )\n",
        "        if self.amsgrad:\n",
        "            vhat = self.get_slot(var, \"vhat\")\n",
        "            vhat_t = vhat.assign(tf.maximum(vhat, v_t), use_locking=self._use_locking)\n",
        "            v_corr_t = tf.sqrt(vhat_t / (1.0 - beta_2_power))\n",
        "        else:\n",
        "            vhat_t = None\n",
        "            v_corr_t = tf.sqrt(v_t / (1.0 - beta_2_power))\n",
        " \n",
        "        r_t = tf.sqrt(\n",
        "            (sma_t - 4.0)\n",
        "            / (sma_inf - 4.0)\n",
        "            * (sma_t - 2.0)\n",
        "            / (sma_inf - 2.0)\n",
        "            * sma_inf\n",
        "            / sma_t\n",
        "        )\n",
        " \n",
        "        sma_threshold = self._get_hyper(\"sma_threshold\", var_dtype)\n",
        "        var_t = tf.where(\n",
        "            sma_t >= sma_threshold, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t\n",
        "        )\n",
        " \n",
        "        if self._has_weight_decay:\n",
        "            var_t += wd_t * var\n",
        " \n",
        "        var_update = var.assign_sub(lr_t * var_t, use_locking=self._use_locking)\n",
        " \n",
        "        updates = [var_update, m_t, v_t]\n",
        "        if self.amsgrad:\n",
        "            updates.append(vhat_t)\n",
        "        return tf.group(*updates)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtZCnkM3BCN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22efe86e-c2aa-46fa-883f-a00b793aea3f"
      },
      "source": [
        "# RandomCropedSized FIX\n",
        "# Cosine Decay Radam\n",
        " \n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = []; history_list = []; normal_oof_pred = []; pred_max = []\n",
        "import gc\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = CFG.N_FOLDS, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "seed_everything(SEED)\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    TRAINING_IMAGES = TRAINING_FILENAMES\n",
        " \n",
        "    train_dataset = get_dataset(TRAINING_FILENAMES, labeled=True, ordered=False, repeated=True, augment=True, validation=False)\n",
        "    val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        " \n",
        "    def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'imagenet', include_top = False, pooling='avg')\n",
        "        #for i, layer in enumerate(effnet.layers):\n",
        "            #if i < 236: overfit\n",
        "        #    if i < 200:\n",
        "                # 179 overfit\n",
        "\n",
        "        #        layer.trainable = False\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x0 = tf.keras.layers.Dropout(0.5)(x0)\n",
        "        x0 = tf.keras.layers.Dense(64, activation='relu')(x0)\n",
        "        x = tf.keras.layers.Dense(CFG.NUMBER_OF_CLASSES, activation='softmax', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        \n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        #opt =tf.keras.optimizers.Adam(learning_rate=CFG.LEARNING_RATE)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'categorical_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tf.keras.backend.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(ROOT_PATH, f\"COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"), \n",
        "                                                    monitor = 'val_auc', \n",
        "                                                    save_best_only = True,\n",
        "                                                    mode = 'max')\n",
        "    history = model.fit(train_dataset,  \n",
        "                        steps_per_epoch = STEPS_PER_EPOCH,\n",
        "                        epochs = CFG.EPOCHS,\n",
        "                        callbacks = [checkpoint],\n",
        "                        validation_data = val_dataset,\n",
        "                        verbose = 1,\n",
        "                        ).history\n",
        "    print(f\"#### FOLD {fold+1} without TTA VAL_AUC = {np.max(history['val_auc']):.3f}\")\n",
        "    del model\n",
        "    gc.collect()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "258441216/258434480 [==============================] - 3s 0us/step\n",
            "Efficient Model7 has been loaded \n",
            "Epoch 1/50\n",
            "79/79 [==============================] - 822s 861ms/step - loss: 1.4328 - auc: 0.5067 - val_loss: 1.4017 - val_auc: 0.5174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 1.3137 - auc: 0.5396 - val_loss: 1.2236 - val_auc: 0.6470\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 1.1140 - auc: 0.6156 - val_loss: 1.1179 - val_auc: 0.6945\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 45s 576ms/step - loss: 1.0391 - auc: 0.6559 - val_loss: 0.9599 - val_auc: 0.7643\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 1.0095 - auc: 0.6638 - val_loss: 0.9446 - val_auc: 0.7787\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 45s 576ms/step - loss: 0.9974 - auc: 0.6762 - val_loss: 0.9713 - val_auc: 0.7763\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 44s 563ms/step - loss: 0.9607 - auc: 0.7068 - val_loss: 0.9327 - val_auc: 0.7885\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.9618 - auc: 0.7047 - val_loss: 0.9256 - val_auc: 0.7879\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.9276 - auc: 0.7212 - val_loss: 0.9298 - val_auc: 0.7926\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.9194 - auc: 0.7279 - val_loss: 0.9356 - val_auc: 0.7922\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 47s 600ms/step - loss: 0.9123 - auc: 0.7177 - val_loss: 0.9591 - val_auc: 0.7836\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.8668 - auc: 0.7508 - val_loss: 0.9844 - val_auc: 0.7959\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 45s 576ms/step - loss: 0.8289 - auc: 0.7597 - val_loss: 0.9891 - val_auc: 0.7956\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 45s 566ms/step - loss: 0.8482 - auc: 0.7633 - val_loss: 1.0191 - val_auc: 0.7741\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 45s 564ms/step - loss: 0.8139 - auc: 0.7571 - val_loss: 1.0211 - val_auc: 0.7772\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 45s 566ms/step - loss: 0.7798 - auc: 0.7682 - val_loss: 1.0416 - val_auc: 0.7787\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.7480 - auc: 0.7901 - val_loss: 1.0433 - val_auc: 0.7816\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 44s 564ms/step - loss: 0.7456 - auc: 0.7873 - val_loss: 1.0414 - val_auc: 0.7922\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.6920 - auc: 0.8024 - val_loss: 1.1852 - val_auc: 0.7815\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.6907 - auc: 0.7991 - val_loss: 1.0926 - val_auc: 0.7664\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 45s 566ms/step - loss: 0.6175 - auc: 0.8282 - val_loss: 1.2317 - val_auc: 0.7689\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.6174 - auc: 0.8236 - val_loss: 1.1935 - val_auc: 0.7648\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 45s 567ms/step - loss: 0.5922 - auc: 0.8358 - val_loss: 1.3832 - val_auc: 0.7580\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 0.5491 - auc: 0.8374 - val_loss: 1.2535 - val_auc: 0.7672\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 45s 568ms/step - loss: 0.5367 - auc: 0.8492 - val_loss: 1.3524 - val_auc: 0.7600\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.5248 - auc: 0.8379 - val_loss: 1.2920 - val_auc: 0.7564\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 45s 564ms/step - loss: 0.4759 - auc: 0.8416 - val_loss: 1.3320 - val_auc: 0.7622\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 45s 567ms/step - loss: 0.4482 - auc: 0.8361 - val_loss: 1.4745 - val_auc: 0.7432\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.4345 - auc: 0.8632 - val_loss: 1.4586 - val_auc: 0.7448\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.4337 - auc: 0.8382 - val_loss: 1.3631 - val_auc: 0.7521\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 45s 568ms/step - loss: 0.3854 - auc: 0.8729 - val_loss: 1.5461 - val_auc: 0.7363\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 45s 564ms/step - loss: 0.3873 - auc: 0.8517 - val_loss: 1.4714 - val_auc: 0.7487\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 45s 564ms/step - loss: 0.3600 - auc: 0.8587 - val_loss: 1.5741 - val_auc: 0.7474\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 45s 567ms/step - loss: 0.3371 - auc: 0.8708 - val_loss: 1.5510 - val_auc: 0.7474\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 45s 567ms/step - loss: 0.3225 - auc: 0.8815 - val_loss: 1.5410 - val_auc: 0.7427\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 45s 564ms/step - loss: 0.3223 - auc: 0.8728 - val_loss: 1.5073 - val_auc: 0.7423\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.3145 - auc: 0.8722 - val_loss: 1.5405 - val_auc: 0.7503\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 45s 567ms/step - loss: 0.3021 - auc: 0.8724 - val_loss: 1.5236 - val_auc: 0.7515\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 45s 568ms/step - loss: 0.2843 - auc: 0.8847 - val_loss: 1.5526 - val_auc: 0.7535\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 45s 566ms/step - loss: 0.2762 - auc: 0.8853 - val_loss: 1.5689 - val_auc: 0.7477\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.2806 - auc: 0.8744 - val_loss: 1.5620 - val_auc: 0.7494\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 45s 566ms/step - loss: 0.2842 - auc: 0.8662 - val_loss: 1.5523 - val_auc: 0.7478\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 44s 564ms/step - loss: 0.2848 - auc: 0.8722 - val_loss: 1.5578 - val_auc: 0.7517\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 44s 563ms/step - loss: 0.2869 - auc: 0.8560 - val_loss: 1.5442 - val_auc: 0.7536\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 45s 566ms/step - loss: 0.2968 - auc: 0.8576 - val_loss: 1.5287 - val_auc: 0.7507\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 44s 564ms/step - loss: 0.2785 - auc: 0.8656 - val_loss: 1.5287 - val_auc: 0.7522\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 45s 564ms/step - loss: 0.2715 - auc: 0.8655 - val_loss: 1.5299 - val_auc: 0.7510\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 45s 564ms/step - loss: 0.2705 - auc: 0.8703 - val_loss: 1.5320 - val_auc: 0.7511\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 45s 565ms/step - loss: 0.2908 - auc: 0.8617 - val_loss: 1.5368 - val_auc: 0.7514\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 45s 566ms/step - loss: 0.2683 - auc: 0.8719 - val_loss: 1.5356 - val_auc: 0.7523\n",
            "#### FOLD 1 without TTA VAL_AUC = 0.796\n",
            "[1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model7 has been loaded \n",
            "Epoch 1/50\n",
            "79/79 [==============================] - 800s 827ms/step - loss: 1.4354 - auc: 0.5086 - val_loss: 1.3876 - val_auc: 0.5521\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 46s 583ms/step - loss: 1.3091 - auc: 0.5457 - val_loss: 1.2181 - val_auc: 0.6079\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 1.1129 - auc: 0.6197 - val_loss: 1.0460 - val_auc: 0.6893\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 46s 577ms/step - loss: 1.0253 - auc: 0.6577 - val_loss: 0.9597 - val_auc: 0.7413\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 49s 616ms/step - loss: 0.9979 - auc: 0.6725 - val_loss: 0.9375 - val_auc: 0.7538\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 46s 588ms/step - loss: 1.0053 - auc: 0.6803 - val_loss: 0.9121 - val_auc: 0.7716\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 46s 583ms/step - loss: 0.9637 - auc: 0.7025 - val_loss: 0.9082 - val_auc: 0.7827\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 45s 576ms/step - loss: 0.9532 - auc: 0.7003 - val_loss: 0.9095 - val_auc: 0.7866\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 0.9407 - auc: 0.7143 - val_loss: 0.9145 - val_auc: 0.7808\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.9238 - auc: 0.7185 - val_loss: 0.9747 - val_auc: 0.7899\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 46s 577ms/step - loss: 0.8983 - auc: 0.7313 - val_loss: 0.9267 - val_auc: 0.7958\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 46s 579ms/step - loss: 0.8908 - auc: 0.7463 - val_loss: 0.9094 - val_auc: 0.7948\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.8546 - auc: 0.7545 - val_loss: 0.9650 - val_auc: 0.7842\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 45s 568ms/step - loss: 0.8580 - auc: 0.7646 - val_loss: 1.0508 - val_auc: 0.7741\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.8115 - auc: 0.7623 - val_loss: 1.0401 - val_auc: 0.7693\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 0.8094 - auc: 0.7607 - val_loss: 1.1081 - val_auc: 0.7682\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.7906 - auc: 0.7765 - val_loss: 1.1191 - val_auc: 0.7556\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.7683 - auc: 0.7836 - val_loss: 1.0719 - val_auc: 0.7698\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.7354 - auc: 0.7894 - val_loss: 1.0458 - val_auc: 0.7677\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.7161 - auc: 0.7942 - val_loss: 1.0414 - val_auc: 0.7767\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.6611 - auc: 0.8175 - val_loss: 1.1870 - val_auc: 0.7659\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 0.6388 - auc: 0.8299 - val_loss: 1.1953 - val_auc: 0.7724\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.6166 - auc: 0.8323 - val_loss: 1.3549 - val_auc: 0.7413\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.5981 - auc: 0.8293 - val_loss: 1.0976 - val_auc: 0.7729\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.5589 - auc: 0.8475 - val_loss: 1.3787 - val_auc: 0.7555\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 0.5190 - auc: 0.8448 - val_loss: 1.3142 - val_auc: 0.7576\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.5411 - auc: 0.8358 - val_loss: 1.2269 - val_auc: 0.7615\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.5040 - auc: 0.8316 - val_loss: 1.4262 - val_auc: 0.7528\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.4573 - auc: 0.8649 - val_loss: 1.3338 - val_auc: 0.7542\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.4709 - auc: 0.8370 - val_loss: 1.3357 - val_auc: 0.7546\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 45s 576ms/step - loss: 0.4239 - auc: 0.8729 - val_loss: 1.4233 - val_auc: 0.7356\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.4223 - auc: 0.8545 - val_loss: 1.3797 - val_auc: 0.7453\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.4003 - auc: 0.8571 - val_loss: 1.3923 - val_auc: 0.7455\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.3723 - auc: 0.8720 - val_loss: 1.3974 - val_auc: 0.7460\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.3754 - auc: 0.8722 - val_loss: 1.4385 - val_auc: 0.7519\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.3490 - auc: 0.8733 - val_loss: 1.4304 - val_auc: 0.7519\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.3396 - auc: 0.8760 - val_loss: 1.4166 - val_auc: 0.7505\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.3357 - auc: 0.8694 - val_loss: 1.4728 - val_auc: 0.7466\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.3136 - auc: 0.8835 - val_loss: 1.4920 - val_auc: 0.7441\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.3029 - auc: 0.8864 - val_loss: 1.4420 - val_auc: 0.7494\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.3050 - auc: 0.8735 - val_loss: 1.4424 - val_auc: 0.7510\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.3133 - auc: 0.8686 - val_loss: 1.4542 - val_auc: 0.7508\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 45s 568ms/step - loss: 0.3013 - auc: 0.8698 - val_loss: 1.4400 - val_auc: 0.7452\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 45s 566ms/step - loss: 0.3300 - auc: 0.8538 - val_loss: 1.4230 - val_auc: 0.7493\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.3254 - auc: 0.8584 - val_loss: 1.4211 - val_auc: 0.7487\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 0.3014 - auc: 0.8732 - val_loss: 1.4217 - val_auc: 0.7503\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 0.3076 - auc: 0.8715 - val_loss: 1.4255 - val_auc: 0.7487\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 45s 568ms/step - loss: 0.2960 - auc: 0.8766 - val_loss: 1.4331 - val_auc: 0.7476\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 45s 568ms/step - loss: 0.3112 - auc: 0.8642 - val_loss: 1.4373 - val_auc: 0.7479\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.3105 - auc: 0.8666 - val_loss: 1.4382 - val_auc: 0.7481\n",
            "#### FOLD 2 without TTA VAL_AUC = 0.796\n",
            "[1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model7 has been loaded \n",
            "Epoch 1/50\n",
            "79/79 [==============================] - 802s 833ms/step - loss: 1.3915 - auc: 0.5010 - val_loss: 1.3426 - val_auc: 0.5072\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 46s 583ms/step - loss: 1.2862 - auc: 0.5543 - val_loss: 1.2186 - val_auc: 0.6386\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 45s 576ms/step - loss: 1.1064 - auc: 0.6159 - val_loss: 1.0594 - val_auc: 0.6991\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 1.0202 - auc: 0.6587 - val_loss: 0.9878 - val_auc: 0.7375\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 46s 577ms/step - loss: 1.0125 - auc: 0.6716 - val_loss: 1.0119 - val_auc: 0.7441\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 46s 580ms/step - loss: 0.9973 - auc: 0.6857 - val_loss: 0.9372 - val_auc: 0.7761\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 0.9636 - auc: 0.7148 - val_loss: 0.9075 - val_auc: 0.7845\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 45s 577ms/step - loss: 0.9557 - auc: 0.7005 - val_loss: 0.9091 - val_auc: 0.7871\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 0.9542 - auc: 0.7167 - val_loss: 0.9157 - val_auc: 0.7825\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.9115 - auc: 0.7279 - val_loss: 0.9996 - val_auc: 0.7729\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 0.8824 - auc: 0.7309 - val_loss: 0.9287 - val_auc: 0.7909\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 46s 579ms/step - loss: 0.8791 - auc: 0.7518 - val_loss: 0.9462 - val_auc: 0.7948\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 0.8574 - auc: 0.7535 - val_loss: 0.9527 - val_auc: 0.7781\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.8214 - auc: 0.7706 - val_loss: 1.1962 - val_auc: 0.7534\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.8344 - auc: 0.7616 - val_loss: 1.0194 - val_auc: 0.7805\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.8088 - auc: 0.7703 - val_loss: 1.0988 - val_auc: 0.7664\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.7584 - auc: 0.7852 - val_loss: 1.0468 - val_auc: 0.7725\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.7226 - auc: 0.7923 - val_loss: 1.0238 - val_auc: 0.7838\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.7144 - auc: 0.7931 - val_loss: 1.0353 - val_auc: 0.7792\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.6952 - auc: 0.8007 - val_loss: 1.2770 - val_auc: 0.7576\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.6629 - auc: 0.8208 - val_loss: 1.2172 - val_auc: 0.7607\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.6325 - auc: 0.8273 - val_loss: 1.1896 - val_auc: 0.7824\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 46s 583ms/step - loss: 0.6016 - auc: 0.8372 - val_loss: 1.3502 - val_auc: 0.7492\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.5867 - auc: 0.8380 - val_loss: 1.2228 - val_auc: 0.7646\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.5264 - auc: 0.8497 - val_loss: 1.2696 - val_auc: 0.7751\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 0.5501 - auc: 0.8372 - val_loss: 1.1934 - val_auc: 0.7613\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.5204 - auc: 0.8371 - val_loss: 1.3083 - val_auc: 0.7594\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.4866 - auc: 0.8290 - val_loss: 1.3586 - val_auc: 0.7451\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.4617 - auc: 0.8620 - val_loss: 1.3234 - val_auc: 0.7421\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.4518 - auc: 0.8439 - val_loss: 1.2960 - val_auc: 0.7628\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.3910 - auc: 0.8712 - val_loss: 1.3300 - val_auc: 0.7629\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.4158 - auc: 0.8495 - val_loss: 1.3124 - val_auc: 0.7601\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.3920 - auc: 0.8627 - val_loss: 1.3973 - val_auc: 0.7463\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.3322 - auc: 0.8797 - val_loss: 1.3969 - val_auc: 0.7555\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.3514 - auc: 0.8726 - val_loss: 1.3651 - val_auc: 0.7632\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.3571 - auc: 0.8717 - val_loss: 1.3832 - val_auc: 0.7603\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 46s 582ms/step - loss: 0.3249 - auc: 0.8719 - val_loss: 1.4100 - val_auc: 0.7531\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.3238 - auc: 0.8768 - val_loss: 1.4092 - val_auc: 0.7564\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.2976 - auc: 0.8828 - val_loss: 1.4188 - val_auc: 0.7565\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.3042 - auc: 0.8813 - val_loss: 1.4323 - val_auc: 0.7537\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.2993 - auc: 0.8782 - val_loss: 1.4225 - val_auc: 0.7566\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.3143 - auc: 0.8672 - val_loss: 1.4134 - val_auc: 0.7538\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.2949 - auc: 0.8763 - val_loss: 1.4049 - val_auc: 0.7555\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 45s 568ms/step - loss: 0.3228 - auc: 0.8570 - val_loss: 1.4047 - val_auc: 0.7564\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.3192 - auc: 0.8587 - val_loss: 1.4030 - val_auc: 0.7570\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 49s 616ms/step - loss: 0.2889 - auc: 0.8757 - val_loss: 1.4048 - val_auc: 0.7575\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.2968 - auc: 0.8675 - val_loss: 1.4015 - val_auc: 0.7577\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.2841 - auc: 0.8808 - val_loss: 1.4067 - val_auc: 0.7578\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.2985 - auc: 0.8631 - val_loss: 1.4084 - val_auc: 0.7579\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 0.2973 - auc: 0.8721 - val_loss: 1.4127 - val_auc: 0.7586\n",
            "#### FOLD 3 without TTA VAL_AUC = 0.795\n",
            "[1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model7 has been loaded \n",
            "Epoch 1/50\n",
            "79/79 [==============================] - 824s 861ms/step - loss: 1.3415 - auc: 0.5109 - val_loss: 1.3413 - val_auc: 0.5099\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 46s 580ms/step - loss: 1.2490 - auc: 0.5573 - val_loss: 1.1907 - val_auc: 0.6175\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 1.1185 - auc: 0.6204 - val_loss: 1.1045 - val_auc: 0.6763\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 1.0291 - auc: 0.6585 - val_loss: 0.9994 - val_auc: 0.7427\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 46s 589ms/step - loss: 1.0152 - auc: 0.6610 - val_loss: 0.9263 - val_auc: 0.7687\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 0.9932 - auc: 0.6809 - val_loss: 0.9329 - val_auc: 0.7781\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 46s 583ms/step - loss: 0.9356 - auc: 0.7131 - val_loss: 0.9073 - val_auc: 0.7955\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 46s 579ms/step - loss: 0.9525 - auc: 0.7058 - val_loss: 0.9068 - val_auc: 0.7889\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.9309 - auc: 0.7189 - val_loss: 0.9301 - val_auc: 0.7987\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 0.9471 - auc: 0.7074 - val_loss: 0.9105 - val_auc: 0.7936\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.9027 - auc: 0.7287 - val_loss: 0.9407 - val_auc: 0.7861\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.8940 - auc: 0.7413 - val_loss: 0.9330 - val_auc: 0.8019\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 46s 582ms/step - loss: 0.8375 - auc: 0.7631 - val_loss: 0.9300 - val_auc: 0.7986\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.7965 - auc: 0.7784 - val_loss: 0.9383 - val_auc: 0.7967\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.8274 - auc: 0.7612 - val_loss: 0.9622 - val_auc: 0.7935\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 46s 579ms/step - loss: 0.7898 - auc: 0.7678 - val_loss: 1.1592 - val_auc: 0.7652\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.7513 - auc: 0.7892 - val_loss: 1.0651 - val_auc: 0.7583\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.7325 - auc: 0.7831 - val_loss: 1.0541 - val_auc: 0.7756\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.7190 - auc: 0.7920 - val_loss: 1.0693 - val_auc: 0.7797\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.6878 - auc: 0.7989 - val_loss: 1.1485 - val_auc: 0.7736\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.6574 - auc: 0.8137 - val_loss: 1.1908 - val_auc: 0.7735\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.5968 - auc: 0.8321 - val_loss: 1.1784 - val_auc: 0.7888\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 46s 577ms/step - loss: 0.5628 - auc: 0.8359 - val_loss: 1.3047 - val_auc: 0.7395\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.5767 - auc: 0.8346 - val_loss: 1.2239 - val_auc: 0.7632\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.5316 - auc: 0.8436 - val_loss: 1.3322 - val_auc: 0.7542\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.5058 - auc: 0.8391 - val_loss: 1.3134 - val_auc: 0.7722\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 0.4712 - auc: 0.8406 - val_loss: 1.4363 - val_auc: 0.7509\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 46s 577ms/step - loss: 0.4739 - auc: 0.8304 - val_loss: 1.4112 - val_auc: 0.7654\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 46s 579ms/step - loss: 0.4098 - auc: 0.8641 - val_loss: 1.4116 - val_auc: 0.7698\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.4427 - auc: 0.8360 - val_loss: 1.3745 - val_auc: 0.7620\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.3868 - auc: 0.8670 - val_loss: 1.5003 - val_auc: 0.7556\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.3877 - auc: 0.8466 - val_loss: 1.4248 - val_auc: 0.7668\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.3561 - auc: 0.8674 - val_loss: 1.4445 - val_auc: 0.7664\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 46s 577ms/step - loss: 0.3323 - auc: 0.8732 - val_loss: 1.5506 - val_auc: 0.7580\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 0.3211 - auc: 0.8799 - val_loss: 1.5187 - val_auc: 0.7604\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 45s 576ms/step - loss: 0.3297 - auc: 0.8697 - val_loss: 1.4520 - val_auc: 0.7605\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 45s 576ms/step - loss: 0.2986 - auc: 0.8711 - val_loss: 1.5294 - val_auc: 0.7648\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 46s 577ms/step - loss: 0.3044 - auc: 0.8690 - val_loss: 1.4970 - val_auc: 0.7607\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.2834 - auc: 0.8795 - val_loss: 1.5154 - val_auc: 0.7639\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 0.2588 - auc: 0.8812 - val_loss: 1.5121 - val_auc: 0.7592\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 45s 576ms/step - loss: 0.2858 - auc: 0.8744 - val_loss: 1.4778 - val_auc: 0.7609\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 0.2807 - auc: 0.8680 - val_loss: 1.4833 - val_auc: 0.7610\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.2676 - auc: 0.8668 - val_loss: 1.4941 - val_auc: 0.7627\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.2853 - auc: 0.8557 - val_loss: 1.5047 - val_auc: 0.7619\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 46s 577ms/step - loss: 0.2950 - auc: 0.8529 - val_loss: 1.4852 - val_auc: 0.7600\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.2673 - auc: 0.8683 - val_loss: 1.4837 - val_auc: 0.7620\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.2727 - auc: 0.8691 - val_loss: 1.4815 - val_auc: 0.7617\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.2586 - auc: 0.8695 - val_loss: 1.4872 - val_auc: 0.7607\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.2848 - auc: 0.8570 - val_loss: 1.4963 - val_auc: 0.7599\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.2791 - auc: 0.8606 - val_loss: 1.4936 - val_auc: 0.7599\n",
            "#### FOLD 4 without TTA VAL_AUC = 0.802\n",
            "[1267, 1267, 1267, 1267]\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Efficient Model7 has been loaded \n",
            "Epoch 1/50\n",
            "79/79 [==============================] - 825s 834ms/step - loss: 1.3882 - auc: 0.5128 - val_loss: 1.3436 - val_auc: 0.5761\n",
            "Epoch 2/50\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 1.2849 - auc: 0.5508 - val_loss: 1.2111 - val_auc: 0.6142\n",
            "Epoch 3/50\n",
            "79/79 [==============================] - 46s 579ms/step - loss: 1.1155 - auc: 0.6232 - val_loss: 1.0690 - val_auc: 0.6991\n",
            "Epoch 4/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 1.0209 - auc: 0.6599 - val_loss: 0.9644 - val_auc: 0.7462\n",
            "Epoch 5/50\n",
            "79/79 [==============================] - 46s 577ms/step - loss: 1.0127 - auc: 0.6625 - val_loss: 0.9522 - val_auc: 0.7736\n",
            "Epoch 6/50\n",
            "79/79 [==============================] - 46s 582ms/step - loss: 0.9972 - auc: 0.6907 - val_loss: 0.9051 - val_auc: 0.7858\n",
            "Epoch 7/50\n",
            "79/79 [==============================] - 46s 582ms/step - loss: 0.9405 - auc: 0.7163 - val_loss: 0.9088 - val_auc: 0.7804\n",
            "Epoch 8/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.9555 - auc: 0.7055 - val_loss: 0.9544 - val_auc: 0.7883\n",
            "Epoch 9/50\n",
            "79/79 [==============================] - 47s 597ms/step - loss: 0.9451 - auc: 0.7172 - val_loss: 0.9695 - val_auc: 0.7829\n",
            "Epoch 10/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.9252 - auc: 0.7262 - val_loss: 1.1272 - val_auc: 0.7702\n",
            "Epoch 11/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.9081 - auc: 0.7208 - val_loss: 0.9367 - val_auc: 0.8002\n",
            "Epoch 12/50\n",
            "79/79 [==============================] - 46s 578ms/step - loss: 0.8915 - auc: 0.7456 - val_loss: 0.9228 - val_auc: 0.7992\n",
            "Epoch 13/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.8556 - auc: 0.7517 - val_loss: 1.0384 - val_auc: 0.7746\n",
            "Epoch 14/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.8391 - auc: 0.7660 - val_loss: 1.0298 - val_auc: 0.7935\n",
            "Epoch 15/50\n",
            "79/79 [==============================] - 48s 608ms/step - loss: 0.8560 - auc: 0.7567 - val_loss: 1.0651 - val_auc: 0.7762\n",
            "Epoch 16/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.8057 - auc: 0.7678 - val_loss: 1.0023 - val_auc: 0.7870\n",
            "Epoch 17/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.8025 - auc: 0.7734 - val_loss: 0.9762 - val_auc: 0.7912\n",
            "Epoch 18/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.7837 - auc: 0.7797 - val_loss: 1.0051 - val_auc: 0.7837\n",
            "Epoch 19/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.7497 - auc: 0.7868 - val_loss: 1.1024 - val_auc: 0.7904\n",
            "Epoch 20/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.7293 - auc: 0.7979 - val_loss: 1.0927 - val_auc: 0.7865\n",
            "Epoch 21/50\n",
            "79/79 [==============================] - 45s 576ms/step - loss: 0.6871 - auc: 0.8183 - val_loss: 1.1737 - val_auc: 0.7706\n",
            "Epoch 22/50\n",
            "79/79 [==============================] - 46s 582ms/step - loss: 0.6592 - auc: 0.8199 - val_loss: 1.2700 - val_auc: 0.7576\n",
            "Epoch 23/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.6137 - auc: 0.8352 - val_loss: 1.1839 - val_auc: 0.7713\n",
            "Epoch 24/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.6171 - auc: 0.8278 - val_loss: 1.1739 - val_auc: 0.7836\n",
            "Epoch 25/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.5617 - auc: 0.8471 - val_loss: 1.2560 - val_auc: 0.7741\n",
            "Epoch 26/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.5711 - auc: 0.8365 - val_loss: 1.2674 - val_auc: 0.7729\n",
            "Epoch 27/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 0.5396 - auc: 0.8336 - val_loss: 1.4514 - val_auc: 0.7396\n",
            "Epoch 28/50\n",
            "79/79 [==============================] - 45s 577ms/step - loss: 0.5331 - auc: 0.8268 - val_loss: 1.3156 - val_auc: 0.7620\n",
            "Epoch 29/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.4679 - auc: 0.8647 - val_loss: 1.2728 - val_auc: 0.7537\n",
            "Epoch 30/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.4850 - auc: 0.8415 - val_loss: 1.3224 - val_auc: 0.7642\n",
            "Epoch 31/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.4368 - auc: 0.8676 - val_loss: 1.3884 - val_auc: 0.7615\n",
            "Epoch 32/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.4381 - auc: 0.8445 - val_loss: 1.3467 - val_auc: 0.7537\n",
            "Epoch 33/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.3936 - auc: 0.8666 - val_loss: 1.3932 - val_auc: 0.7611\n",
            "Epoch 34/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.3904 - auc: 0.8715 - val_loss: 1.4151 - val_auc: 0.7611\n",
            "Epoch 35/50\n",
            "79/79 [==============================] - 46s 581ms/step - loss: 0.3488 - auc: 0.8790 - val_loss: 1.4379 - val_auc: 0.7520\n",
            "Epoch 36/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.3662 - auc: 0.8675 - val_loss: 1.4129 - val_auc: 0.7585\n",
            "Epoch 37/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.3736 - auc: 0.8677 - val_loss: 1.4237 - val_auc: 0.7623\n",
            "Epoch 38/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.3340 - auc: 0.8731 - val_loss: 1.4502 - val_auc: 0.7539\n",
            "Epoch 39/50\n",
            "79/79 [==============================] - 46s 577ms/step - loss: 0.3260 - auc: 0.8845 - val_loss: 1.4312 - val_auc: 0.7555\n",
            "Epoch 40/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.3097 - auc: 0.8815 - val_loss: 1.4759 - val_auc: 0.7588\n",
            "Epoch 41/50\n",
            "79/79 [==============================] - 45s 574ms/step - loss: 0.3247 - auc: 0.8711 - val_loss: 1.4909 - val_auc: 0.7530\n",
            "Epoch 42/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.3284 - auc: 0.8689 - val_loss: 1.4663 - val_auc: 0.7540\n",
            "Epoch 43/50\n",
            "79/79 [==============================] - 45s 569ms/step - loss: 0.3328 - auc: 0.8748 - val_loss: 1.4475 - val_auc: 0.7563\n",
            "Epoch 44/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.3381 - auc: 0.8601 - val_loss: 1.4515 - val_auc: 0.7585\n",
            "Epoch 45/50\n",
            "79/79 [==============================] - 45s 572ms/step - loss: 0.3440 - auc: 0.8558 - val_loss: 1.4398 - val_auc: 0.7544\n",
            "Epoch 46/50\n",
            "79/79 [==============================] - 45s 570ms/step - loss: 0.3197 - auc: 0.8683 - val_loss: 1.4232 - val_auc: 0.7585\n",
            "Epoch 47/50\n",
            "79/79 [==============================] - 45s 573ms/step - loss: 0.3127 - auc: 0.8715 - val_loss: 1.4294 - val_auc: 0.7591\n",
            "Epoch 48/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.2981 - auc: 0.8789 - val_loss: 1.4262 - val_auc: 0.7585\n",
            "Epoch 49/50\n",
            "79/79 [==============================] - 45s 571ms/step - loss: 0.3284 - auc: 0.8614 - val_loss: 1.4246 - val_auc: 0.7578\n",
            "Epoch 50/50\n",
            "79/79 [==============================] - 45s 575ms/step - loss: 0.3148 - auc: 0.8732 - val_loss: 1.4257 - val_auc: 0.7565\n",
            "#### FOLD 5 without TTA VAL_AUC = 0.800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSXjYZ-Rewt-"
      },
      "source": [
        "#Inference B4512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eZByBYeuDMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "495698f5-7fc9-4250-ce80-243998f83fb3"
      },
      "source": [
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "test_gogo = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-07b08a23789b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_FILENAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_image_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_gogo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TEST_FILENAMES' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hCPkcNNNrPi",
        "outputId": "dc5859a9-e2a1-4aa7-cfee-a3d36289a60f"
      },
      "source": [
        "len(test_gogo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaX722tJhYXh",
        "outputId": "e822843b-c154-4cd5-ef92-308c2095089c"
      },
      "source": [
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "sub_names = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])\n",
        "sub_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['002a34c58c5b758217ed1f584ccbcfe9',\n",
              "       '004f33259ee4aef671c2b95d54e4be68',\n",
              "       '008bdde2af2462e86fd373a445d0f4cd', ...,\n",
              "       'ffaa288c8abca300974f043b57d81521',\n",
              "       'ffc441e0c8b7153844047483a577e7c3',\n",
              "       'ffccf1709d0081d122a1d1f9edbefdf1'], dtype='<U32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuMFk-cMhmly"
      },
      "source": [
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "6LOiSoo6hnfA",
        "outputId": "cb4d6f24-3fb7-4227-85da-d02609af2cce"
      },
      "source": [
        "df_total_sub_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002a34c58c5b758217ed1f584ccbcfe9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>004f33259ee4aef671c2b95d54e4be68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008bdde2af2462e86fd373a445d0f4cd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>009bc039326338823ca3aa84381f17f1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00a2145de1886cb9eb88869c85d74080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>ff91fb82429a27521bbec8569b041f02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>ff9fcc4087ed5e941209aa3fa948e364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>ffaa288c8abca300974f043b57d81521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>ffc441e0c8b7153844047483a577e7c3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>ffccf1709d0081d122a1d1f9edbefdf1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image_name\n",
              "0     002a34c58c5b758217ed1f584ccbcfe9\n",
              "1     004f33259ee4aef671c2b95d54e4be68\n",
              "2     008bdde2af2462e86fd373a445d0f4cd\n",
              "3     009bc039326338823ca3aa84381f17f1\n",
              "4     00a2145de1886cb9eb88869c85d74080\n",
              "...                                ...\n",
              "2995  ff91fb82429a27521bbec8569b041f02\n",
              "2996  ff9fcc4087ed5e941209aa3fa948e364\n",
              "2997  ffaa288c8abca300974f043b57d81521\n",
              "2998  ffc441e0c8b7153844047483a577e7c3\n",
              "2999  ffccf1709d0081d122a1d1f9edbefdf1\n",
              "\n",
              "[3000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "DvkmEybnhuxB",
        "outputId": "a9aa89a9-9785-4caf-d25f-9f91c82c5ed8"
      },
      "source": [
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub\n",
        "#df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_SUB.csv'),index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002a34c58c5b758217ed1f584ccbcfe9</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.002111</td>\n",
              "      <td>0.001013</td>\n",
              "      <td>0.000697</td>\n",
              "      <td>0.001526</td>\n",
              "      <td>0.002502</td>\n",
              "      <td>0.001551</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.001017</td>\n",
              "      <td>0.005805</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.001309</td>\n",
              "      <td>0.195280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>004f33259ee4aef671c2b95d54e4be68</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.002430</td>\n",
              "      <td>0.000818</td>\n",
              "      <td>0.000933</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>0.000899</td>\n",
              "      <td>0.001299</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.001937</td>\n",
              "      <td>0.001803</td>\n",
              "      <td>0.003263</td>\n",
              "      <td>0.000503</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>0.197328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008bdde2af2462e86fd373a445d0f4cd</td>\n",
              "      <td>0.174792</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>0.007077</td>\n",
              "      <td>0.122213</td>\n",
              "      <td>0.002034</td>\n",
              "      <td>0.004011</td>\n",
              "      <td>0.006038</td>\n",
              "      <td>0.022974</td>\n",
              "      <td>0.007495</td>\n",
              "      <td>0.016485</td>\n",
              "      <td>0.003327</td>\n",
              "      <td>0.023178</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>0.018443</td>\n",
              "      <td>0.033101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>009bc039326338823ca3aa84381f17f1</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>0.000667</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.000990</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.000758</td>\n",
              "      <td>0.000430</td>\n",
              "      <td>0.000802</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.199561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00a2145de1886cb9eb88869c85d74080</td>\n",
              "      <td>0.086371</td>\n",
              "      <td>0.000703</td>\n",
              "      <td>0.002839</td>\n",
              "      <td>0.140198</td>\n",
              "      <td>0.002009</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>0.002813</td>\n",
              "      <td>0.008863</td>\n",
              "      <td>0.003644</td>\n",
              "      <td>0.006245</td>\n",
              "      <td>0.003057</td>\n",
              "      <td>0.019245</td>\n",
              "      <td>0.001014</td>\n",
              "      <td>0.005706</td>\n",
              "      <td>0.062666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>ff91fb82429a27521bbec8569b041f02</td>\n",
              "      <td>0.169418</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.034280</td>\n",
              "      <td>0.107503</td>\n",
              "      <td>0.099559</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.036410</td>\n",
              "      <td>0.178246</td>\n",
              "      <td>0.184320</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>0.007016</td>\n",
              "      <td>0.037167</td>\n",
              "      <td>0.001567</td>\n",
              "      <td>0.069370</td>\n",
              "      <td>0.002304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>ff9fcc4087ed5e941209aa3fa948e364</td>\n",
              "      <td>0.195568</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.008906</td>\n",
              "      <td>0.118982</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.002094</td>\n",
              "      <td>0.002883</td>\n",
              "      <td>0.007362</td>\n",
              "      <td>0.006666</td>\n",
              "      <td>0.011426</td>\n",
              "      <td>0.005162</td>\n",
              "      <td>0.045798</td>\n",
              "      <td>0.000817</td>\n",
              "      <td>0.026318</td>\n",
              "      <td>0.010865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>ffaa288c8abca300974f043b57d81521</td>\n",
              "      <td>0.001954</td>\n",
              "      <td>0.002920</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>0.001406</td>\n",
              "      <td>0.004295</td>\n",
              "      <td>0.005929</td>\n",
              "      <td>0.011130</td>\n",
              "      <td>0.022830</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.125751</td>\n",
              "      <td>0.071830</td>\n",
              "      <td>0.002736</td>\n",
              "      <td>0.005590</td>\n",
              "      <td>0.162730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>ffc441e0c8b7153844047483a577e7c3</td>\n",
              "      <td>0.018895</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.021862</td>\n",
              "      <td>0.001242</td>\n",
              "      <td>0.000793</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>0.004114</td>\n",
              "      <td>0.002283</td>\n",
              "      <td>0.002916</td>\n",
              "      <td>0.001685</td>\n",
              "      <td>0.003270</td>\n",
              "      <td>0.000978</td>\n",
              "      <td>0.003354</td>\n",
              "      <td>0.163176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>ffccf1709d0081d122a1d1f9edbefdf1</td>\n",
              "      <td>0.145861</td>\n",
              "      <td>0.095181</td>\n",
              "      <td>0.034802</td>\n",
              "      <td>0.004557</td>\n",
              "      <td>0.008672</td>\n",
              "      <td>0.045669</td>\n",
              "      <td>0.050831</td>\n",
              "      <td>0.070977</td>\n",
              "      <td>0.008625</td>\n",
              "      <td>0.026598</td>\n",
              "      <td>0.189738</td>\n",
              "      <td>0.199768</td>\n",
              "      <td>0.004524</td>\n",
              "      <td>0.194726</td>\n",
              "      <td>0.000403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image_name    class0  ...   class13   class14\n",
              "0     002a34c58c5b758217ed1f584ccbcfe9  0.000875  ...  0.001309  0.195280\n",
              "1     004f33259ee4aef671c2b95d54e4be68  0.001957  ...  0.000784  0.197328\n",
              "2     008bdde2af2462e86fd373a445d0f4cd  0.174792  ...  0.018443  0.033101\n",
              "3     009bc039326338823ca3aa84381f17f1  0.000378  ...  0.000440  0.199561\n",
              "4     00a2145de1886cb9eb88869c85d74080  0.086371  ...  0.005706  0.062666\n",
              "...                                ...       ...  ...       ...       ...\n",
              "2995  ff91fb82429a27521bbec8569b041f02  0.169418  ...  0.069370  0.002304\n",
              "2996  ff9fcc4087ed5e941209aa3fa948e364  0.195568  ...  0.026318  0.010865\n",
              "2997  ffaa288c8abca300974f043b57d81521  0.001954  ...  0.005590  0.162730\n",
              "2998  ffc441e0c8b7153844047483a577e7c3  0.018895  ...  0.003354  0.163176\n",
              "2999  ffccf1709d0081d122a1d1f9edbefdf1  0.145861  ...  0.194726  0.000403\n",
              "\n",
              "[3000 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HAnbQUN5qXv"
      },
      "source": [
        "TTA = True"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jPmlTjd8exx8",
        "outputId": "a6560bb8-b049-437c-efa8-db72f74c1893"
      },
      "source": [
        "#model prediction\n",
        "from sklearn.metrics import average_precision_score\n",
        "TEST_FILENAMES = FILENAMES\n",
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "sub_names = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])\n",
        "\n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [];\n",
        "history_list = []; normal_oof_pred = []; pred_max = []; pred_probs = []; pred_sub_probs = [];\n",
        "sub_pred = [];\n",
        "pred_sub_prob = np.zeros(shape=(count_data_items(TEST_FILENAMES), CFG.NUMBER_OF_CLASSES))\n",
        "def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'imagenet', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x0 = tf.keras.layers.Dropout(0.5)(x0)\n",
        "        x0 = tf.keras.layers.Dense(64, activation='relu')(x0)\n",
        "        x = tf.keras.layers.Dense(CFG.NUMBER_OF_CLASSES, activation='softmax', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=500, warmup_proportion=0.1, min_lr=2e-6)\n",
        "        \n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        #opt =tf.keras.optimizers.Adam(learning_rate=CFG.LEARNING_RATE)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'categorical_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = CFG.N_FOLDS, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        "    #val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    seed_everything(SEED)\n",
        "    model.load_weights(os.path.join(ROOT_PATH, f\"COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"))\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False                   \n",
        "    \n",
        "    ct_valid = count_data_items(VALIDATION_FILENAMES)\n",
        "    \n",
        "    if TTA:\n",
        "########## TTA\n",
        "    ## GET NORMAL OOF\n",
        "        for i in range(CFG.TTA_NUM+1):\n",
        "            if i == 0:\n",
        "                ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "                pred_prob = model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 1)\n",
        "            else:\n",
        "                ds_valid = get_dataset_for_tta(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "                pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 1)\n",
        "\n",
        "########## NO TTA\n",
        "    else:\n",
        "        ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "        pred_prob = model.predict(ds_valid, verbose=1)\n",
        "    \n",
        "    pred_probs.append(pred_prob)\n",
        "\n",
        "\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
        "    oof_folds.append(np.ones_like(oof_tar[-1], dtype='int8')*fold)\n",
        "    ds = get_dataset(VALIDATION_FILENAMES, labeled=False, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds.unbatch())]))\n",
        "    \n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=False)\n",
        "    pred_sub_prob += model.predict(ds_test, verbose=1) / CFG.N_FOLDS\n",
        "    #pred_sub_probs.append(pred_sub_prob)\n",
        "\n",
        "    #ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "    #sub_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())]))\n",
        "\n",
        "\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "#total_sub_names = np.concatenate(sub_names)\n",
        "#total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(CFG.NUMBER_OF_CLASSES)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'(sub)COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.csv'),index=False)\n",
        "print(df_sub)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(CFG.NUMBER_OF_CLASSES)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(CFG.NUMBER_OF_CLASSES)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'(oof)COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.csv.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "ind_class_ap = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "    ind_class_ap.append(average_precision_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"total map:\",np.array(ind_class_ap).mean()*2/3)\n",
        "#print(f\"class {CFG.NUMBER_OF_CLASSES} auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "Efficient Model7 has been loaded \n",
            "[1267]\n",
            "20/20 [==============================] - 23s 138ms/step\n",
            "20/20 [==============================] - 4s 143ms/step\n",
            "20/20 [==============================] - 4s 143ms/step\n",
            "20/20 [==============================] - 4s 145ms/step\n",
            "20/20 [==============================] - 4s 142ms/step\n",
            "99/99 [==============================] - 35s 145ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "Efficient Model7 has been loaded \n",
            "[1267]\n",
            "20/20 [==============================] - 23s 139ms/step\n",
            "20/20 [==============================] - 4s 144ms/step\n",
            "20/20 [==============================] - 4s 142ms/step\n",
            "20/20 [==============================] - 4s 145ms/step\n",
            "20/20 [==============================] - 4s 143ms/step\n",
            "99/99 [==============================] - 35s 144ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "Efficient Model7 has been loaded \n",
            "[1267]\n",
            "20/20 [==============================] - 24s 141ms/step\n",
            "20/20 [==============================] - 4s 145ms/step\n",
            "20/20 [==============================] - 4s 144ms/step\n",
            "20/20 [==============================] - 4s 146ms/step\n",
            "20/20 [==============================] - 4s 144ms/step\n",
            "99/99 [==============================] - 35s 145ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "Efficient Model7 has been loaded \n",
            "[1267]\n",
            "20/20 [==============================] - 24s 139ms/step\n",
            "20/20 [==============================] - 4s 143ms/step\n",
            "20/20 [==============================] - 4s 144ms/step\n",
            "20/20 [==============================] - 4s 147ms/step\n",
            "20/20 [==============================] - 5s 210ms/step\n",
            "99/99 [==============================] - 35s 144ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1267]\n",
            "Efficient Model7 has been loaded \n",
            "[1266]\n",
            "20/20 [==============================] - 24s 140ms/step\n",
            "20/20 [==============================] - 4s 141ms/step\n",
            "20/20 [==============================] - 4s 144ms/step\n",
            "20/20 [==============================] - 4s 143ms/step\n",
            "20/20 [==============================] - 4s 142ms/step\n",
            "99/99 [==============================] - 35s 144ms/step\n",
            "        image_name    class0    class1    class2    class3\n",
            "0     000c3a3f293f  0.249513  0.309366  0.116553  0.324568\n",
            "1     001398f4ff4f  0.772411  0.092160  0.058864  0.076566\n",
            "2     007b2567d83e  0.003349  0.048829  0.002676  0.945146\n",
            "3     001bd15d1891  0.034541  0.103859  0.011111  0.850488\n",
            "4     000a312787f2  0.019858  0.102129  0.009639  0.868375\n",
            "...            ...       ...       ...       ...       ...\n",
            "6329  ffbeafe30b77  0.470692  0.163142  0.047240  0.318927\n",
            "6330  ffcc16bbf428  0.051062  0.088677  0.010254  0.850007\n",
            "6331  ffdc682f7680  0.043759  0.135711  0.012581  0.807949\n",
            "6332  ffd9b6cf2961  0.435957  0.246219  0.149517  0.168307\n",
            "6333  ffe942c8655f  0.000455  0.007980  0.000811  0.990753\n",
            "\n",
            "[6334 rows x 5 columns]\n",
            "total auc: 0.7923934304218596\n",
            "total map: 0.3510911308078371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c3a3f293f</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.245400</td>\n",
              "      <td>0.111061</td>\n",
              "      <td>0.022274</td>\n",
              "      <td>0.621265</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00b0891276a3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.074440</td>\n",
              "      <td>0.090781</td>\n",
              "      <td>0.013611</td>\n",
              "      <td>0.821168</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00e37a390f0f</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010702</td>\n",
              "      <td>0.020213</td>\n",
              "      <td>0.003280</td>\n",
              "      <td>0.965806</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00e3a7e91a34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.361843</td>\n",
              "      <td>0.138582</td>\n",
              "      <td>0.076110</td>\n",
              "      <td>0.423465</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0d4d6acc9ed3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.358434</td>\n",
              "      <td>0.139364</td>\n",
              "      <td>0.060191</td>\n",
              "      <td>0.442011</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_name  target0  target1  target2  ...    class1    class2    class3  fold\n",
              "0  000c3a3f293f      1.0      0.0      0.0  ...  0.111061  0.022274  0.621265     0\n",
              "1  00b0891276a3      0.0      0.0      0.0  ...  0.090781  0.013611  0.821168     0\n",
              "2  00e37a390f0f      0.0      0.0      0.0  ...  0.020213  0.003280  0.965806     0\n",
              "3  00e3a7e91a34      1.0      0.0      0.0  ...  0.138582  0.076110  0.423465     0\n",
              "4  0d4d6acc9ed3      1.0      0.0      0.0  ...  0.139364  0.060191  0.442011     0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "gabhdDkw7fqP",
        "outputId": "258f646b-7960-4f92-d0bc-93885be3f2e2"
      },
      "source": [
        "df_oof[['target0','target1','target2','target3']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c3a3f293f</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044777</td>\n",
              "      <td>0.229694</td>\n",
              "      <td>0.041547</td>\n",
              "      <td>0.683982</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00b0891276a3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.070826</td>\n",
              "      <td>0.166704</td>\n",
              "      <td>0.025137</td>\n",
              "      <td>0.737333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00e37a390f0f</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.075357</td>\n",
              "      <td>0.003436</td>\n",
              "      <td>0.913689</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00e3a7e91a34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0d4d6acc9ed3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6329</th>\n",
              "      <td>fece1740823c</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.296112</td>\n",
              "      <td>0.276682</td>\n",
              "      <td>0.046547</td>\n",
              "      <td>0.380660</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6330</th>\n",
              "      <td>ff23167d20b4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.045188</td>\n",
              "      <td>0.237923</td>\n",
              "      <td>0.060011</td>\n",
              "      <td>0.656877</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6331</th>\n",
              "      <td>ff322f8e36c4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.877586</td>\n",
              "      <td>0.057183</td>\n",
              "      <td>0.005390</td>\n",
              "      <td>0.059840</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6332</th>\n",
              "      <td>ff9f10a24c27</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.949183</td>\n",
              "      <td>0.023384</td>\n",
              "      <td>0.004172</td>\n",
              "      <td>0.023261</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6333</th>\n",
              "      <td>ffbeafe30b77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.293803</td>\n",
              "      <td>0.321225</td>\n",
              "      <td>0.096799</td>\n",
              "      <td>0.288172</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6334 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        image_name  target0  target1  ...    class2    class3  fold\n",
              "0     000c3a3f293f      1.0      0.0  ...  0.041547  0.683982     0\n",
              "1     00b0891276a3      0.0      0.0  ...  0.025137  0.737333     0\n",
              "2     00e37a390f0f      0.0      0.0  ...  0.003436  0.913689     0\n",
              "3     00e3a7e91a34      1.0      0.0  ...  0.049463  0.544704     0\n",
              "4     0d4d6acc9ed3      1.0      0.0  ...  0.049463  0.544704     0\n",
              "...            ...      ...      ...  ...       ...       ...   ...\n",
              "6329  fece1740823c      0.0      0.0  ...  0.046547  0.380660     4\n",
              "6330  ff23167d20b4      0.0      0.0  ...  0.060011  0.656877     4\n",
              "6331  ff322f8e36c4      0.0      0.0  ...  0.005390  0.059840     4\n",
              "6332  ff9f10a24c27      1.0      0.0  ...  0.004172  0.023261     4\n",
              "6333  ffbeafe30b77      0.0      0.0  ...  0.096799  0.288172     4\n",
              "\n",
              "[6334 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "TFQiTe-u6CCx",
        "outputId": "393f346e-4ed8-4575-f56c-2eb5579d1d71"
      },
      "source": [
        "ind_class_roc = []\n",
        "ind_class_ap = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "    ind_class_ap.append(average_precision_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"total map:\",np.array(ind_class_ap).mean()*2/3)\n",
        "#print(f\"class {CFG.NUMBER_OF_CLASSES} auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total auc: 0.7926285606178927\n",
            "total map: 0.3519535713592532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c3a3f293f</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044777</td>\n",
              "      <td>0.229694</td>\n",
              "      <td>0.041547</td>\n",
              "      <td>0.683982</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00b0891276a3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.070826</td>\n",
              "      <td>0.166704</td>\n",
              "      <td>0.025137</td>\n",
              "      <td>0.737333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00e37a390f0f</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.075357</td>\n",
              "      <td>0.003436</td>\n",
              "      <td>0.913689</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00e3a7e91a34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0d4d6acc9ed3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_name  target0  target1  target2  ...    class1    class2    class3  fold\n",
              "0  000c3a3f293f      1.0      0.0      0.0  ...  0.229694  0.041547  0.683982     0\n",
              "1  00b0891276a3      0.0      0.0      0.0  ...  0.166704  0.025137  0.737333     0\n",
              "2  00e37a390f0f      0.0      0.0      0.0  ...  0.075357  0.003436  0.913689     0\n",
              "3  00e3a7e91a34      1.0      0.0      0.0  ...  0.262778  0.049463  0.544704     0\n",
              "4  0d4d6acc9ed3      1.0      0.0      0.0  ...  0.262778  0.049463  0.544704     0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}