{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(Stacked)(AugChange)(김웅곤)(TPU-Effnet-B7-640)Covid19-StudyBaseLine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrHV15YJJshV2NX65gAJyI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kimwoonggon/SIIM-COVID19-KAGGLE/blob/main/(Stacked)(AugChange)(%EA%B9%80%EC%9B%85%EA%B3%A4)(TPU_Effnet_B7_640)Covid19_StudyBaseLine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhbJWFGLTJ9A",
        "outputId": "9f0b6e47-ebdc-4dcc-da3e-5bcffef80836"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU_vL8ic3HcZ",
        "outputId": "9e736003-a957-46ff-8528-c63b9d317dd3"
      },
      "source": [
        "#!pip install tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0\n",
        "#!pip install -U tensorflow-addons==0.9.1\n",
        "!pip install -U tensorflow-addons\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_addons as tfa\n",
        "import requests\n",
        "import os\n",
        "resp = requests.post(\"http://{}:8475/requestversion/{}\".format(os.environ[\"COLAB_TPU_ADDR\"].split(\":\")[0], tf.__version__))\n",
        "if resp.status_code != 200:\n",
        "  print(\"Failed to switch the TPU to TF {}\".format(version))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\r\u001b[K     |▌                               | 10kB 14.1MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 19.5MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 14.4MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 11.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 112kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 143kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 174kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 194kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 204kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 225kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████                     | 235kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 256kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 266kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 286kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 307kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 327kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 348kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 358kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 368kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 378kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 389kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 399kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 409kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 419kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 430kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 440kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 450kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 460kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 471kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 481kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 491kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 501kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 512kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 522kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 532kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 542kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 552kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 563kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 573kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 583kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 593kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 604kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 614kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 624kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 634kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 645kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 655kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 665kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 675kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 686kB 6.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6xX204k2Ktd"
      },
      "source": [
        "!pip install -q efficientnet >> /dev/null"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFPVid4aN0du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9bc766-948b-4d4d-ff86-1b5de8df48dd"
      },
      "source": [
        "import random, re, math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf, tensorflow.keras.backend as K\n",
        "!pip install gcsfs #gcp 파일 로드\n",
        "#from kaggle_datasets import KaggleDatasets\n",
        "from tensorflow.data.experimental import AUTOTUNE\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "import operator\n",
        "import gc\n",
        "import pathlib\n",
        "from scipy import spatial\n",
        "import cv2\n",
        "import functools"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "  Downloading https://files.pythonhosted.org/packages/11/30/306bcaadd0145f55934202c77215e26e73b4c3d81fbdac587d26af38a2ad/gcsfs-2021.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.7/dist-packages (from gcsfs) (1.31.0)\n",
            "Collecting fsspec==2021.06.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/3a/666e63625a19883ae8e1674099e631f9737bd5478c4790e5ad49c5ac5261/fsspec-2021.6.1-py3-none-any.whl (115kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gcsfs) (2.23.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from gcsfs) (4.4.2)\n",
            "Collecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 35.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.7/dist-packages (from gcsfs) (0.4.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.7.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (57.0.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (4.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.2->gcsfs) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gcsfs) (2021.5.30)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 45.8MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gcsfs) (21.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth>=1.2->gcsfs) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.1.1)\n",
            "Installing collected packages: fsspec, async-timeout, multidict, yarl, aiohttp, gcsfs\n",
            "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.6.1 gcsfs-2021.6.1 multidict-5.1.0 yarl-1.6.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NERnp6GCrxgr"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    tf.random.set_seed(seed)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37CFiVVS4Q82",
        "outputId": "ab6fefaf-a685-4281-8b94-ea7d76c3c9df"
      },
      "source": [
        "DEVICE = \"TPU\"\n",
        "if DEVICE == \"TPU\":\n",
        "    print(\"connecting to TPU...\")\n",
        "    try:\n",
        "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "        print('Running on TPU ', tpu.master())\n",
        "    except ValueError:\n",
        "        print(\"Could not connect to TPU\")\n",
        "        tpu = None\n",
        "\n",
        "    if tpu:\n",
        "        try:\n",
        "            print(\"initializing  TPU ...\")\n",
        "            tf.config.experimental_connect_to_cluster(tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "            print(\"TPU initialized\")\n",
        "        except:\n",
        "            print(\"failed to initialize TPU\")\n",
        "    else:\n",
        "        DEVICE = \"GPU\"\n",
        "\n",
        "if DEVICE != \"TPU\":\n",
        "    print(\"Using default strategy for CPU and single GPU\")\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "if DEVICE == \"GPU\":\n",
        "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "    \n",
        "\n",
        "AUTO     = tf.data.experimental.AUTOTUNE\n",
        "REPLICAS = strategy.num_replicas_in_sync\n",
        "print(f'REPLICAS: {REPLICAS}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "connecting to TPU...\n",
            "Running on TPU  grpc://10.5.126.170:8470\n",
            "initializing  TPU ...\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.5.126.170:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.5.126.170:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TPU initialized\n",
            "REPLICAS: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8Ylvljm1eIu",
        "outputId": "f6d32760-abd5-4a76-8735-46daaaedc70e"
      },
      "source": [
        "MIXED_PRECISION = True\n",
        "XLA_ACCELERATE = True\n",
        " \n",
        "if MIXED_PRECISION:\n",
        "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
        "    if tpu: \n",
        "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
        "    else: \n",
        "        policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
        "    mixed_precision.set_policy(policy)\n",
        "    print('Mixed precision enabled')\n",
        " \n",
        "if XLA_ACCELERATE:\n",
        "    tf.config.optimizer.set_jit(True)\n",
        "    print('Accelerated Linear Algebra enabled')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mixed precision enabled\n",
            "Accelerated Linear Algebra enabled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quqZy4Kipt7v"
      },
      "source": [
        "class CFG:\n",
        "    StudyOrTwoClasses = \"study\"\n",
        "    WIDTH = 640\n",
        "    HEIGHT = 640\n",
        "    OBJ_WIDTH = 640\n",
        "    OBJ_HEIGHT = 640\n",
        "    MEAN = (0.485, 0.456, 0.406)\n",
        "    STD = (0.229, 0.224, 0.225)\n",
        "    CHANNELS = 3\n",
        "    \n",
        "    REPLICAS = 8\n",
        "    EPOCHS = 20\n",
        "    BATCH_SIZE = 8 * REPLICAS\n",
        "    AUG_BATCH = BATCH_SIZE\n",
        "    \n",
        "    LEARNING_RATE = 9e-5 * REPLICAS\n",
        "    \n",
        "    NUMBER_OF_CLASSES = 4\n",
        "    RANDAUG_NUM = 2\n",
        "    RANDAUG_MAGNITUDE = 15\n",
        "    N_FOLDS = 5\n",
        " \n",
        "    NET = 7\n",
        "    TTA_NUM = 4\n",
        "    SEED = 100\n",
        "    #GCS_PATH = 'gs://kds-516797a1df892145d5ba2988da2a0e9f80e2aa231cb6453e66962c14'\n",
        "    #GCS_PATH = 'gs://kds-d01a8ccac2f40923bd1e45b9926e5dad01232e523339871333f1162e'\n",
        "    GCS_PATH = \"gs://kds-4caf7edb855d0a688094343b5bc77a518de4f9cada5bde7d12831657\" # Stacked\n",
        "    ROOT_PATH = 'gdrive/My Drive/Colab Notebooks/KAGGLE_COVID19'\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qXd8pFJ1fmR",
        "outputId": "7f6475e3-10d6-44d2-b6e1-36fa0cf7d26a"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import efficientnet.tfkeras as efn\n",
        "import tensorflow.keras.applications as apl\n",
        "# import EfficientNetB0\n",
        "# Configuration\n",
        "effnets = [efn.EfficientNetB0,efn.EfficientNetB1,efn.EfficientNetB2,efn.EfficientNetB3,efn.EfficientNetB4,efn.EfficientNetB5,efn.EfficientNetB6,efn.EfficientNetB7]\n",
        "#effnets = [apl.EfficientNetB0,apl.EfficientNetB1,apl.EfficientNetB2,apl.EfficientNetB3,apl.EfficientNetB4,apl.EfficientNetB5,apl.EfficientNetB6,apl.EfficientNetB7]\n",
        "TTA_NUM = CFG.TTA_NUM\n",
        "TOTALWIDTH = CFG.WIDTH\n",
        "TOTALHEIGHT = CFG.HEIGHT\n",
        "HEIGHT = CFG.OBJ_HEIGHT\n",
        "WIDTH = CFG.OBJ_WIDTH\n",
        "IMAGE_SIZE = [HEIGHT, WIDTH]\n",
        "NET = CFG.NET\n",
        "BATCH_SIZE = CFG.BATCH_SIZE\n",
        "AUG_BATCH = BATCH_SIZE\n",
        "CHANNELS = CFG.CHANNELS\n",
        "AUTO = tf.data.experimental.AUTOTUNE\n",
        " \n",
        "GCS_PATH = CFG.GCS_PATH\n",
        "ROOT_PATH = CFG.ROOT_PATH\n",
        "EPOCHS = CFG.EPOCHS\n",
        "SEED = CFG.SEED\n",
        "LEARNING_RATE = CFG.LEARNING_RATE\n",
        "NUMBER_OF_CLASSES = CFG.NUMBER_OF_CLASSES\n",
        " \n",
        "#class_weight = CFG.CLASS_WEIGHT\n",
        " \n",
        "IMAGE_MEAN = CFG.MEAN\n",
        "IMAGE_STD = CFG.STD \n",
        "FILENAMES = tf.io.gfile.glob(CFG.GCS_PATH+f\"/train_mask_stacked*\")\n",
        "#TEST_FILENAMES = tf.io.gfile.glob(CFG.GCS_PATH+\"/test*\")\n",
        "print(FILENAMES)\n",
        "#print(TEST_FILENAMES)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gs://kds-4caf7edb855d0a688094343b5bc77a518de4f9cada5bde7d12831657/train_mask_stacked00-1267.tfrec', 'gs://kds-4caf7edb855d0a688094343b5bc77a518de4f9cada5bde7d12831657/train_mask_stacked01-1267.tfrec', 'gs://kds-4caf7edb855d0a688094343b5bc77a518de4f9cada5bde7d12831657/train_mask_stacked02-1267.tfrec', 'gs://kds-4caf7edb855d0a688094343b5bc77a518de4f9cada5bde7d12831657/train_mask_stacked03-1267.tfrec', 'gs://kds-4caf7edb855d0a688094343b5bc77a518de4f9cada5bde7d12831657/train_mask_stacked04-1266.tfrec']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SOJUTcaXH2a",
        "outputId": "0369bb68-360f-4712-8d41-c584a2e0ada3"
      },
      "source": [
        "test_image = tf.cast(tf.random.uniform(shape=(1024,1024,3),minval = 0,maxval = 255,dtype=tf.int32), dtype=tf.uint8)\n",
        " \n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from tensorflow_addons.image.utils import to_4D_image, from_4D_image \n",
        "import inspect\n",
        "import math\n",
        "#import tensorflow.compat.v1 as tf\n",
        "#from tensorflow.contrib import image as contrib_image\n",
        "#from tensorflow.contrib import training as contrib_training\n",
        "def blend(image1, image2, factor):\n",
        "  \"\"\"Blend image1 and image2 using 'factor'.\n",
        "  Factor can be above 0.0.  A value of 0.0 means only image1 is used.\n",
        "  A value of 1.0 means only image2 is used.  A value between 0.0 and\n",
        "  1.0 means we linearly interpolate the pixel values between the two\n",
        "  images.  A value greater than 1.0 \"extrapolates\" the difference\n",
        "  between the two pixel values, and we clip the results to values\n",
        "  between 0 and 255.\n",
        "  Args:\n",
        "    image1: An image Tensor of type uint8.\n",
        "    image2: An image Tensor of type uint8.\n",
        "    factor: A floating point value above 0.0.\n",
        "  Returns:\n",
        "    A blended image Tensor of type uint8.\n",
        "  \"\"\"\n",
        "  if factor == 0.0:\n",
        "    return tf.convert_to_tensor(image1)\n",
        "  if factor == 1.0:\n",
        "    return tf.convert_to_tensor(image2)\n",
        " \n",
        "  image1 = tf.cast(image1, dtype=tf.float32)\n",
        "  image2 = tf.cast(image2, dtype=tf.float32)\n",
        " \n",
        "  difference = image2 - image1\n",
        "  scaled = factor * difference\n",
        " \n",
        "  # Do addition in float.\n",
        "  temp = tf.cast(image1, dtype=tf.float32) + scaled\n",
        " \n",
        "  # Interpolate\n",
        "  if factor > 0.0 and factor < 1.0:\n",
        "    # Interpolation means we always stay within 0 and 255.\n",
        "    return tf.cast(temp, tf.uint8)\n",
        " \n",
        "  # Extrapolate:\n",
        "  #\n",
        "  # We need to clip and then cast.\n",
        "  return tf.cast(tf.clip_by_value(temp, 0.0, 255.0), tf.uint8)\n",
        "def Identity(image, _):\n",
        "    return image\n",
        "#Identity(test_image, 3)\n",
        "def AutoContrast(image, _):\n",
        "  \"\"\"Implements Autocontrast function from PIL using TF ops.\n",
        "  Args:\n",
        "    image: A 3D uint8 tensor.\n",
        "  Returns:\n",
        "    The image after it has had autocontrast applied to it and will be of type\n",
        "    uint8.\n",
        "  \"\"\"\n",
        " \n",
        "  def scale_channel(image):\n",
        "    \"\"\"Scale the 2D image using the autocontrast rule.\"\"\"\n",
        "    # A possibly cheaper version can be done using cumsum/unique_with_counts\n",
        "    # over the histogram values, rather than iterating over the entire image.\n",
        "    # to compute mins and maxes.\n",
        "    lo = tf.cast(tf.reduce_min(image), dtype = tf.float32)\n",
        "    hi = tf.cast(tf.reduce_max(image), dtype = tf.float32)\n",
        " \n",
        "    # Scale the image, making the lowest value 0 and the highest value 255.\n",
        "    def scale_values(im):\n",
        "        scale = 255.0 / (hi - lo)\n",
        "        offset = -lo * scale\n",
        "        im = tf.cast(im, dtype=tf.float32) * scale + offset\n",
        "        im = tf.clip_by_value(im, 0.0, 255.0)\n",
        "        return tf.cast(im, tf.uint8)\n",
        " \n",
        "    result = tf.cond(hi > lo, lambda: scale_values(image), lambda: image)\n",
        "    return result\n",
        " \n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image[:, :, 0])\n",
        "  s2 = scale_channel(image[:, :, 1])\n",
        "  s3 = scale_channel(image[:, :, 2])\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        " \n",
        "AutoContrast(test_image, 3)\n",
        "def Equalize(image, _):\n",
        "  \"\"\"Implements Equalize function from PIL using TF ops.\"\"\"\n",
        "  def scale_channel(im, c):\n",
        "    \"\"\"Scale the data in the channel to implement equalize.\"\"\"\n",
        "    im = tf.cast(im[:, :, c], tf.int32)\n",
        "    # Compute the histogram of the image channel.\n",
        "    histo = tf.histogram_fixed_width(im, [0, 255], nbins=256)\n",
        " \n",
        "    # For the purposes of computing the step, filter out the nonzeros.\n",
        "    nonzero = tf.where(tf.not_equal(histo, 0))\n",
        "    nonzero_histo = tf.reshape(tf.gather(histo, nonzero), [-1])\n",
        "    step = (tf.reduce_sum(nonzero_histo) - nonzero_histo[-1]) // 255\n",
        " \n",
        "    def build_lut(histo, step):\n",
        "      # Compute the cumulative sum, shifting by step // 2\n",
        "      # and then normalization by step.\n",
        "      lut = (tf.cumsum(histo) + (step // 2)) // step\n",
        "      # Shift lut, prepending with 0.\n",
        "      lut = tf.concat([[0], lut[:-1]], 0)\n",
        "      # Clip the counts to be in range.  This is done\n",
        "      # in the C code for image.point.\n",
        "      return tf.clip_by_value(lut, 0, 255)\n",
        " \n",
        "    # If step is zero, return the original image.  Otherwise, build\n",
        "    # lut from the full histogram and step and then index from it.\n",
        "    result = tf.cond(tf.equal(step, 0),\n",
        "                     lambda: im,\n",
        "                     lambda: tf.gather(build_lut(histo, step), im))\n",
        " \n",
        "    return tf.cast(result, tf.uint8)\n",
        " \n",
        "  # Assumes RGB for now.  Scales each channel independently\n",
        "  # and then stacks the result.\n",
        "  s1 = scale_channel(image, 0)\n",
        "  s2 = scale_channel(image, 1)\n",
        "  s3 = scale_channel(image, 2)\n",
        "  image = tf.stack([s1, s2, s3], 2)\n",
        "  return image\n",
        "Equalize(test_image, 1)\n",
        "def Rotate(image, degrees):\n",
        "  \"\"\"Rotates the image by degrees either clockwise or counterclockwise.\n",
        "  Args:\n",
        "    image: An image Tensor of type uint8.\n",
        "    degrees: Float, a scalar angle in degrees to rotate all images by. If\n",
        "      degrees is positive the image will be rotated clockwise otherwise it will\n",
        "      be rotated counterclockwise.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels caused by\n",
        "      the rotate operation.\n",
        "  Returns:\n",
        "    The rotated version of image.\n",
        "  \"\"\"\n",
        "  # Convert from degrees to radians.\n",
        "  degrees = int(degrees)\n",
        "  degrees_to_radians = math.pi / 180.0\n",
        "  radians = degrees * degrees_to_radians\n",
        " \n",
        "  # In practice, we should randomize the rotation degrees by flipping\n",
        "  # it negatively half the time, but that's done on 'degrees' outside\n",
        "  # of the function.\n",
        "  #image = contrib_image.rotate(wrap(image), radians)\n",
        "  image = tfa.image.rotate(image, radians)\n",
        "  #return unwrap(image, replace)\n",
        "  return image\n",
        "Rotate(test_image, 30.1)\n",
        "def Solarize(image, threshold=128):\n",
        "  # For each pixel in the image, select the pixel\n",
        "  # if the value is less than the threshold.\n",
        "  # Otherwise, subtract 255 from the pixel.\n",
        "  #image = tf.convert_to_tensor(image, dtype=tf.int32)\n",
        "  #print(image)\n",
        "  \n",
        "  threshold = tf.cast(threshold, dtype=tf.uint8)\n",
        "  #print(threshold)\n",
        "  minus_value = tf.constant(255, dtype=tf.uint8)\n",
        "  #print(minus_value)\n",
        "  return tf.where(image < threshold, image, minus_value - image)\n",
        "Solarize(test_image, 10.0)\n",
        "def Color(image, factor):\n",
        "  \"\"\"Equivalent of PIL Color.\"\"\"\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(image))\n",
        "  #factor = tf.cast(factor, dtype=tf.float32)\n",
        "  return blend(degenerate, image, factor)\n",
        "Color(test_image, 10.1)\n",
        " \n",
        " \n",
        " \n",
        "def Posterize(image, bits):\n",
        " \n",
        "  bits=int(bits)\n",
        "  #print(bits)\n",
        "  \"\"\"Equivalent of PIL Posterize.\"\"\"\n",
        "  shift = 8 - bits\n",
        "  #print(shift)\n",
        "  #print(image)\n",
        "  return tf.bitwise.left_shift(tf.bitwise.right_shift(image, shift), shift)\n",
        "Posterize(test_image, 1.1)\n",
        "def Contrast(image, factor):\n",
        "  \"\"\"Equivalent of PIL Contrast.\"\"\"\n",
        "  degenerate = tf.image.rgb_to_grayscale(image)\n",
        "  # Cast before calling tf.histogram.\n",
        "  degenerate = tf.cast(degenerate, tf.int32)\n",
        " \n",
        "  # Compute the grayscale histogram, then compute the mean pixel value,\n",
        "  # and create a constant image size of that value.  Use that as the\n",
        "  # blending degenerate target of the original image.\n",
        "  hist = tf.histogram_fixed_width(degenerate, [0, 255], nbins=256)\n",
        "  mean = tf.reduce_sum(tf.cast(hist, tf.float32)) / 256.0\n",
        "  degenerate = tf.ones_like(degenerate, dtype=tf.float32) * mean\n",
        "  degenerate = tf.clip_by_value(degenerate, 0.0, 255.0)\n",
        "  degenerate = tf.image.grayscale_to_rgb(tf.cast(degenerate, tf.uint8))\n",
        "  return blend(degenerate, image, factor)\n",
        "Contrast(test_image, 10.1)\n",
        "def Brightness(image, factor):\n",
        "  \"\"\"Equivalent of PIL Brightness.\"\"\"\n",
        "  degenerate = tf.zeros_like(image)\n",
        "  return blend(degenerate, image, factor)\n",
        "Brightness(test_image, 10.1)\n",
        "def _sharpness_image(image, factor):\n",
        "    orig_image = image\n",
        "    image_dtype = image.dtype\n",
        "    image_channels = image.shape[-1]\n",
        "    image = tf.cast(image, tf.float32)\n",
        " \n",
        "    # SMOOTH PIL Kernel.\n",
        "    kernel = (\n",
        "        tf.constant(\n",
        "            [[1, 1, 1], [1, 5, 1], [1, 1, 1]], dtype=tf.float32, shape=[3, 3, 1, 1]\n",
        "        )\n",
        "        / 13.0\n",
        "    )\n",
        "    kernel = tf.tile(kernel, [1, 1, image_channels, 1])\n",
        " \n",
        "    # Apply kernel channel-wise.\n",
        "    degenerate = tf.nn.depthwise_conv2d(\n",
        "        image, kernel, strides=[1, 1, 1, 1], padding=\"VALID\", dilations=[1, 1]\n",
        "    )\n",
        "    degenerate = tf.cast(degenerate, image_dtype)\n",
        " \n",
        "    # For the borders of the resulting image, fill in the values of the original image.\n",
        "    mask = tf.ones_like(degenerate)\n",
        "    padded_mask = tf.pad(mask, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "    padded_degenerate = tf.pad(degenerate, [[0, 0], [1, 1], [1, 1], [0, 0]])\n",
        "    result = tf.where(tf.equal(padded_mask, 1), padded_degenerate, orig_image)\n",
        " \n",
        "    # Blend the final result.\n",
        "    blended = blend(result, orig_image, factor)\n",
        "    return tf.cast(blended, image_dtype)\n",
        " \n",
        " \n",
        "def Sharpness(image, factor):\n",
        "    \n",
        "        image_dims = tf.rank(image)\n",
        "        image = to_4D_image(image)\n",
        "        image = _sharpness_image(image, factor=factor)\n",
        "        return from_4D_image(image, image_dims)\n",
        "    #return tfa.image.sharpness(image, factor)\n",
        "Sharpness(test_image, 10.1)\n",
        " \n",
        "def ShearX(image, level):\n",
        "  \"\"\"Equivalent of PIL Shearing in X dimension.\"\"\"\n",
        "  # Shear parallel to x axis is a projective transform\n",
        "  # with a matrix form of:\n",
        "  # [1  level\n",
        "  #  0  1].\n",
        "  #image = contrib_image.transform(\n",
        "  #    wrap(image), [1., level, 0., 0., 1., 0., 0., 0.])\n",
        "  #return unwrap(image, replace)\n",
        "  \n",
        "  return tfa.image.shear_x(image, level, 0)\n",
        "ShearX(test_image,10)\n",
        "def ShearY(image, level):\n",
        "  \"\"\"Equivalent of PIL Shearing in Y dimension.\"\"\"\n",
        "  # Shear parallel to y axis is a projective transform\n",
        "  # with a matrix form of:\n",
        "  # [1  0\n",
        "  #  level  1].\n",
        "  #image = contrib_image.transform(\n",
        "  #    wrap(image), [1., 0., 0., level, 1., 0., 0., 0.])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.shear_y(image, level, 0)\n",
        "ShearX(test_image,20)\n",
        "def wrap(image):\n",
        "  \"\"\"Returns 'image' with an extra channel set to all 1s.\"\"\"\n",
        "  shape = tf.shape(image)\n",
        "  extended_channel = tf.ones([shape[0], shape[1], 1], image.dtype)\n",
        "  extended = tf.concat([image, extended_channel], 2)\n",
        "  return extended\n",
        " \n",
        "def unwrap(image, replace):\n",
        "  \"\"\"Unwraps an image produced by wrap.\n",
        "  Where there is a 0 in the last channel for every spatial position,\n",
        "  the rest of the three channels in that spatial dimension are grayed\n",
        "  (set to 128).  Operations like translate and shear on a wrapped\n",
        "  Tensor will leave 0s in empty locations.  Some transformations look\n",
        "  at the intensity of values to do preprocessing, and we want these\n",
        "  empty pixels to assume the 'average' value, rather than pure black.\n",
        "  Args:\n",
        "    image: A 3D Image Tensor with 4 channels.\n",
        "    replace: A one or three value 1D tensor to fill empty pixels.\n",
        "  Returns:\n",
        "    image: A 3D image Tensor with 3 channels.\n",
        "  \"\"\"\n",
        "  image_shape = tf.shape(image)\n",
        "  # Flatten the spatial dimensions.\n",
        "  flattened_image = tf.reshape(image, [-1, image_shape[2]])\n",
        " \n",
        "  # Find all pixels where the last channel is zero.\n",
        "  alpha_channel = flattened_image[:, 3]\n",
        " \n",
        "  replace = tf.concat([replace, tf.ones([1], image.dtype)], 0)\n",
        " \n",
        "  # Where they are zero, fill them in with 'replace'.\n",
        "  flattened_image = tf.where(\n",
        "      tf.equal(alpha_channel, 0),\n",
        "      tf.ones_like(flattened_image, dtype=image.dtype) * replace,\n",
        "      flattened_image)\n",
        " \n",
        "  image = tf.reshape(flattened_image, image_shape)\n",
        "  image = tf.slice(image, [0, 0, 0], [image_shape[0], image_shape[1], 3])\n",
        "  return image\n",
        " \n",
        "def TranslateX(image, pixels):\n",
        "  \"\"\"Equivalent of PIL Translate in X dimension.\"\"\"\n",
        "  #image = contrib_image.translate(wrap(image), [-pixels, 0])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.translate_xy(image, [pixels, 0], replace=0)\n",
        "TranslateX(test_image, 10)\n",
        "def TranslateY(image, pixels):\n",
        "  \"\"\"Equivalent of PIL Translate in Y dimension.\"\"\"\n",
        "  #image = contrib_image.translate(wrap(image), [0, -pixels])\n",
        "  #return unwrap(image, replace)\n",
        "  return tfa.image.translate_xy(image, [0, pixels], replace=0)\n",
        "TranslateY(test_image, 10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1024, 1024, 3), dtype=uint8, numpy=\n",
              "array([[[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       [[  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        ...,\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0],\n",
              "        [  0,   0,   0]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 20,  68,  85],\n",
              "        [144,  45,   8],\n",
              "        [146, 198,  20],\n",
              "        ...,\n",
              "        [159, 164,  35],\n",
              "        [168,  99,   7],\n",
              "        [ 34, 181,  61]],\n",
              "\n",
              "       [[248,  72, 197],\n",
              "        [188, 211, 252],\n",
              "        [143,  72,  80],\n",
              "        ...,\n",
              "        [  1,  26,  69],\n",
              "        [253, 181,  37],\n",
              "        [250, 210, 198]],\n",
              "\n",
              "       [[236,  48, 171],\n",
              "        [202, 187, 103],\n",
              "        [120, 187, 225],\n",
              "        ...,\n",
              "        [177,  81,  18],\n",
              "        [126, 157,  75],\n",
              "        [152, 170,  18]]], dtype=uint8)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws5Tg2JZpE7g"
      },
      "source": [
        "class RandomResizedCrop:\n",
        "    \"\"\"Torchvision's variant of crop a random part of the input and rescale it to some size.\n",
        "    Args:\n",
        "        height (int): height after crop and resize.\n",
        "        width (int): width after crop and resize.\n",
        "        scale ((float, float)): range of size of the origin size cropped\n",
        "        ratio ((float, float)): range of aspect ratio of the origin aspect ratio cropped\n",
        "        interpolation (OpenCV flag): flag that is used to specify the interpolation algorithm. Should be one of:\n",
        "            cv2.INTER_NEAREST, cv2.INTER_LINEAR, cv2.INTER_CUBIC, cv2.INTER_AREA, cv2.INTER_LANCZOS4.\n",
        "            Default: cv2.INTER_LINEAR.\n",
        "        p (float): probability of applying the transform. Default: 1.\n",
        "    Targets:\n",
        "        image, mask, bboxes, keypoints\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        height,\n",
        "        width,\n",
        "        org_height,\n",
        "        org_width,\n",
        "        scale=(0.08, 1.0),\n",
        "        ratio=(0.75, 1.3333333333333333),\n",
        "    ):\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.scale = scale\n",
        "        self.ratio = ratio\n",
        "        self.beforeheight = org_height\n",
        "        self.beforewidth = org_width\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_random_crop_coords(height, width, crop_height, crop_width, h_start, w_start):\n",
        "        x1 = int((height - crop_height) * h_start)\n",
        "        x2 = x1 + crop_height\n",
        "        y1 = int((width - crop_width) * w_start)\n",
        "        y2 = y1 + crop_width\n",
        "        return x1, y1, x2, y2\n",
        "    \n",
        "    def __call__(self, img):\n",
        "\n",
        "        \n",
        "        area = img.shape[0] * img.shape[1]\n",
        "        #print(img.shape[0], img.shape[1])\n",
        "        for _attempt in range(10):\n",
        "            target_area = random.uniform(*self.scale) * area\n",
        "            log_ratio = (math.log(self.ratio[0]), math.log(self.ratio[1]))\n",
        "            aspect_ratio = math.exp(random.uniform(*log_ratio))\n",
        "\n",
        "            w = int(round(math.sqrt(target_area * aspect_ratio)))  # skipcq: PTC-W0028\n",
        "            h = int(round(math.sqrt(target_area / aspect_ratio)))  # skipcq: PTC-W0028\n",
        "            #print(w, h)\n",
        "            if 0 < w <= img.shape[1] and 0 < h <= img.shape[0]:\n",
        "                i = random.randint(0, img.shape[0] - h)\n",
        "                j = random.randint(0, img.shape[1] - w)\n",
        "                h_start = i * 1.0 / (img.shape[0] - h + 1e-10)\n",
        "                w_start = j * 1.0 / (img.shape[1] - w + 1e-10)\n",
        "                #print(h, w)\n",
        "                x1, y1, x2, y2 = self.get_random_crop_coords(self.beforeheight, self.beforewidth, h, w, h_start, w_start)\n",
        "                #print(h, w)\n",
        "                #print(x1, y1, x2, y2)\n",
        "                #print(x1, y1, x2, y2)\n",
        "                img = img[x1:x2, y1:y2, :]\n",
        "                img = tf.image.resize(img, (self.height, self.width))\n",
        "                return tf.cast(img, dtype=tf.uint8)\n",
        "\n",
        "        # Fallback to central crop\n",
        "        #print('central gogo')\n",
        "        in_ratio = img.shape[1] / img.shape[0]\n",
        "        if in_ratio < min(self.ratio):\n",
        "            w = img.shape[1]\n",
        "            h = int(round(w / min(self.ratio)))\n",
        "        elif in_ratio > max(self.ratio):\n",
        "            h = img.shape[0]\n",
        "            w = int(round(h * max(self.ratio)))\n",
        "        else:  # whole image\n",
        "            w = img.shape[1]\n",
        "            h = img.shape[0]\n",
        "        i = (img.shape[0] - h) // 2\n",
        "        j = (img.shape[1] - w) // 2\n",
        "        x1, y1, x2, y2 = self.get_random_crop_coords(self.beforeheight, self.beforewidth, h, w, i, j)\n",
        "        img = img[x1:x2, y1:y2, :]\n",
        "        img = tf.image.resize(img, (self.height, self.width))\n",
        "        return tf.cast(img, dtype=tf.uint8)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDDsiU6PE6Zm"
      },
      "source": [
        "class Normalize:\n",
        "    \"\"\"Divide pixel values by 255 = 2**8 - 1, subtract mean per channel and divide by std per channel.\n",
        "    Args:\n",
        "        mean (float, list of float): mean values\n",
        "        std  (float, list of float): std values\n",
        "        max_pixel_value (float): maximum possible pixel value\n",
        "    Targets:\n",
        "        image\n",
        "    Image types:\n",
        "        uint8, float32\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, mean=CFG.MEAN, std=CFG.STD, max_pixel_value=255.0, always_apply=False, p=1.0\n",
        "    ):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.max_pixel_value = max_pixel_value\n",
        "\n",
        "\n",
        "    \n",
        "    def normalize_image(self, img, mean, std, max_pixel_value=255.0):\n",
        "        mean = tf.convert_to_tensor(mean, dtype=tf.float32)\n",
        "        mean = mean * max_pixel_value\n",
        "\n",
        "        std = tf.convert_to_tensor(std, dtype=tf.float32)\n",
        "        std = std * max_pixel_value\n",
        "\n",
        "        denominator = tf.math.reciprocal(std)\n",
        "\n",
        "        #print('before cast', img)\n",
        "        img = tf.cast(img, dtype = tf.float32)\n",
        "        #print('after cast', img)\n",
        "        #img = img - mean\n",
        "        #img = img * denominator\n",
        "        img = img / 255.\n",
        "        return img\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.normalize_image(img, self.mean, self.std)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ivUmviTzRd6"
      },
      "source": [
        "import random\n",
        "class CoarseDropout:\n",
        "  def __init__(self, max_holes, size=0.06):\n",
        "    self.size = size\n",
        "    self.max_holes = max_holes\n",
        "\n",
        "\n",
        "  def __call__(self, image):\n",
        "      #holes = []\n",
        "      P = random.uniform(0,1)\n",
        "      #P = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        "      height = image.shape[0]\n",
        "      width = image.shape[1]\n",
        "      for _n in range(self.max_holes):\n",
        "          hole_height = height * self.size * P\n",
        "          hole_width = width * self.size * P\n",
        "          hole_height = int(hole_height)\n",
        "          hole_width = int(hole_width)\n",
        "          y1 = random.randint(0, int(height - hole_height))\n",
        "          #y1 = tf.random.uniform(0, height - hole_height, dtype=tf.int32)\n",
        "          x1 = random.randint(0, int(width- hole_width))\n",
        "          y2 = y1 + hole_height\n",
        "          x2 = x1 + hole_width\n",
        "          #holes.append((y1, x1, y2, x2))\n",
        "        \n",
        "          one = image[y1:y2,0:x1,:]\n",
        "          two = tf.zeros([y2-y1,x2-x1,3], dtype=tf.float32) \n",
        "          three = image[y1:y2,x2:width,:]\n",
        "          middle = tf.concat([one,two,three],axis=1)\n",
        "          image = tf.concat([image[0:y1,:,:],middle,image[y2:height,:,:]],axis=0)\n",
        "      \n",
        "          \n",
        "      image = tf.cast(image, dtype=tf.float32)\n",
        "      return image"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qtmKcRRnLJS"
      },
      "source": [
        "def augment_list():\n",
        " \n",
        "  l = [  #(Identity, 0, 1),\n",
        "        #(AutoContrast, 0, 1),\n",
        "        #(Equalize, 0, 1),\n",
        "        (Rotate, -20, 20),\n",
        "        #(Posterize, 0, 4),\n",
        "        #(Solarize, 0, 256),\n",
        "        #(Color, 0.1, 1.9),\n",
        "        (Contrast, 0.1, 1.9),\n",
        "        (Brightness, 0.1, 1.9),\n",
        "        #(Sharpness, 0.1, 1.9),\n",
        "        (ShearX, -0.1, 0.1),\n",
        "        (ShearY, -0.1, 0.1),\n",
        "        (TranslateX, -CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "        (TranslateY, -CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "    ]\n",
        "  return l"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tzakJMqhjAY"
      },
      "source": [
        "def augment_list_tta():\n",
        " \n",
        "  l = [  #(Identity, 0, 1),\n",
        "        #(AutoContrast, 0, 1),\n",
        "        #(Equalize, 0, 1),\n",
        "        #(Rotate, -15, 15),\n",
        "        #(Posterize, 0, 4),\n",
        "        #(Solarize, 0, 256),\n",
        "        #(Color, 0.1, 1.9),\n",
        "        #(Contrast, 0.1, 1.9),\n",
        "        (Brightness, 0.1, 1.9),\n",
        "        #(Sharpness, 0.1, 1.9),\n",
        "        #(ShearX, -0.1, 0.1),\n",
        "        #(ShearY, -0.1, 0.1),\n",
        "        #(TranslateX, -CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_WIDTH * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "        #(TranslateY, -CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE, CFG.OBJ_HEIGHT * 0.0625 * 30 / CFG.RANDAUG_MAGNITUDE),\n",
        "    ]\n",
        "  return l"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYyHDbDpnfBk"
      },
      "source": [
        "import random\n",
        "class RandAugment:\n",
        "    def __init__(self, n, m):\n",
        "        self.n = n\n",
        "        self.m = m      # [0, 30]\n",
        "        self.augment_list = augment_list()\n",
        " \n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_list, k=self.n)\n",
        "        for op, minval, maxval in ops:\n",
        "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
        "            img = op(img, val)\n",
        " \n",
        " \n",
        "        return img"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykrpFND_rQ-p"
      },
      "source": [
        "import random\n",
        "class RandAugmentTTA:\n",
        "    def __init__(self, n, m):\n",
        "        self.n = n\n",
        "        self.m = m      # [0, 30]\n",
        "        self.augment_list = augment_list_tta()\n",
        " \n",
        "    def __call__(self, img):\n",
        "        ops = random.choices(self.augment_list, k=self.n)\n",
        "        for op, minval, maxval in ops:\n",
        "            val = (float(self.m) / 30) * float(maxval - minval) + minval\n",
        "            img = op(img, val)\n",
        " \n",
        " \n",
        "        return img"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB4CyRdNAKS4"
      },
      "source": [
        "randomaugtta = RandAugmentTTA(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "randaugtta = RandAugmentTTA(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oqGkm0mLoW0"
      },
      "source": [
        "def cutmix(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with cutmix applied\n",
        "    #print(image.shape, label.shape)\n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.BATCH_SIZE\n",
        "    cutmix_start = 0.0\n",
        "    imgs = []; labs = []\n",
        "    \n",
        "    image = tf.image.resize(image, size=(DIM1, DIM2))\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO CUTMIX WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],cutmix_start,1)<=PROBABILITY, tf.int32)\n",
        "        # CHOOSE RANDOM IMAGE TO CUTMIX WITH\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        # CHOOSE RANDOM LOCATION\n",
        "        x = tf.cast( tf.random.uniform([],0,DIM2),tf.int32)\n",
        "        y = tf.cast( tf.random.uniform([],0,DIM1),tf.int32)\n",
        "        a = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32)\n",
        "        b = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32) # this is beta dist with alpha=1.0\n",
        "        WIDTH = tf.cast( DIM2 * tf.math.sqrt(1-a),tf.int32) * P\n",
        "        HEIGHT = tf.cast( DIM1 * tf.math.sqrt(1-b), tf.int32) * P\n",
        "        ya = tf.math.maximum(0,y-HEIGHT//2)\n",
        "        yb = tf.math.minimum(DIM1,y+HEIGHT//2)\n",
        "        xa = tf.math.maximum(0,x-WIDTH//2)\n",
        "        xb = tf.math.minimum(DIM2,x+WIDTH//2)\n",
        "        # MAKE CUTMIX IMAGE\n",
        "        one = image[j,ya:yb,0:xa,:]\n",
        "        two = image[k,ya:yb,xa:xb,:]\n",
        "        three = image[j,ya:yb,xb:DIM2,:]\n",
        "        middle = tf.concat([one,two,three],axis=1)\n",
        "        cutmix_img = tf.concat([image[j,0:ya,:,:],middle,image[j,yb:DIM1,:,:]],axis=0)\n",
        "        p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        if p_flip > 0.5:\n",
        "            cutmix_img = tf.image.flip_left_right(cutmix_img)\n",
        "        if p_v_flip > 0.5:\n",
        "            cutmix_img = tf.image.flip_up_down(cutmix_img)\n",
        "        if p_transpose > 0.5:\n",
        "            cutmix_img = tf.image.transpose(cutmix_img)\n",
        "        #cutmix_img = Normalize(CFG.MEAN, CFG.STD)(cutmix_img)\n",
        "        #cutmix_img = tf.image.resize(cutmix_img, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        #mixup_image = (1-a)*img1 + a*img2\n",
        "        cutmix_img = Normalize(CFG.MEAN, CFG.STD)(cutmix_img)\n",
        "        #mixup_image = tf.image.resize(mixup_image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        #imgs.append(mixup_image)\n",
        "        imgs.append(cutmix_img)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        a = tf.cast(WIDTH*HEIGHT/DIM1/DIM2,tf.float32)\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2\n",
        " \n",
        " \n",
        " \n",
        "def mixup(image, label, PROBABILITY = 1.0):\n",
        "    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n",
        "    # output - a batch of images with mixup applied\n",
        "    AUG_BATCH = CFG.BATCH_SIZE\n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    \n",
        "    imgs = []; labs = []\n",
        "    image = tf.image.resize(image, size=(DIM1, DIM2))\n",
        "    image = tf.cast(image, dtype=tf.float32)\n",
        "    for j in range(AUG_BATCH):\n",
        "        # DO MIXUP WITH PROBABILITY DEFINED ABOVE\n",
        "        P = tf.cast( tf.random.uniform([],0,1)<=PROBABILITY, tf.float32)\n",
        "        # CHOOSE RANDOM\n",
        "        k = tf.cast( tf.random.uniform([],0,AUG_BATCH),tf.int32)\n",
        "        a = tf.cast(np.random.beta(0.3,0.3), dtype=tf.float32)*P # this is beta dist with alpha=1.0\n",
        "        # MAKE MIXUP IMAGE\n",
        "        img1 = image[j,]\n",
        "        img2 = image[k,]\n",
        "        #mixup_image = (1-0.5)*img1 + 0.5*img2\n",
        "        mixup_image = (1-a)*img1 + a*img2\n",
        "        p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        #p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        #p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "        if p_flip > 0.5:\n",
        "            mixup_image = tf.image.flip_left_right(mixup_image)\n",
        "        #if p_v_flip > 0.5:\n",
        "        #    mixup_image = tf.image.flip_up_down(mixup_image)\n",
        "        #if p_transpose > 0.5:\n",
        "        #    mixup_image = tf.image.transpose(mixup_image)\n",
        "        #mixup_image = Normalize(CFG.MEAN, CFG.STD)(mixup_image)\n",
        "        mixup_image = tf.image.resize(mixup_image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "        mixup_image = tf.cast(mixup_image, tf.float32) / 255.\n",
        "        imgs.append(mixup_image)\n",
        "        # MAKE CUTMIX LABEL\n",
        "        if len(label.shape)==1:\n",
        "            lab1 = tf.one_hot(label[j],CLASSES)\n",
        "            lab2 = tf.one_hot(label[k],CLASSES)\n",
        "        else:\n",
        "            lab1 = label[j,]\n",
        "            lab2 = label[k,]\n",
        "        labs.append((1-a)*lab1 + a*lab2)\n",
        "            \n",
        "    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n",
        "    image2 = tf.reshape(tf.stack(imgs),(AUG_BATCH,CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH,3))\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        "    return image2,label2"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0fwjv7RQnAi"
      },
      "source": [
        "def rectangular_zoom(image, mag=0.2):\n",
        "    s = 1 + tf.random.uniform([], -1,1,dtype=tf.float32) * mag\n",
        "    height, width = image.shape[0], image.shape[1]\n",
        "    w, h = int(s*width), int(s*height)\n",
        "    if (w == CFG.OBJ_HEIGHT) and (h == CFG.OBJ_WIDTH):\n",
        "        return image\n",
        "\n",
        "    if s > 1:\n",
        "\n",
        "        image = tf.image.crop_to_bounding_box(image, 0,0,height-(h-height),width-(w-width))\n",
        "        image = tf.image.resize(image, (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH))\n",
        "    if s < 1:\n",
        "        image = tf.image.crop_to_bounding_box(image, height-h,width-w,h,w)\n",
        "        image = tf.image.resize(image, (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH))\n",
        "    return image"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEAxFwBse-yv"
      },
      "source": [
        "def real_data_augment(image, label):\n",
        "    k = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    #if k < 0.5:\n",
        "    #    image2, label2 = mixup(image, label)\n",
        "    #elif (k >= -2) and (k < 0):\n",
        "    #    image2, label2 = cutmix(image, label)\n",
        "    #else:\n",
        "    image2, label2 = train_aug_gogo(image, label)\n",
        " \n",
        "    return image2, label2 \n",
        " \n",
        "def prep_for_val(image, label):\n",
        "    \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    #randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    #coarse = CoarseDropout(30)\n",
        "    #randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.85, 1.0))\n",
        " \n",
        "    #P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            img = tf.image.resize(img, [DIM1, DIM2])\n",
        "            img = normalize(img)\n",
        "            imgs.append(img)\n",
        " \n",
        "       \n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2\n",
        " \n",
        " \n",
        "def data_augment(image, label):\n",
        " \n",
        " \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    coarse = CoarseDropout(1)\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.9, 1.1))\n",
        " \n",
        "    P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        " \n",
        "            img = randomcrop(img)\n",
        " \n",
        "            if p_flip >= 0.5:\n",
        "                img = tf.image.flip_left_right(img)\n",
        "            if p_v_flip >= 0.5:\n",
        "                img = tf.image.flip_up_down(img)\n",
        "            #if p_transpose >= 0.5:\n",
        "            #    if CFG.OBJ_HEIGHT == CFG.OBJ_WIDTH:\n",
        "            #        img = tf.image.transpose(img)\n",
        " \n",
        "            img = coarse(img)\n",
        "            img = randaug(img)\n",
        "            #img = img/255.\n",
        "            img = tf.cast(img, tf.float32) / 255.\n",
        "            imgs.append(img)\n",
        " \n",
        "       \n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2\n",
        "\n",
        "def train_aug_gogo(image, label):\n",
        " \n",
        " \n",
        "    DIM1 = CFG.OBJ_HEIGHT\n",
        "    DIM2 = CFG.OBJ_WIDTH\n",
        "    CLASSES = CFG.NUMBER_OF_CLASSES\n",
        "    AUG_BATCH = CFG.AUG_BATCH\n",
        "    imgs = []; labs = []\n",
        "    randaug = RandAugment(CFG.RANDAUG_NUM,CFG.RANDAUG_MAGNITUDE)\n",
        "    #randaug = RandAugment(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    coarse = CoarseDropout(2, 0.32)\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.9, 1.33))\n",
        " \n",
        "    P_NORMAL_OR_MIX = tf.random.uniform([],0,1,dtype=tf.float32)\n",
        " \n",
        " \n",
        "    for j in range(AUG_BATCH):        \n",
        "            img = image[j,:,:,:]\n",
        " \n",
        "            p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "            rotate_degree = tf.random.uniform([],-20,20, dtype=tf.float32)\n",
        "            cutout_degree1 = tf.random.uniform([],96,192, dtype=tf.int32)\n",
        "            cutout_degree2 = tf.random.uniform([],96,192, dtype=tf.int32)\n",
        "\n",
        "            #img = randomcrop(img)\n",
        "            img = tf.cast(img, tf.float32) / 255.\n",
        "            img = tf.image.resize(img, (CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "            img = rectangular_zoom(img)\n",
        "            \n",
        "            if p_flip >= 0.5:\n",
        "                img = tf.image.flip_left_right(img)\n",
        "            if p_v_flip >= 1.2:\n",
        "                img = tf.image.flip_up_down(img)\n",
        "            img = tfa.image.rotate(img, rotate_degree)\n",
        "            img = tf.image.random_brightness(img, 0.2)\n",
        "            img = tf.image.random_saturation(img, 0.05,0.2)\n",
        "            img = coarse(img)\n",
        "            #img = tfa.image.random_cutout(img, tf.Variable((cutout_degree,cutout_degree), dtype=tf.int32))\n",
        "            imgs.append(img)\n",
        "            lab1 = label[j,]\n",
        "            labs.append(lab1)\n",
        " \n",
        "    image2 = tf.reshape(tf.stack(imgs),[AUG_BATCH, DIM1,DIM2,3])\n",
        "    label2 = tf.reshape(tf.stack(labs),(AUG_BATCH,CLASSES))\n",
        " \n",
        "    return image2,label2"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECrHNVz2S4Dk",
        "outputId": "d593a2c6-9556-4fd1-989b-96f386e58408"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "88"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI8RTuBuSEpg"
      },
      "source": [
        "def decode_tr_image(image_data):\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    \n",
        "    return image\n",
        " \n",
        "def decode_val_image(image_data, label):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    #image = normalize(image)\n",
        "    image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    label = tf.reshape(label, [CFG.NUMBER_OF_CLASSES])\n",
        "    return image, label\n",
        "\n",
        "def decode_test_image(image_data, label):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image, label\n",
        "\n",
        "def decode_just_test_image(image_data):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    image = normalize(image)\n",
        "    #image = tf.cast(image, tf.float32) / 255.\n",
        "    \n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image\n",
        " \n",
        "def decode_val_image_for_tta(image_data):\n",
        "    \"\"\"\n",
        "        1. Decode a JPEG-encoded image to a uint8 tensor.\n",
        "        2. Cast tensor to float and normalizes (range between 0 and 1).\n",
        "        3. Resize and reshape images to the expected size.\n",
        "    \"\"\"\n",
        "    randomcrop = RandomResizedCrop(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, CFG.HEIGHT, CFG.WIDTH, scale=(0.99,1.0))\n",
        "    randaug = RandAugmentTTA(3, 12)\n",
        "    normalize = Normalize(CFG.MEAN, CFG.STD)\n",
        "    p_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    p_v_flip = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    #p_transpose = tf.random.uniform([], 0, 1, dtype=tf.float32)\n",
        "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tf.reshape(image, [CFG.HEIGHT, CFG.WIDTH, 3])\n",
        "    image = tf.image.resize(image, size=(CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH))\n",
        "    #image = randomcrop(image)\n",
        "    if p_flip > 0.5:\n",
        "        image = tf.image.flip_left_right(image)\n",
        "    if p_v_flip > 0.5:\n",
        "        image = tf.image.flip_up_down(image)\n",
        "    #if CFG.OBJ_HEIGHT == CFG.OBJ_WIDTH:\n",
        "    #    if p_transpose > 0.5:\n",
        "    #        image = tf.image.transpose(image)\n",
        "    image = randaugtta(image)\n",
        "    #image = normalize(image)\n",
        "    image = tf.cast(image, tf.float32) / 255.\n",
        "    image = tf.reshape(image, [CFG.OBJ_HEIGHT, CFG.OBJ_WIDTH, 3])\n",
        "    return image\n",
        " \n",
        "def read_tfrecord(example, labeled=True):\n",
        "    \"\"\"\n",
        "        1. Parse data based on the 'TFREC_FORMAT' map.\n",
        "        2. Decode image.\n",
        "        3. If 'labeled' returns (image, label) if not (image, name).\n",
        "    \"\"\"\n",
        "    if labeled:\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'target': tf.io.FixedLenFeature([], tf.int64), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image'], tf.one_hot(example['target'], depth=CFG.NUMBER_OF_CLASSES)\n",
        "    else:\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image'], example['image_id']\n",
        "\n",
        "def read_test_tfrecord(example):\n",
        "\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image'], example['image_id']\n",
        "\n",
        "def read_test_image_tfrecord(example):\n",
        "\n",
        "        TFREC_FORMAT = {\n",
        "            'image': tf.io.FixedLenFeature([], tf.string), \n",
        "            'image_id': tf.io.FixedLenFeature([], tf.string), \n",
        "        }\n",
        "        example = tf.io.parse_single_example(example, TFREC_FORMAT)\n",
        "        return example['image']\n",
        " \n",
        "def load_dataset(filenames, validation, labeled=True, ordered=False, ):\n",
        "    \"\"\"\n",
        "        Create a Tensorflow dataset from TFRecords.\n",
        "    \"\"\"\n",
        "    ignore_order = tf.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False\n",
        " \n",
        "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO)\n",
        "    dataset = dataset.with_options(ignore_order)\n",
        "    if validation == False:\n",
        " \n",
        "        dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled, validation = False), num_parallel_calls=AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda x: read_tfrecord(x, labeled=labeled, validation = True), num_parallel_calls=AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_dataset(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False, validation=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(1024*8)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        dataset = dataset.with_options(opt)\n",
        "    \n",
        "    if (labeled == True):\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=True), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=False), num_parallel_calls = AUTO)\n",
        "    \n",
        "    if (validation == True) and (labeled == False):\n",
        "        pass\n",
        "    elif (validation == False) and (labeled == True):\n",
        "        dataset = dataset.map(lambda image, label : (decode_tr_image(image), label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda image, label : decode_val_image(image, label), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if augment:\n",
        "            #dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "            dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "    #else:\n",
        "    #        dataset = dataset.map(prep_for_val, num_parallel_calls=AUTO)\n",
        "    \n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_test_dataset(FILENAMES, return_image_name=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()   \n",
        "    \n",
        "    \n",
        "    if return_image_name:\n",
        "        dataset = dataset.map(lambda example : read_test_tfrecord(example), num_parallel_calls = AUTO)\n",
        "        dataset = dataset.map(lambda image, label : decode_test_image(image, label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_test_image_tfrecord(example), num_parallel_calls = AUTO)\n",
        "        dataset = dataset.map(lambda image : decode_just_test_image(image), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset\n",
        " \n",
        "def get_dataset_for_tta(FILENAMES, labeled=True, ordered=False, repeated=False, augment=False, validation=False):\n",
        "    \"\"\"\n",
        "        Return a Tensorflow dataset ready for training or inference.\n",
        "    \"\"\"\n",
        "    dataset = tf.data.TFRecordDataset(FILENAMES, num_parallel_reads = AUTO)\n",
        "    dataset = dataset.cache()\n",
        "    if repeated:\n",
        "        dataset = dataset.repeat()\n",
        "    \n",
        "    if not ordered:\n",
        "        dataset = dataset.shuffle(1024*8)\n",
        "        opt = tf.data.Options()\n",
        "        opt.experimental_deterministic = False\n",
        "        dataset = dataset.with_options(opt)\n",
        "    \n",
        "    if (labeled == True):\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=True), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda example : read_tfrecord(example, labeled=False), num_parallel_calls = AUTO)\n",
        "    \n",
        "    if validation == False:\n",
        "        dataset = dataset.map(lambda image, label : (decode_tr_image(image), label), num_parallel_calls = AUTO)\n",
        "    else:\n",
        "        dataset = dataset.map(lambda image, label : (decode_val_image_for_tta(image), label), num_parallel_calls = AUTO)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if augment:\n",
        "            dataset = dataset.map(real_data_augment, num_parallel_calls=AUTO)\n",
        "    \n",
        "    dataset = dataset.prefetch(AUTO)\n",
        "    return dataset"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEVAoSVZoB-1"
      },
      "source": [
        "def count_data_items(filenames):\n",
        "    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n",
        "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
        "    print(n)\n",
        "    return np.sum(n)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDqawNTsn1vX"
      },
      "source": [
        "from tensorflow_addons.utils.types import FloatTensorLike\n",
        " \n",
        "from typing import Union, Callable, Dict\n",
        "from typeguard import typechecked\n",
        " \n",
        " \n",
        "class CosineDecayRAdam(tfa.optimizers.RectifiedAdam):\n",
        "    def _resource_apply_dense(self, grad, var):\n",
        "        var_dtype = var.dtype.base_dtype\n",
        "        lr_t = self._decayed_lr(var_dtype)\n",
        "        wd_t = self._decayed_wd(var_dtype)\n",
        "        m = self.get_slot(var, \"m\")\n",
        "        v = self.get_slot(var, \"v\")\n",
        "        beta_1_t = self._get_hyper(\"beta_1\", var_dtype)\n",
        "        beta_2_t = self._get_hyper(\"beta_2\", var_dtype)\n",
        "        epsilon_t = tf.convert_to_tensor(self.epsilon, var_dtype)\n",
        "        local_step = tf.cast(self.iterations + 1, var_dtype)\n",
        "        beta_1_power = tf.pow(beta_1_t, local_step)\n",
        "        beta_2_power = tf.pow(beta_2_t, local_step)\n",
        " \n",
        "        if self._initial_total_steps > 0:\n",
        "            total_steps = self._get_hyper(\"total_steps\", var_dtype)\n",
        "            warmup_steps = total_steps * self._get_hyper(\"warmup_proportion\", var_dtype)\n",
        "            min_lr = self._get_hyper(\"min_lr\", var_dtype)\n",
        "            decay_steps = tf.maximum(total_steps - warmup_steps, 1)\n",
        "            decay_rate = (min_lr - lr_t) / decay_steps\n",
        "            pi = tf.constant(3.141592)\n",
        "            cos = tf.math.cos(pi * ((local_step - warmup_steps) / (total_steps - warmup_steps))) + tf.constant(1.)\n",
        "            lr_t = tf.where(\n",
        "                local_step <= warmup_steps,\n",
        "                lr_t * (local_step / warmup_steps),\n",
        "                #lr_t + decay_rate * tf.minimum(local_step - warmup_steps, decay_steps),\n",
        "                min_lr + (lr_t - min_lr) / 2. * cos\n",
        "            )\n",
        " \n",
        "        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n",
        "        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n",
        " \n",
        "        m_t = m.assign(\n",
        "            beta_1_t * m + (1.0 - beta_1_t) * grad, use_locking=self._use_locking\n",
        "        )\n",
        "        m_corr_t = m_t / (1.0 - beta_1_power)\n",
        " \n",
        "        v_t = v.assign(\n",
        "            beta_2_t * v + (1.0 - beta_2_t) * tf.square(grad),\n",
        "            use_locking=self._use_locking,\n",
        "        )\n",
        "        if self.amsgrad:\n",
        "            vhat = self.get_slot(var, \"vhat\")\n",
        "            vhat_t = vhat.assign(tf.maximum(vhat, v_t), use_locking=self._use_locking)\n",
        "            v_corr_t = tf.sqrt(vhat_t / (1.0 - beta_2_power))\n",
        "        else:\n",
        "            vhat_t = None\n",
        "            v_corr_t = tf.sqrt(v_t / (1.0 - beta_2_power))\n",
        " \n",
        "        r_t = tf.sqrt(\n",
        "            (sma_t - 4.0)\n",
        "            / (sma_inf - 4.0)\n",
        "            * (sma_t - 2.0)\n",
        "            / (sma_inf - 2.0)\n",
        "            * sma_inf\n",
        "            / sma_t\n",
        "        )\n",
        " \n",
        "        sma_threshold = self._get_hyper(\"sma_threshold\", var_dtype)\n",
        "        var_t = tf.where(\n",
        "            sma_t >= sma_threshold, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t\n",
        "        )\n",
        " \n",
        "        if self._has_weight_decay:\n",
        "            var_t += wd_t * var\n",
        " \n",
        "        var_update = var.assign_sub(lr_t * var_t, use_locking=self._use_locking)\n",
        " \n",
        "        updates = [var_update, m_t, v_t]\n",
        "        if self.amsgrad:\n",
        "            updates.append(vhat_t)\n",
        "        return tf.group(*updates)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtZCnkM3BCN5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca0bbf13-ee9d-4ecf-b157-167bee338a58"
      },
      "source": [
        "# RandomCropedSized FIX\n",
        "# Cosine Decay Radam\n",
        " \n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = []; history_list = []; normal_oof_pred = []; pred_max = []\n",
        "import gc\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = 5, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "seed_everything(SEED)\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    TRAINING_IMAGES = TRAINING_FILENAMES\n",
        " \n",
        "    train_dataset = get_dataset(TRAINING_FILENAMES, labeled=True, ordered=False, repeated=True, augment=True, validation=False)\n",
        "    val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        " \n",
        "    def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'imagenet', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x0 = tf.keras.layers.Dropout(0.5)(x0)\n",
        "        x0 = tf.keras.layers.Dense(64, activation='relu')(x0)\n",
        "        x = tf.keras.layers.Dense(CFG.NUMBER_OF_CLASSES, activation='softmax', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=int(STEPS_PER_EPOCH*CFG.EPOCHS), warmup_proportion=0.1, min_lr=2e-6)\n",
        "        \n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        #opt =tf.keras.optimizers.Adam(learning_rate=CFG.LEARNING_RATE)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'categorical_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tf.keras.backend.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(os.path.join(ROOT_PATH, f\"(Stacked)COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"), \n",
        "                                                    monitor = 'val_auc', \n",
        "                                                    save_best_only = True,\n",
        "                                                    mode = 'max')\n",
        "    history = model.fit(train_dataset,  \n",
        "                        steps_per_epoch = STEPS_PER_EPOCH,\n",
        "                        epochs = CFG.EPOCHS,\n",
        "                        callbacks = [checkpoint],\n",
        "                        validation_data = val_dataset,\n",
        "                        verbose = 1,\n",
        "                        ).history\n",
        "    print(f\"#### FOLD {fold+1} without TTA VAL_AUC = {np.max(history['val_auc']):.3f}\")\n",
        "    del model\n",
        "    gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.5.126.170:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.5.126.170:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.5.126.170:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.5.126.170:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "258441216/258434480 [==============================] - 3s 0us/step\n",
            "Efficient Model7 has been loaded \n",
            "Epoch 1/20\n",
            "39/79 [=============>................] - ETA: 32s - loss: 1.4480 - auc: 0.5056"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSXjYZ-Rewt-"
      },
      "source": [
        "#Inference B4512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eZByBYeuDMi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "495698f5-7fc9-4250-ce80-243998f83fb3"
      },
      "source": [
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "test_gogo = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-07b08a23789b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_test_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_FILENAMES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_image_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_gogo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TEST_FILENAMES' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hCPkcNNNrPi",
        "outputId": "dc5859a9-e2a1-4aa7-cfee-a3d36289a60f"
      },
      "source": [
        "len(test_gogo)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2986"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaX722tJhYXh",
        "outputId": "e822843b-c154-4cd5-ef92-308c2095089c"
      },
      "source": [
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "sub_names = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])\n",
        "sub_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['002a34c58c5b758217ed1f584ccbcfe9',\n",
              "       '004f33259ee4aef671c2b95d54e4be68',\n",
              "       '008bdde2af2462e86fd373a445d0f4cd', ...,\n",
              "       'ffaa288c8abca300974f043b57d81521',\n",
              "       'ffc441e0c8b7153844047483a577e7c3',\n",
              "       'ffccf1709d0081d122a1d1f9edbefdf1'], dtype='<U32')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuMFk-cMhmly"
      },
      "source": [
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "6LOiSoo6hnfA",
        "outputId": "cb4d6f24-3fb7-4227-85da-d02609af2cce"
      },
      "source": [
        "df_total_sub_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002a34c58c5b758217ed1f584ccbcfe9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>004f33259ee4aef671c2b95d54e4be68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008bdde2af2462e86fd373a445d0f4cd</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>009bc039326338823ca3aa84381f17f1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00a2145de1886cb9eb88869c85d74080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>ff91fb82429a27521bbec8569b041f02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>ff9fcc4087ed5e941209aa3fa948e364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>ffaa288c8abca300974f043b57d81521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>ffc441e0c8b7153844047483a577e7c3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>ffccf1709d0081d122a1d1f9edbefdf1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image_name\n",
              "0     002a34c58c5b758217ed1f584ccbcfe9\n",
              "1     004f33259ee4aef671c2b95d54e4be68\n",
              "2     008bdde2af2462e86fd373a445d0f4cd\n",
              "3     009bc039326338823ca3aa84381f17f1\n",
              "4     00a2145de1886cb9eb88869c85d74080\n",
              "...                                ...\n",
              "2995  ff91fb82429a27521bbec8569b041f02\n",
              "2996  ff9fcc4087ed5e941209aa3fa948e364\n",
              "2997  ffaa288c8abca300974f043b57d81521\n",
              "2998  ffc441e0c8b7153844047483a577e7c3\n",
              "2999  ffccf1709d0081d122a1d1f9edbefdf1\n",
              "\n",
              "[3000 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "DvkmEybnhuxB",
        "outputId": "a9aa89a9-9785-4caf-d25f-9f91c82c5ed8"
      },
      "source": [
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(15)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub\n",
        "#df_sub.to_csv(os.path.join(ROOT_PATH,f'VINBIG_B4512_SUB.csv'),index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>class4</th>\n",
              "      <th>class5</th>\n",
              "      <th>class6</th>\n",
              "      <th>class7</th>\n",
              "      <th>class8</th>\n",
              "      <th>class9</th>\n",
              "      <th>class10</th>\n",
              "      <th>class11</th>\n",
              "      <th>class12</th>\n",
              "      <th>class13</th>\n",
              "      <th>class14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>002a34c58c5b758217ed1f584ccbcfe9</td>\n",
              "      <td>0.000875</td>\n",
              "      <td>0.000712</td>\n",
              "      <td>0.000914</td>\n",
              "      <td>0.002111</td>\n",
              "      <td>0.001013</td>\n",
              "      <td>0.000697</td>\n",
              "      <td>0.001526</td>\n",
              "      <td>0.002502</td>\n",
              "      <td>0.001551</td>\n",
              "      <td>0.001744</td>\n",
              "      <td>0.001017</td>\n",
              "      <td>0.005805</td>\n",
              "      <td>0.000549</td>\n",
              "      <td>0.001309</td>\n",
              "      <td>0.195280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>004f33259ee4aef671c2b95d54e4be68</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.002430</td>\n",
              "      <td>0.000818</td>\n",
              "      <td>0.000933</td>\n",
              "      <td>0.000613</td>\n",
              "      <td>0.000899</td>\n",
              "      <td>0.001299</td>\n",
              "      <td>0.002292</td>\n",
              "      <td>0.001937</td>\n",
              "      <td>0.001803</td>\n",
              "      <td>0.003263</td>\n",
              "      <td>0.000503</td>\n",
              "      <td>0.000784</td>\n",
              "      <td>0.197328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>008bdde2af2462e86fd373a445d0f4cd</td>\n",
              "      <td>0.174792</td>\n",
              "      <td>0.001424</td>\n",
              "      <td>0.007077</td>\n",
              "      <td>0.122213</td>\n",
              "      <td>0.002034</td>\n",
              "      <td>0.004011</td>\n",
              "      <td>0.006038</td>\n",
              "      <td>0.022974</td>\n",
              "      <td>0.007495</td>\n",
              "      <td>0.016485</td>\n",
              "      <td>0.003327</td>\n",
              "      <td>0.023178</td>\n",
              "      <td>0.000824</td>\n",
              "      <td>0.018443</td>\n",
              "      <td>0.033101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>009bc039326338823ca3aa84381f17f1</td>\n",
              "      <td>0.000378</td>\n",
              "      <td>0.000667</td>\n",
              "      <td>0.000435</td>\n",
              "      <td>0.000579</td>\n",
              "      <td>0.001003</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>0.000990</td>\n",
              "      <td>0.001040</td>\n",
              "      <td>0.000758</td>\n",
              "      <td>0.000430</td>\n",
              "      <td>0.000802</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.000415</td>\n",
              "      <td>0.000440</td>\n",
              "      <td>0.199561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>00a2145de1886cb9eb88869c85d74080</td>\n",
              "      <td>0.086371</td>\n",
              "      <td>0.000703</td>\n",
              "      <td>0.002839</td>\n",
              "      <td>0.140198</td>\n",
              "      <td>0.002009</td>\n",
              "      <td>0.000702</td>\n",
              "      <td>0.002813</td>\n",
              "      <td>0.008863</td>\n",
              "      <td>0.003644</td>\n",
              "      <td>0.006245</td>\n",
              "      <td>0.003057</td>\n",
              "      <td>0.019245</td>\n",
              "      <td>0.001014</td>\n",
              "      <td>0.005706</td>\n",
              "      <td>0.062666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2995</th>\n",
              "      <td>ff91fb82429a27521bbec8569b041f02</td>\n",
              "      <td>0.169418</td>\n",
              "      <td>0.001050</td>\n",
              "      <td>0.034280</td>\n",
              "      <td>0.107503</td>\n",
              "      <td>0.099559</td>\n",
              "      <td>0.004379</td>\n",
              "      <td>0.036410</td>\n",
              "      <td>0.178246</td>\n",
              "      <td>0.184320</td>\n",
              "      <td>0.069109</td>\n",
              "      <td>0.007016</td>\n",
              "      <td>0.037167</td>\n",
              "      <td>0.001567</td>\n",
              "      <td>0.069370</td>\n",
              "      <td>0.002304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2996</th>\n",
              "      <td>ff9fcc4087ed5e941209aa3fa948e364</td>\n",
              "      <td>0.195568</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.008906</td>\n",
              "      <td>0.118982</td>\n",
              "      <td>0.001435</td>\n",
              "      <td>0.002094</td>\n",
              "      <td>0.002883</td>\n",
              "      <td>0.007362</td>\n",
              "      <td>0.006666</td>\n",
              "      <td>0.011426</td>\n",
              "      <td>0.005162</td>\n",
              "      <td>0.045798</td>\n",
              "      <td>0.000817</td>\n",
              "      <td>0.026318</td>\n",
              "      <td>0.010865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2997</th>\n",
              "      <td>ffaa288c8abca300974f043b57d81521</td>\n",
              "      <td>0.001954</td>\n",
              "      <td>0.002920</td>\n",
              "      <td>0.000992</td>\n",
              "      <td>0.001406</td>\n",
              "      <td>0.004295</td>\n",
              "      <td>0.005929</td>\n",
              "      <td>0.011130</td>\n",
              "      <td>0.022830</td>\n",
              "      <td>0.001263</td>\n",
              "      <td>0.005433</td>\n",
              "      <td>0.125751</td>\n",
              "      <td>0.071830</td>\n",
              "      <td>0.002736</td>\n",
              "      <td>0.005590</td>\n",
              "      <td>0.162730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2998</th>\n",
              "      <td>ffc441e0c8b7153844047483a577e7c3</td>\n",
              "      <td>0.018895</td>\n",
              "      <td>0.000734</td>\n",
              "      <td>0.001783</td>\n",
              "      <td>0.021862</td>\n",
              "      <td>0.001242</td>\n",
              "      <td>0.000793</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>0.004114</td>\n",
              "      <td>0.002283</td>\n",
              "      <td>0.002916</td>\n",
              "      <td>0.001685</td>\n",
              "      <td>0.003270</td>\n",
              "      <td>0.000978</td>\n",
              "      <td>0.003354</td>\n",
              "      <td>0.163176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2999</th>\n",
              "      <td>ffccf1709d0081d122a1d1f9edbefdf1</td>\n",
              "      <td>0.145861</td>\n",
              "      <td>0.095181</td>\n",
              "      <td>0.034802</td>\n",
              "      <td>0.004557</td>\n",
              "      <td>0.008672</td>\n",
              "      <td>0.045669</td>\n",
              "      <td>0.050831</td>\n",
              "      <td>0.070977</td>\n",
              "      <td>0.008625</td>\n",
              "      <td>0.026598</td>\n",
              "      <td>0.189738</td>\n",
              "      <td>0.199768</td>\n",
              "      <td>0.004524</td>\n",
              "      <td>0.194726</td>\n",
              "      <td>0.000403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3000 rows × 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            image_name    class0  ...   class13   class14\n",
              "0     002a34c58c5b758217ed1f584ccbcfe9  0.000875  ...  0.001309  0.195280\n",
              "1     004f33259ee4aef671c2b95d54e4be68  0.001957  ...  0.000784  0.197328\n",
              "2     008bdde2af2462e86fd373a445d0f4cd  0.174792  ...  0.018443  0.033101\n",
              "3     009bc039326338823ca3aa84381f17f1  0.000378  ...  0.000440  0.199561\n",
              "4     00a2145de1886cb9eb88869c85d74080  0.086371  ...  0.005706  0.062666\n",
              "...                                ...       ...  ...       ...       ...\n",
              "2995  ff91fb82429a27521bbec8569b041f02  0.169418  ...  0.069370  0.002304\n",
              "2996  ff9fcc4087ed5e941209aa3fa948e364  0.195568  ...  0.026318  0.010865\n",
              "2997  ffaa288c8abca300974f043b57d81521  0.001954  ...  0.005590  0.162730\n",
              "2998  ffc441e0c8b7153844047483a577e7c3  0.018895  ...  0.003354  0.163176\n",
              "2999  ffccf1709d0081d122a1d1f9edbefdf1  0.145861  ...  0.194726  0.000403\n",
              "\n",
              "[3000 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HAnbQUN5qXv"
      },
      "source": [
        "TTA = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jPmlTjd8exx8",
        "outputId": "a6560bb8-b049-437c-efa8-db72f74c1893"
      },
      "source": [
        "#model prediction\n",
        "from sklearn.metrics import average_precision_score\n",
        "TEST_FILENAMES = FILENAMES\n",
        "ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "sub_names = np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())])\n",
        "\n",
        "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [];\n",
        "history_list = []; normal_oof_pred = []; pred_max = []; pred_probs = []; pred_sub_probs = [];\n",
        "sub_pred = [];\n",
        "pred_sub_prob = np.zeros(shape=(count_data_items(TEST_FILENAMES), CFG.NUMBER_OF_CLASSES))\n",
        "def get_model2(NET):\n",
        " \n",
        " \n",
        "        inp = tf.keras.layers.Input(shape = (CFG.OBJ_HEIGHT,CFG.OBJ_WIDTH, 3), name = 'inp1')\n",
        "        effnet = effnets[NET](weights = 'imagenet', include_top = False, pooling='avg')\n",
        "        for layer in effnet.layers:\n",
        "            if 'bn' in layer.name:\n",
        "                layer.trainable = True\n",
        "        \n",
        "        x0 = effnet(inp)\n",
        "        x0 = tf.keras.layers.Dropout(0.5)(x0)\n",
        "        x0 = tf.keras.layers.Dense(64, activation='relu')(x0)\n",
        "        x = tf.keras.layers.Dense(CFG.NUMBER_OF_CLASSES, activation='softmax', dtype='float32')(x0)\n",
        " \n",
        "        model = tf.keras.models.Model(inputs = inp, outputs = x)\n",
        "        opt = CosineDecayRAdam(learning_rate=CFG.LEARNING_RATE, total_steps=500, warmup_proportion=0.1, min_lr=2e-6)\n",
        "        \n",
        "        opt = tfa.optimizers.Lookahead(opt)\n",
        "        #opt =tf.keras.optimizers.Adam(learning_rate=CFG.LEARNING_RATE)\n",
        "        model.compile(\n",
        "            optimizer = opt,\n",
        "            loss = 'categorical_crossentropy',\n",
        "            metrics = [tf.keras.metrics.AUC(multi_label=True)]\n",
        "            ) \n",
        "        \n",
        "        return model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kf = KFold(n_splits = CFG.N_FOLDS, random_state = 0)\n",
        "FILENAMES = np.array(FILENAMES)\n",
        "\n",
        "for fold, (tr_index, val_index) in enumerate(kf.split(FILENAMES)):\n",
        "    \n",
        "    if DEVICE=='TPU':\n",
        "        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    with strategy.scope():\n",
        "        model = get_model2(CFG.NET)\n",
        "    \n",
        "    TRAINING_FILENAMES, VALIDATION_FILENAMES = FILENAMES[tr_index], FILENAMES[val_index]\n",
        "    NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
        "    STEPS_PER_EPOCH = NUM_TRAINING_IMAGES // CFG.BATCH_SIZE\n",
        "    #val_dataset = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    seed_everything(SEED)\n",
        "    model.load_weights(os.path.join(ROOT_PATH, f\"COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.h5\"))\n",
        "    print(f\"Efficient Model{CFG.NET} has been loaded \")\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False                   \n",
        "    \n",
        "    ct_valid = count_data_items(VALIDATION_FILENAMES)\n",
        "    \n",
        "    if TTA:\n",
        "########## TTA\n",
        "    ## GET NORMAL OOF\n",
        "        for i in range(CFG.TTA_NUM+1):\n",
        "            if i == 0:\n",
        "                ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "                pred_prob = model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 1)\n",
        "            else:\n",
        "                ds_valid = get_dataset_for_tta(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "                pred_prob += model.predict(ds_valid, verbose=1) / (CFG.TTA_NUM + 1)\n",
        "\n",
        "########## NO TTA\n",
        "    else:\n",
        "        ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "        pred_prob = model.predict(ds_valid, verbose=1)\n",
        "    \n",
        "    pred_probs.append(pred_prob)\n",
        "\n",
        "\n",
        "    ds_valid = get_dataset(VALIDATION_FILENAMES, labeled=True, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
        "    oof_folds.append(np.ones_like(oof_tar[-1], dtype='int8')*fold)\n",
        "    ds = get_dataset(VALIDATION_FILENAMES, labeled=False, ordered=True, repeated=False, augment=False, validation=True)\n",
        "    oof_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds.unbatch())]))\n",
        "    \n",
        "    ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=False)\n",
        "    pred_sub_prob += model.predict(ds_test, verbose=1) / CFG.N_FOLDS\n",
        "    #pred_sub_probs.append(pred_sub_prob)\n",
        "\n",
        "    #ds_test = get_test_dataset(TEST_FILENAMES, return_image_name=True)\n",
        "    #sub_names.append(np.array([img_name.numpy().decode('utf-8') for img, img_name in iter(ds_test.unbatch())]))\n",
        "\n",
        "\n",
        "\n",
        "    del model\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "true = np.concatenate(oof_tar);\n",
        "names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n",
        "pred_probs_oof = np.concatenate(pred_probs);\n",
        "\n",
        "#total_sub_names = np.concatenate(sub_names)\n",
        "#total_pred_sub_probs = np.concatenate(pred_sub_probs)\n",
        "\n",
        "df_total_sub_names = pd.DataFrame()\n",
        "df_total_sub_names['image_name'] = sub_names\n",
        "df_total_pred_sub_probs = pd.DataFrame(pred_sub_prob, columns=[f\"class{x}\" for x in range(CFG.NUMBER_OF_CLASSES)])\n",
        "df_sub = pd.concat([df_total_sub_names, df_total_pred_sub_probs], axis=1)\n",
        "df_sub.to_csv(os.path.join(ROOT_PATH,f'(sub)COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.csv'),index=False)\n",
        "print(df_sub)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "df_image = pd.DataFrame()\n",
        "df_image['image_name'] = names\n",
        "df_target = pd.DataFrame(true, columns=[f\"target{x}\" for x in range(CFG.NUMBER_OF_CLASSES)])\n",
        "\n",
        "df_fold = pd.DataFrame()\n",
        "df_fold['fold'] = folds[:,0]\n",
        "df_pred_probs = pd.DataFrame(pred_probs_oof, columns=[f\"class{x}\" for x in range(CFG.NUMBER_OF_CLASSES)])\n",
        "df_oof = pd.concat([df_image, df_target, df_pred_probs, df_fold], axis=1)\n",
        "df_oof.to_csv(os.path.join(ROOT_PATH,f'(oof)COVID19{CFG.NET}_WIDTH_{CFG.OBJ_WIDTH}_HEIGHT_{CFG.OBJ_HEIGHT}_fold{fold}.csv.csv'),index=False)\n",
        "\n",
        "ind_class_roc = []\n",
        "ind_class_ap = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "    ind_class_ap.append(average_precision_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"total map:\",np.array(ind_class_ap).mean()*2/3)\n",
        "#print(f\"class {CFG.NUMBER_OF_CLASSES} auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1267, 1266]\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "Efficient Model7 has been loaded \n",
            "[1267]\n",
            "20/20 [==============================] - 23s 138ms/step\n",
            "20/20 [==============================] - 4s 143ms/step\n",
            "20/20 [==============================] - 4s 143ms/step\n",
            "20/20 [==============================] - 4s 145ms/step\n",
            "20/20 [==============================] - 4s 142ms/step\n",
            "99/99 [==============================] - 35s 145ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "Efficient Model7 has been loaded \n",
            "[1267]\n",
            "20/20 [==============================] - 23s 139ms/step\n",
            "20/20 [==============================] - 4s 144ms/step\n",
            "20/20 [==============================] - 4s 142ms/step\n",
            "20/20 [==============================] - 4s 145ms/step\n",
            "20/20 [==============================] - 4s 143ms/step\n",
            "99/99 [==============================] - 35s 144ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "Efficient Model7 has been loaded \n",
            "[1267]\n",
            "20/20 [==============================] - 24s 141ms/step\n",
            "20/20 [==============================] - 4s 145ms/step\n",
            "20/20 [==============================] - 4s 144ms/step\n",
            "20/20 [==============================] - 4s 146ms/step\n",
            "20/20 [==============================] - 4s 144ms/step\n",
            "99/99 [==============================] - 35s 145ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1266]\n",
            "Efficient Model7 has been loaded \n",
            "[1267]\n",
            "20/20 [==============================] - 24s 139ms/step\n",
            "20/20 [==============================] - 4s 143ms/step\n",
            "20/20 [==============================] - 4s 144ms/step\n",
            "20/20 [==============================] - 4s 147ms/step\n",
            "20/20 [==============================] - 5s 210ms/step\n",
            "99/99 [==============================] - 35s 144ms/step\n",
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.103.110.98:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.103.110.98:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1267, 1267, 1267, 1267]\n",
            "Efficient Model7 has been loaded \n",
            "[1266]\n",
            "20/20 [==============================] - 24s 140ms/step\n",
            "20/20 [==============================] - 4s 141ms/step\n",
            "20/20 [==============================] - 4s 144ms/step\n",
            "20/20 [==============================] - 4s 143ms/step\n",
            "20/20 [==============================] - 4s 142ms/step\n",
            "99/99 [==============================] - 35s 144ms/step\n",
            "        image_name    class0    class1    class2    class3\n",
            "0     000c3a3f293f  0.249513  0.309366  0.116553  0.324568\n",
            "1     001398f4ff4f  0.772411  0.092160  0.058864  0.076566\n",
            "2     007b2567d83e  0.003349  0.048829  0.002676  0.945146\n",
            "3     001bd15d1891  0.034541  0.103859  0.011111  0.850488\n",
            "4     000a312787f2  0.019858  0.102129  0.009639  0.868375\n",
            "...            ...       ...       ...       ...       ...\n",
            "6329  ffbeafe30b77  0.470692  0.163142  0.047240  0.318927\n",
            "6330  ffcc16bbf428  0.051062  0.088677  0.010254  0.850007\n",
            "6331  ffdc682f7680  0.043759  0.135711  0.012581  0.807949\n",
            "6332  ffd9b6cf2961  0.435957  0.246219  0.149517  0.168307\n",
            "6333  ffe942c8655f  0.000455  0.007980  0.000811  0.990753\n",
            "\n",
            "[6334 rows x 5 columns]\n",
            "total auc: 0.7923934304218596\n",
            "total map: 0.3510911308078371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c3a3f293f</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.245400</td>\n",
              "      <td>0.111061</td>\n",
              "      <td>0.022274</td>\n",
              "      <td>0.621265</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00b0891276a3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.074440</td>\n",
              "      <td>0.090781</td>\n",
              "      <td>0.013611</td>\n",
              "      <td>0.821168</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00e37a390f0f</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010702</td>\n",
              "      <td>0.020213</td>\n",
              "      <td>0.003280</td>\n",
              "      <td>0.965806</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00e3a7e91a34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.361843</td>\n",
              "      <td>0.138582</td>\n",
              "      <td>0.076110</td>\n",
              "      <td>0.423465</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0d4d6acc9ed3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.358434</td>\n",
              "      <td>0.139364</td>\n",
              "      <td>0.060191</td>\n",
              "      <td>0.442011</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_name  target0  target1  target2  ...    class1    class2    class3  fold\n",
              "0  000c3a3f293f      1.0      0.0      0.0  ...  0.111061  0.022274  0.621265     0\n",
              "1  00b0891276a3      0.0      0.0      0.0  ...  0.090781  0.013611  0.821168     0\n",
              "2  00e37a390f0f      0.0      0.0      0.0  ...  0.020213  0.003280  0.965806     0\n",
              "3  00e3a7e91a34      1.0      0.0      0.0  ...  0.138582  0.076110  0.423465     0\n",
              "4  0d4d6acc9ed3      1.0      0.0      0.0  ...  0.139364  0.060191  0.442011     0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "gabhdDkw7fqP",
        "outputId": "258f646b-7960-4f92-d0bc-93885be3f2e2"
      },
      "source": [
        "df_oof[['target0','target1','target2','target3']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c3a3f293f</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044777</td>\n",
              "      <td>0.229694</td>\n",
              "      <td>0.041547</td>\n",
              "      <td>0.683982</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00b0891276a3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.070826</td>\n",
              "      <td>0.166704</td>\n",
              "      <td>0.025137</td>\n",
              "      <td>0.737333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00e37a390f0f</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.075357</td>\n",
              "      <td>0.003436</td>\n",
              "      <td>0.913689</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00e3a7e91a34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0d4d6acc9ed3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6329</th>\n",
              "      <td>fece1740823c</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.296112</td>\n",
              "      <td>0.276682</td>\n",
              "      <td>0.046547</td>\n",
              "      <td>0.380660</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6330</th>\n",
              "      <td>ff23167d20b4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.045188</td>\n",
              "      <td>0.237923</td>\n",
              "      <td>0.060011</td>\n",
              "      <td>0.656877</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6331</th>\n",
              "      <td>ff322f8e36c4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.877586</td>\n",
              "      <td>0.057183</td>\n",
              "      <td>0.005390</td>\n",
              "      <td>0.059840</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6332</th>\n",
              "      <td>ff9f10a24c27</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.949183</td>\n",
              "      <td>0.023384</td>\n",
              "      <td>0.004172</td>\n",
              "      <td>0.023261</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6333</th>\n",
              "      <td>ffbeafe30b77</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.293803</td>\n",
              "      <td>0.321225</td>\n",
              "      <td>0.096799</td>\n",
              "      <td>0.288172</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6334 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        image_name  target0  target1  ...    class2    class3  fold\n",
              "0     000c3a3f293f      1.0      0.0  ...  0.041547  0.683982     0\n",
              "1     00b0891276a3      0.0      0.0  ...  0.025137  0.737333     0\n",
              "2     00e37a390f0f      0.0      0.0  ...  0.003436  0.913689     0\n",
              "3     00e3a7e91a34      1.0      0.0  ...  0.049463  0.544704     0\n",
              "4     0d4d6acc9ed3      1.0      0.0  ...  0.049463  0.544704     0\n",
              "...            ...      ...      ...  ...       ...       ...   ...\n",
              "6329  fece1740823c      0.0      0.0  ...  0.046547  0.380660     4\n",
              "6330  ff23167d20b4      0.0      0.0  ...  0.060011  0.656877     4\n",
              "6331  ff322f8e36c4      0.0      0.0  ...  0.005390  0.059840     4\n",
              "6332  ff9f10a24c27      1.0      0.0  ...  0.004172  0.023261     4\n",
              "6333  ffbeafe30b77      0.0      0.0  ...  0.096799  0.288172     4\n",
              "\n",
              "[6334 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "TFQiTe-u6CCx",
        "outputId": "393f346e-4ed8-4575-f56c-2eb5579d1d71"
      },
      "source": [
        "ind_class_roc = []\n",
        "ind_class_ap = []\n",
        "for i in range(CFG.NUMBER_OF_CLASSES):\n",
        "    ind_class_roc.append(roc_auc_score(true[:,i], pred_probs_oof[:,i]))\n",
        "    ind_class_ap.append(average_precision_score(true[:,i], pred_probs_oof[:,i]))\n",
        "print(\"total auc:\",np.array(ind_class_roc).mean())\n",
        "print(\"total map:\",np.array(ind_class_ap).mean()*2/3)\n",
        "#print(f\"class {CFG.NUMBER_OF_CLASSES} auc:\", ind_class_roc[-1])\n",
        "df_oof.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total auc: 0.7926285606178927\n",
            "total map: 0.3519535713592532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_name</th>\n",
              "      <th>target0</th>\n",
              "      <th>target1</th>\n",
              "      <th>target2</th>\n",
              "      <th>target3</th>\n",
              "      <th>class0</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>class3</th>\n",
              "      <th>fold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c3a3f293f</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.044777</td>\n",
              "      <td>0.229694</td>\n",
              "      <td>0.041547</td>\n",
              "      <td>0.683982</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00b0891276a3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.070826</td>\n",
              "      <td>0.166704</td>\n",
              "      <td>0.025137</td>\n",
              "      <td>0.737333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>00e37a390f0f</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007519</td>\n",
              "      <td>0.075357</td>\n",
              "      <td>0.003436</td>\n",
              "      <td>0.913689</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>00e3a7e91a34</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0d4d6acc9ed3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.143055</td>\n",
              "      <td>0.262778</td>\n",
              "      <td>0.049463</td>\n",
              "      <td>0.544704</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     image_name  target0  target1  target2  ...    class1    class2    class3  fold\n",
              "0  000c3a3f293f      1.0      0.0      0.0  ...  0.229694  0.041547  0.683982     0\n",
              "1  00b0891276a3      0.0      0.0      0.0  ...  0.166704  0.025137  0.737333     0\n",
              "2  00e37a390f0f      0.0      0.0      0.0  ...  0.075357  0.003436  0.913689     0\n",
              "3  00e3a7e91a34      1.0      0.0      0.0  ...  0.262778  0.049463  0.544704     0\n",
              "4  0d4d6acc9ed3      1.0      0.0      0.0  ...  0.262778  0.049463  0.544704     0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    }
  ]
}